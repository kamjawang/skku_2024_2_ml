{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch==2.1.1 in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (2.1.1)\n",
      "Requirement already satisfied: torchvision==0.16.1 in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (0.16.1)\n",
      "Requirement already satisfied: filelock in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (from torch==2.1.1) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (from torch==2.1.1) (4.11.0)\n",
      "Requirement already satisfied: sympy in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (from torch==2.1.1) (1.13.3)\n",
      "Requirement already satisfied: networkx in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (from torch==2.1.1) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (from torch==2.1.1) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (from torch==2.1.1) (2024.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (from torch==2.1.1) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (from torch==2.1.1) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (from torch==2.1.1) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (from torch==2.1.1) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (from torch==2.1.1) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (from torch==2.1.1) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (from torch==2.1.1) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (from torch==2.1.1) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (from torch==2.1.1) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (from torch==2.1.1) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (from torch==2.1.1) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (from torch==2.1.1) (2.1.0)\n",
      "Requirement already satisfied: numpy in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (from torchvision==0.16.1) (1.26.4)\n",
      "Requirement already satisfied: requests in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (from torchvision==0.16.1) (2.32.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (from torchvision==0.16.1) (11.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.1.1) (12.6.85)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (from jinja2->torch==2.1.1) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (from requests->torchvision==0.16.1) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (from requests->torchvision==0.16.1) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (from requests->torchvision==0.16.1) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (from requests->torchvision==0.16.1) (2024.8.30)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (from sympy->torch==2.1.1) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: causal-conv1d==1.1.1 in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (1.1.1)\n",
      "Requirement already satisfied: torch in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (from causal-conv1d==1.1.1) (2.1.1)\n",
      "Requirement already satisfied: packaging in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (from causal-conv1d==1.1.1) (24.2)\n",
      "Requirement already satisfied: buildtools in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (from causal-conv1d==1.1.1) (1.0.6)\n",
      "Requirement already satisfied: ninja in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (from causal-conv1d==1.1.1) (1.11.1.2)\n",
      "Requirement already satisfied: sqlalchemy in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (from buildtools->causal-conv1d==1.1.1) (2.0.36)\n",
      "Collecting argparse (from buildtools->causal-conv1d==1.1.1)\n",
      "  Using cached argparse-1.4.0-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: twisted in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (from buildtools->causal-conv1d==1.1.1) (24.10.0)\n",
      "Requirement already satisfied: simplejson in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (from buildtools->causal-conv1d==1.1.1) (3.19.3)\n",
      "Requirement already satisfied: furl in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (from buildtools->causal-conv1d==1.1.1) (2.1.3)\n",
      "Requirement already satisfied: requests in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (from buildtools->causal-conv1d==1.1.1) (2.32.3)\n",
      "Requirement already satisfied: docopt in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (from buildtools->causal-conv1d==1.1.1) (0.6.2)\n",
      "Requirement already satisfied: python-dateutil in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (from buildtools->causal-conv1d==1.1.1) (2.9.0.post0)\n",
      "Requirement already satisfied: jinja2 in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (from buildtools->causal-conv1d==1.1.1) (3.1.4)\n",
      "Requirement already satisfied: redo in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (from buildtools->causal-conv1d==1.1.1) (3.0.0)\n",
      "Requirement already satisfied: filelock in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (from torch->causal-conv1d==1.1.1) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (from torch->causal-conv1d==1.1.1) (4.11.0)\n",
      "Requirement already satisfied: sympy in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (from torch->causal-conv1d==1.1.1) (1.13.3)\n",
      "Requirement already satisfied: networkx in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (from torch->causal-conv1d==1.1.1) (3.4.2)\n",
      "Requirement already satisfied: fsspec in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (from torch->causal-conv1d==1.1.1) (2024.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (from torch->causal-conv1d==1.1.1) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (from torch->causal-conv1d==1.1.1) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (from torch->causal-conv1d==1.1.1) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (from torch->causal-conv1d==1.1.1) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (from torch->causal-conv1d==1.1.1) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (from torch->causal-conv1d==1.1.1) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (from torch->causal-conv1d==1.1.1) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (from torch->causal-conv1d==1.1.1) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (from torch->causal-conv1d==1.1.1) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (from torch->causal-conv1d==1.1.1) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (from torch->causal-conv1d==1.1.1) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (from torch->causal-conv1d==1.1.1) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->causal-conv1d==1.1.1) (12.6.85)\n",
      "Requirement already satisfied: six>=1.8.0 in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (from furl->buildtools->causal-conv1d==1.1.1) (1.16.0)\n",
      "Requirement already satisfied: orderedmultidict>=1.0.1 in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (from furl->buildtools->causal-conv1d==1.1.1) (1.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (from jinja2->buildtools->causal-conv1d==1.1.1) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (from requests->buildtools->causal-conv1d==1.1.1) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (from requests->buildtools->causal-conv1d==1.1.1) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (from requests->buildtools->causal-conv1d==1.1.1) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (from requests->buildtools->causal-conv1d==1.1.1) (2024.8.30)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (from sqlalchemy->buildtools->causal-conv1d==1.1.1) (3.1.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (from sympy->torch->causal-conv1d==1.1.1) (1.3.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (from twisted->buildtools->causal-conv1d==1.1.1) (24.2.0)\n",
      "Requirement already satisfied: automat>=24.8.0 in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (from twisted->buildtools->causal-conv1d==1.1.1) (24.8.1)\n",
      "Requirement already satisfied: constantly>=15.1 in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (from twisted->buildtools->causal-conv1d==1.1.1) (23.10.4)\n",
      "Requirement already satisfied: hyperlink>=17.1.1 in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (from twisted->buildtools->causal-conv1d==1.1.1) (21.0.0)\n",
      "Requirement already satisfied: incremental>=24.7.0 in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (from twisted->buildtools->causal-conv1d==1.1.1) (24.7.2)\n",
      "Requirement already satisfied: zope-interface>=5 in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (from twisted->buildtools->causal-conv1d==1.1.1) (7.1.1)\n",
      "Requirement already satisfied: setuptools>=61.0 in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (from incremental>=24.7.0->twisted->buildtools->causal-conv1d==1.1.1) (75.1.0)\n",
      "Requirement already satisfied: tomli in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (from incremental>=24.7.0->twisted->buildtools->causal-conv1d==1.1.1) (2.1.0)\n",
      "Using cached argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n",
      "Installing collected packages: argparse\n",
      "Successfully installed argparse-1.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: mamba-ssm in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (2.2.2)\n",
      "Requirement already satisfied: torch in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (from mamba-ssm) (2.1.1)\n",
      "Requirement already satisfied: packaging in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (from mamba-ssm) (24.2)\n",
      "Requirement already satisfied: ninja in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (from mamba-ssm) (1.11.1.2)\n",
      "Requirement already satisfied: einops in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (from mamba-ssm) (0.8.0)\n",
      "Requirement already satisfied: triton in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (from mamba-ssm) (2.1.0)\n",
      "Requirement already satisfied: transformers in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (from mamba-ssm) (4.46.3)\n",
      "Requirement already satisfied: filelock in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (from torch->mamba-ssm) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (from torch->mamba-ssm) (4.11.0)\n",
      "Requirement already satisfied: sympy in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (from torch->mamba-ssm) (1.13.3)\n",
      "Requirement already satisfied: networkx in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (from torch->mamba-ssm) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (from torch->mamba-ssm) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (from torch->mamba-ssm) (2024.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (from torch->mamba-ssm) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (from torch->mamba-ssm) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (from torch->mamba-ssm) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (from torch->mamba-ssm) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (from torch->mamba-ssm) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (from torch->mamba-ssm) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (from torch->mamba-ssm) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (from torch->mamba-ssm) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (from torch->mamba-ssm) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (from torch->mamba-ssm) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (from torch->mamba-ssm) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->mamba-ssm) (12.6.85)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (from transformers->mamba-ssm) (0.26.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (from transformers->mamba-ssm) (1.26.4)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (from transformers->mamba-ssm) (5.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (from transformers->mamba-ssm) (2024.11.6)\n",
      "Requirement already satisfied: requests in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (from transformers->mamba-ssm) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (from transformers->mamba-ssm) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (from transformers->mamba-ssm) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (from transformers->mamba-ssm) (4.67.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (from jinja2->torch->mamba-ssm) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (from requests->transformers->mamba-ssm) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (from requests->transformers->mamba-ssm) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (from requests->transformers->mamba-ssm) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (from requests->transformers->mamba-ssm) (2024.8.30)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/jerome75/miniconda3/envs/mambatab_env/lib/python3.10/site-packages (from sympy->torch->mamba-ssm) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# I used python kernel 3.10.15 + nvidia RTX 3090 + cuda 12.1 in local machine\n",
    "\n",
    "# install ralated modules\n",
    "%pip install torch==2.1.1 torchvision==0.16.1   # compatible version of pytorch and torchvision for mamba-ssm \n",
    "%pip install causal-conv1d==1.1.1   # causal dpthwise conv 1d  module in CUDA with pytorch\n",
    "%pip install mamba-ssm  # Mamba block module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from torchsummary import summary\n",
    "\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, OrdinalEncoder, StandardScaler,MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import tqdm\n",
    "\n",
    "from mamba_ssm import Mamba\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.api.types import is_string_dtype\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import copy\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch:  2.1 ; cuda:  cu121\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check environments\n",
    "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
    "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
    "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: `./datasets' 디렉터리를 만들 수 없습니다: 파일이 있습니다\n",
      "mkdir: `./datasets/adult' 디렉터리를 만들 수 없습니다: 파일이 있습니다\n",
      "‘adult.zip’ 파일이 이미 있습니다. 가져오지 않음.\n",
      "\n",
      "Archive:  ./adult.zip\n",
      "  inflating: ./datasets/adult/Index  \n",
      "  inflating: ./datasets/adult/adult.data  \n",
      "  inflating: ./datasets/adult/adult.names  \n",
      "  inflating: ./datasets/adult/adult.test  \n",
      "  inflating: ./datasets/adult/old.adult.names  \n"
     ]
    }
   ],
   "source": [
    "# Get original data\n",
    "!mkdir ./datasets\n",
    "!mkdir ./datasets/adult\n",
    "!wget -nc https://archive.ics.uci.edu/static/public/2/adult.zip\n",
    "!unzip -o ./adult.zip -d ./datasets/adult\n",
    "!cp -rf ./datasets/adult/adult.data ./datasets/adult/data_processed.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Configuration for MambaTab\n",
    "config={\n",
    "    'DATASET_NAME':'adult',\n",
    "    'SEED':15, # random seed 지정\n",
    "    'BATCH':100,\n",
    "    'LR':0.0001,\n",
    "    'EPOCH':1000,\n",
    "    'MAMBA_SSM_DIM':32,  # MAMBA model의 dimension 설정 (d_model: Selective Structured State Machine에 담을 최대 Dimension)\n",
    "    'device':'cuda'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data load and preparing\n",
    "\n",
    "def read_data(dataset_name):\n",
    "    data=pd.read_csv('./datasets/'+dataset_name+'/data_processed'+'.csv')\n",
    "    \n",
    "    # fill null values\n",
    "    for col in data.columns: \n",
    "        #data[col].fillna(data[col].mode()[0], inplace=True)\n",
    "        data[col] = data[col].fillna(data[col].mode()[0])\n",
    "\n",
    "    # categorical encoder: 문자열인 경우 소문자로 통일하고, 숫자로 인코딩 처리\n",
    "    for c in data.columns:\n",
    "        if is_string_dtype(data[c]):\n",
    "            data[c]=data[c].str.lower()\n",
    "            enc=OrdinalEncoder()\n",
    "            cur_data=np.array(data[c])\n",
    "            cur_data=np.reshape(cur_data,(cur_data.shape[0],1))\n",
    "            data[c] = enc.fit_transform(cur_data)\n",
    "\n",
    "    # 마지막 column을 lable로 추출\n",
    "    y_data=data[data.columns[-1]]\n",
    "\n",
    "    # 9번째 컬럼(gender)을 공정성 지표 계산을 위해 별도로 추출\n",
    "    sensitive_data=data[data.columns[9]]\n",
    "\n",
    "    # label 컬럼 제거\n",
    "    x_data = data.drop(labels = [data.columns[-1]],axis = 1)\n",
    "    \n",
    "    # 나머지 컬럼 스케일링 처리\n",
    "    x_data=MinMaxScaler().fit_transform(x_data)\n",
    "    \n",
    "    x_data, y_data, sensitive_data = np.array(x_data),np.array(y_data), np.array(sensitive_data)\n",
    "    \n",
    "    return x_data, y_data, sensitive_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           Male\n",
       "1           Male\n",
       "2           Male\n",
       "3         Female\n",
       "4         Female\n",
       "          ...   \n",
       "32555     Female\n",
       "32556       Male\n",
       "32557     Female\n",
       "32558       Male\n",
       "32559     Female\n",
       "Name:  Male, Length: 32560, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check sensitive column\n",
    "\n",
    "d = pd.read_csv('./datasets/adult/data_processed.csv')\n",
    "d[d.columns[9]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MambaTab Class\n",
    "\n",
    "class MambaTab(torch.nn.Module):\n",
    "\n",
    "    def __init__(self,input_features, n_class, intermediate_representation=config['MAMBA_SSM_DIM']):\n",
    "        super(MambaTab, self).__init__()\n",
    "        self.linear_layer=torch.nn.Linear(input_features,intermediate_representation)\n",
    "        self.relu=torch.nn.ReLU()\n",
    "        self.layer_norm=torch.nn.LayerNorm(intermediate_representation)\n",
    "\n",
    "        self.mamba=Mamba(d_model=intermediate_representation, d_state=32, d_conv=4, expand=2) # to fine-tuning\n",
    "        self.output_layer=torch.nn.Linear(intermediate_representation,n_class)\n",
    "    \n",
    "    # deault model 참조해서 building\n",
    "    def forward(self, x):\n",
    "         x=self.linear_layer(x)\n",
    "         x=self.layer_norm(x)\n",
    "         x=self.relu(x)\n",
    "         x=self.mamba(x)\n",
    "         x=self.output_layer(x)\n",
    "         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "\n",
    "def train_model(model, config, dataloader):\n",
    "    best_model_wts = copy.deepcopy(model.state_dict()) # 최적 가중치 저장\n",
    "    best_loss = 1e10 # 최적 손실값 초기화\n",
    "    early_stopping_counter=0 # earlt stopping 값 초기화\n",
    "\n",
    "    optimizer=torch.optim.Adam(model.parameters(),lr=config['LR'])  # Optimizer setting: Adam\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=config['EPOCH'], eta_min=0,verbose=False) # learning rate 감소를 위한 scheduler setting\n",
    "    loss_fn=torch.nn.BCEWithLogitsLoss()    # 이진분류 처리를 위해 BCEWithLogitLoss 함수 사용\n",
    "  \n",
    "    # 학습 진행\n",
    "    for epoch in tqdm.tqdm(range(config['EPOCH'])):\n",
    "        if early_stopping_counter>=5:\n",
    "          break\n",
    "        \n",
    "        for phase in ['train', 'val']:      \n",
    "            if phase == 'train':               \n",
    "                model.train()  \n",
    "            else:\n",
    "                model.eval()  \n",
    "            \n",
    "            metrics = defaultdict(float)\n",
    "            epoch_samples = 0\n",
    "          \n",
    "            for btch,feed_dict in enumerate(dataloader[phase]):\n",
    "                inputs=feed_dict[0]\n",
    "                inputs=inputs.unsqueeze(0)\n",
    "                labels=feed_dict[1]\n",
    "                sensitives=feed_dict[2]\n",
    "                \n",
    "                inputs = inputs.type(torch.FloatTensor)\n",
    "                inputs = inputs.to(config['device'])\n",
    "                labels = labels.type(torch.FloatTensor)\n",
    "                labels = labels.to(config['device'])\n",
    "                # sensitives = sensitives.type(torch.FloatTensor)\n",
    "                # sensitives = sensitives.to(config['device'])\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'): # 학습 단계에서만 gradient 계산\n",
    "\n",
    "                    outputs = model(inputs)  # 모델 학습\n",
    "                    outputs=outputs.squeeze()  \n",
    "                    loss=loss_fn(outputs,labels) # 손실 계산\n",
    "                    metrics['loss']+=loss.item()\n",
    "                \n",
    "                    if phase == 'train':\n",
    "                        loss.backward() # gradient 계산\n",
    "                        optimizer.step() # graident 업데이트\n",
    "                \n",
    "                epoch_samples += 1 \n",
    "           \n",
    "            epoch_loss = metrics['loss'] / epoch_samples # epoch 총손실 계산\n",
    "\n",
    "            if phase == 'val':\n",
    "           \n",
    "                if epoch_loss<best_loss:\n",
    "                    best_model_wts = copy.deepcopy(model.state_dict()) # 최적 가중치 저장\n",
    "                    best_loss=epoch_loss\n",
    "                    early_stopping_counter=0\n",
    "                else:\n",
    "                    early_stopping_counter+=1\n",
    "            \n",
    "        print(f\"Epoch [{epoch+1}/config['EPOCH'], loss of epoch: {metrics['loss']}\")\n",
    "\n",
    "        scheduler.step()           \n",
    "    \n",
    "    model.load_state_dict(best_model_wts) # 최적 가중치 불러오기\n",
    "\n",
    "    print (\"training completed\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_result(test_model, test_dataloader):\n",
    "\n",
    "    test_model.eval()\n",
    "    \n",
    "    all_probs=[]\n",
    "    all_labels=[]\n",
    "    all_sensitives = []\n",
    "\n",
    "    sig=torch.nn.Sigmoid()  # 이진분류 처리를 위해 BCEWithLogitLoss 함수와 함께 Sigmoid 사용\n",
    "\n",
    "    for inputs,labels, sensitives in test_dataloader['test']:\n",
    "        \n",
    "        inputs = inputs.unsqueeze(0)\n",
    "        inputs = inputs.type(torch.FloatTensor)\n",
    "        \n",
    "        inputs = inputs.to(config['device'])\n",
    "        labels = labels.to(config['device'])\n",
    "        sensitives = sensitives.to(config['device'])\n",
    "\n",
    "        with torch.set_grad_enabled(False):\n",
    "            outputs = test_model(inputs) # 모델 예측\n",
    "            outputs=outputs.squeeze()\n",
    "            \n",
    "            outputs=sig(outputs)\n",
    "\n",
    "            # Detach 처리         \n",
    "            outputs=outputs.cpu().detach().numpy()\n",
    "            labels=labels.cpu().detach().numpy()\n",
    "            sensitives=sensitives.cpu().detach().numpy()\n",
    "            \n",
    "            # 실제 값, 예측 값, 민감 속성 저장\n",
    "            for i in range(outputs.shape[0]):\n",
    "                all_labels.append(labels[i])\n",
    "                all_probs.append(outputs[i])\n",
    "                all_sensitives.append(sensitives[i])\n",
    "    \n",
    "    print(\"test completed\")\n",
    "\n",
    "    return all_labels, all_probs, all_sensitives \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (22792, 14)\n",
      "Val: (3256, 14)\n",
      "Test: (6512, 14)\n"
     ]
    }
   ],
   "source": [
    "# Data loading and data split\n",
    "\n",
    "x_data, y_data, sensitive_data = read_data(dataset_name=config['DATASET_NAME'])\n",
    "\n",
    "x_train, x_test, y_train, y_test, sensitive_train, sensitive_test = train_test_split(x_data, y_data, sensitive_data, test_size=0.2,random_state=config['SEED'],stratify=y_data,shuffle=True)\n",
    "val_size = int(len(y_data)*0.1)\n",
    "x_train, x_val, y_train, y_val, sensitive_train, sensitive_val = train_test_split(x_train, y_train, sensitive_train, test_size=val_size,random_state=config['SEED'],stratify=y_train, shuffle=True)\n",
    "\n",
    "print(\"Train:\",x_train.shape)\n",
    "print(\"Val:\",x_val.shape)\n",
    "print(\"Test:\",x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data from numpy float array to tensor\n",
    "x_train = torch.FloatTensor(x_train)\n",
    "x_val = torch.FloatTensor(x_val)\n",
    "x_test = torch.FloatTensor(x_test)\n",
    "\n",
    "y_train = torch.FloatTensor(y_train)\n",
    "y_val = torch.FloatTensor(y_val)\n",
    "y_test = torch.FloatTensor(y_test)\n",
    "\n",
    "sensitive_train = torch.FloatTensor(sensitive_train)\n",
    "sensitive_val = torch.FloatTensor(sensitive_val)\n",
    "sensitive_test = torch.FloatTensor(sensitive_test)\n",
    "\n",
    "# dataset grouping\n",
    "train_set = TensorDataset(x_train, y_train, sensitive_train)\n",
    "val_set = TensorDataset(x_val, y_val, sensitive_val)\n",
    "test_set = TensorDataset(x_test, y_test, sensitive_test)\n",
    "\n",
    "# build data lodaer\n",
    "dataloader = {\n",
    "      'train': DataLoader(train_set, batch_size=config['BATCH'], shuffle=True, num_workers=4),\n",
    "      'val': DataLoader(val_set, batch_size=config['BATCH'], shuffle=False, num_workers=4),\n",
    "      'test': DataLoader(test_set, batch_size=config['BATCH'], shuffle=False, num_workers=4)\n",
    "   }\n",
    "\n",
    "# Get the model: \"n_class=1 is to use a single output logit strategy,  where n_class does not refer to the number of classes and is sufficient for binary classification\"\n",
    "model=MambaTab(input_features=x_train.shape[1], n_class=1)\n",
    "model=model.to(config['device'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch inputs:  tensor([[0.0000, 0.5000, 0.0696,  ..., 0.0000, 0.1939, 0.9512],\n",
      "        [0.5205, 0.5000, 0.1006,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        [0.1096, 0.5000, 0.0752,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        ...,\n",
      "        [0.2192, 0.5000, 0.1678,  ..., 0.0000, 0.4082, 0.9512],\n",
      "        [0.2877, 0.5000, 0.1005,  ..., 0.4708, 0.4388, 0.9512],\n",
      "        [0.1507, 0.5000, 0.0274,  ..., 0.0000, 0.5000, 0.9512]])\n",
      "Batch labels:  tensor([0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1.,\n",
      "        0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "        0., 1., 0., 0., 0., 0., 0., 0., 0., 1.])\n",
      "Batch sensitive features:  tensor([0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1.,\n",
      "        1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 0.,\n",
      "        1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1., 0., 1., 1.,\n",
      "        1., 1., 0., 1., 1., 0., 0., 1., 1., 1.])\n",
      "Batch inputs:  tensor([[0.2055, 0.5000, 0.0099,  ..., 0.0000, 0.8469, 0.9512],\n",
      "        [0.3014, 0.5000, 0.1296,  ..., 0.0000, 0.4490, 0.9512],\n",
      "        [0.1507, 0.5000, 0.0763,  ..., 0.0000, 0.7041, 0.9512],\n",
      "        ...,\n",
      "        [0.3836, 0.1250, 0.2095,  ..., 0.0000, 0.8061, 0.9512],\n",
      "        [0.2877, 0.5000, 0.0186,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        [0.0411, 0.0000, 0.1523,  ..., 0.0000, 0.3980, 0.9512]])\n",
      "Batch labels:  tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0.,\n",
      "        1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 1., 0., 0., 0., 0., 1., 0., 0.])\n",
      "Batch sensitive features:  tensor([1., 0., 0., 1., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,\n",
      "        1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0.,\n",
      "        1., 1., 1., 0., 1., 1., 0., 1., 0., 1.])\n",
      "Batch inputs:  tensor([[0.3425, 0.5000, 0.3511,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        [0.0137, 0.0000, 0.0782,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        [0.7397, 0.6250, 0.0369,  ..., 0.5491, 0.6020, 0.9512],\n",
      "        ...,\n",
      "        [0.2603, 0.5000, 0.0896,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        [0.2055, 0.5000, 0.1229,  ..., 0.0000, 0.3980, 0.7317],\n",
      "        [0.3562, 0.5000, 0.1949,  ..., 0.0000, 0.3980, 0.9512]])\n",
      "Batch labels:  tensor([0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0.,\n",
      "        1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 1., 1., 0., 0., 0., 0., 0., 0.])\n",
      "Batch sensitive features:  tensor([1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0.,\n",
      "        1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1.,\n",
      "        1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1.,\n",
      "        0., 1., 1., 0., 1., 0., 1., 0., 1., 1.])\n",
      "Batch inputs:  tensor([[0.1233, 0.5000, 0.1650,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        [0.0548, 0.5000, 0.1679,  ..., 0.0000, 0.3571, 0.9512],\n",
      "        [0.5342, 0.5000, 0.0543,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        ...,\n",
      "        [0.1507, 0.2500, 0.2646,  ..., 0.0000, 0.1939, 0.9512],\n",
      "        [0.1370, 0.5000, 0.1131,  ..., 0.0000, 0.8061, 0.9512],\n",
      "        [0.1644, 0.5000, 0.2767,  ..., 0.0000, 0.3980, 0.5854]])\n",
      "Batch labels:  tensor([0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        1., 0., 0., 0., 1., 0., 0., 0., 1., 0.])\n",
      "Batch sensitive features:  tensor([1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0.,\n",
      "        1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1.,\n",
      "        0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0.,\n",
      "        0., 1., 1., 0., 1., 1., 0., 1., 1., 0.])\n",
      "Batch inputs:  tensor([[0.2740, 0.2500, 0.0631,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        [0.0411, 0.5000, 0.1539,  ..., 0.0000, 0.3980, 0.1951],\n",
      "        [0.4658, 0.8750, 0.1527,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        ...,\n",
      "        [0.1233, 0.5000, 0.1615,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        [0.1096, 0.5000, 0.2596,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        [0.4795, 0.8750, 0.2218,  ..., 0.0000, 0.7041, 0.9512]])\n",
      "Batch labels:  tensor([0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 1., 0., 0., 1., 0., 1., 0., 1.])\n",
      "Batch sensitive features:  tensor([1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1.,\n",
      "        0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0.,\n",
      "        0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1.,\n",
      "        0., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
      "        1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 0., 1., 0., 0., 0., 0., 1., 1., 1.])\n",
      "Batch inputs:  tensor([[0.3288, 0.5000, 0.1174,  ..., 0.0000, 0.4490, 0.9512],\n",
      "        [0.5890, 0.7500, 0.0565,  ..., 0.0000, 0.4592, 0.9512],\n",
      "        [0.5616, 0.5000, 0.1239,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        ...,\n",
      "        [0.3562, 0.5000, 0.1220,  ..., 0.0000, 0.5510, 0.9512],\n",
      "        [0.0685, 0.5000, 0.1346,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        [0.5479, 0.5000, 0.1074,  ..., 0.0000, 0.3980, 0.9512]])\n",
      "Batch labels:  tensor([0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0.,\n",
      "        0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
      "        0., 1., 0., 0., 1., 0., 1., 0., 0., 1.])\n",
      "Batch sensitive features:  tensor([0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0.,\n",
      "        1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,\n",
      "        1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1.,\n",
      "        0., 1., 1., 1., 0., 1., 1., 0., 0., 1.])\n",
      "Batch inputs:  tensor([[0.2055, 0.8750, 0.1366,  ..., 0.3962, 0.3776, 0.9512],\n",
      "        [0.1507, 0.5000, 0.2472,  ..., 0.0000, 0.4490, 0.9512],\n",
      "        [0.6301, 0.5000, 0.0994,  ..., 0.0000, 0.0714, 0.9512],\n",
      "        ...,\n",
      "        [0.3562, 0.5000, 0.1233,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        [0.2329, 0.5000, 0.4562,  ..., 0.0000, 0.3980, 0.1951],\n",
      "        [0.4110, 0.5000, 0.1111,  ..., 0.5002, 0.5204, 0.9512]])\n",
      "Batch labels:  tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 1.,\n",
      "        0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1.,\n",
      "        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
      "        1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 1., 1., 0., 0.])\n",
      "Batch sensitive features:  tensor([0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0.,\n",
      "        1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1.,\n",
      "        0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1.,\n",
      "        0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.,\n",
      "        1., 0., 0., 1., 1., 1., 0., 1., 1., 1.])\n",
      "Batch inputs:  tensor([[0.0000, 0.5000, 0.1927,  ..., 0.0000, 0.1939, 0.9512],\n",
      "        [0.3151, 0.8750, 0.1119,  ..., 0.0000, 0.3469, 0.9512],\n",
      "        [0.8356, 0.0000, 0.0107,  ..., 0.0000, 0.3163, 0.9512],\n",
      "        ...,\n",
      "        [0.0411, 0.5000, 0.0853,  ..., 0.0000, 0.4490, 0.9512],\n",
      "        [0.1507, 0.5000, 0.1749,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        [0.2603, 0.5000, 0.0671,  ..., 0.0000, 0.4490, 0.9512]])\n",
      "Batch labels:  tensor([0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
      "        1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 0.,\n",
      "        0., 1., 1., 0., 1., 0., 0., 0., 0., 0.])\n",
      "Batch sensitive features:  tensor([0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,\n",
      "        1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0.,\n",
      "        0., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0.,\n",
      "        1., 1., 1., 1., 1., 0., 1., 1., 1., 1.])\n",
      "Batch inputs:  tensor([[0.1781, 0.5000, 0.2139,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        [0.4795, 0.1250, 0.0170,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        [0.2055, 0.2500, 0.0048,  ..., 0.0000, 0.5612, 0.2195],\n",
      "        ...,\n",
      "        [0.6712, 0.7500, 0.0627,  ..., 0.0000, 0.0714, 0.9512],\n",
      "        [0.2740, 0.1250, 0.1884,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        [0.1507, 0.0000, 0.1252,  ..., 0.0000, 0.3980, 0.6341]])\n",
      "Batch labels:  tensor([0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1.,\n",
      "        1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0.])\n",
      "Batch sensitive features:  tensor([1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1.,\n",
      "        0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0.,\n",
      "        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 1., 1., 1., 0.])\n",
      "Batch inputs:  tensor([[0.1918, 0.5000, 0.2491,  ..., 0.0000, 0.3980, 0.9756],\n",
      "        [0.3014, 0.1250, 0.2854,  ..., 0.3737, 0.3980, 0.9512],\n",
      "        [0.0548, 0.5000, 0.1687,  ..., 0.0000, 0.3571, 0.9512],\n",
      "        ...,\n",
      "        [0.2740, 0.5000, 0.0417,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        [0.2603, 0.5000, 0.4045,  ..., 0.0000, 0.4490, 0.9512],\n",
      "        [0.3425, 0.8750, 0.1983,  ..., 0.0000, 0.3980, 0.9512]])\n",
      "Batch labels:  tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0.,\n",
      "        1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 1., 1., 1., 0.])\n",
      "Batch sensitive features:  tensor([0., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0.,\n",
      "        0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0.,\n",
      "        1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1.,\n",
      "        1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1.,\n",
      "        0., 0., 0., 1., 1., 0., 1., 1., 1., 1.])\n",
      "Batch inputs:  tensor([[0.0137, 0.5000, 0.2815,  ..., 0.0000, 0.3980, 0.6341],\n",
      "        [0.5753, 0.1250, 0.1211,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        [0.2329, 0.5000, 0.2496,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        ...,\n",
      "        [0.2740, 0.5000, 0.1927,  ..., 0.3737, 0.3980, 0.9512],\n",
      "        [0.0000, 0.5000, 0.0641,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        [0.0000, 0.5000, 0.0361,  ..., 0.0000, 0.1122, 0.9512]])\n",
      "Batch labels:  tensor([0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Batch sensitive features:  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0.,\n",
      "        1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0.,\n",
      "        0., 0., 1., 1., 0., 1., 0., 1., 1., 0.])\n",
      "Batch inputs:  tensor([[0.3699, 0.1250, 0.1167,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        [0.2603, 0.8750, 0.1144,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        [0.2740, 0.5000, 0.1270,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        ...,\n",
      "        [0.3836, 0.5000, 0.0577,  ..., 0.0000, 0.1531, 0.9512],\n",
      "        [0.3562, 0.6250, 0.0971,  ..., 0.0000, 0.6020, 0.9512],\n",
      "        [0.2466, 0.5000, 0.0673,  ..., 0.0000, 0.3980, 0.9512]])\n",
      "Batch labels:  tensor([1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
      "        1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
      "        0., 1., 1., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 1., 0.])\n",
      "Batch sensitive features:  tensor([1., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.,\n",
      "        0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1.,\n",
      "        1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1.,\n",
      "        1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,\n",
      "        1., 1., 1., 0., 0., 0., 0., 0., 1., 1.])\n",
      "Batch inputs:  tensor([[0.0685, 0.5000, 0.0245,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        [0.2192, 0.2500, 0.0146,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        [0.3014, 0.5000, 0.1212,  ..., 0.0000, 0.4490, 0.9512],\n",
      "        ...,\n",
      "        [0.1370, 0.5000, 0.0917,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        [0.2329, 0.5000, 0.0328,  ..., 0.2020, 0.6020, 0.9512],\n",
      "        [0.1096, 0.5000, 0.2334,  ..., 0.0000, 1.0000, 0.9512]])\n",
      "Batch labels:  tensor([0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0.,\n",
      "        0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0.,\n",
      "        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0.,\n",
      "        0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Batch sensitive features:  tensor([1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 0.,\n",
      "        1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0.,\n",
      "        1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0.,\n",
      "        1., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1.,\n",
      "        1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 0., 1., 1.])\n",
      "Batch inputs:  tensor([[0.1781, 0.8750, 0.1272,  ..., 0.4366, 0.3980, 0.9512],\n",
      "        [0.3288, 0.5000, 0.1304,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        [0.1781, 0.7500, 0.1097,  ..., 0.0000, 0.6020, 0.9512],\n",
      "        ...,\n",
      "        [0.3973, 0.5000, 0.0759,  ..., 0.0000, 0.4388, 0.9512],\n",
      "        [0.1918, 0.5000, 0.0370,  ..., 0.0000, 0.5000, 0.9512],\n",
      "        [0.1507, 0.5000, 0.0654,  ..., 0.0000, 0.1429, 0.9512]])\n",
      "Batch labels:  tensor([0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 0., 1., 0., 0., 0., 0.])\n",
      "Batch sensitive features:  tensor([1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1.,\n",
      "        1., 0., 0., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
      "        1., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0.,\n",
      "        1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1.,\n",
      "        1., 1., 1., 0., 1., 1., 0., 0., 1., 0.])\n",
      "Batch inputs:  tensor([[0.4247, 0.5000, 0.1306,  ..., 0.0000, 0.5000, 0.9512],\n",
      "        [0.2603, 0.7500, 0.2251,  ..., 0.0000, 0.2959, 0.0000],\n",
      "        [0.0000, 0.5000, 0.1302,  ..., 0.0000, 0.1429, 0.9512],\n",
      "        ...,\n",
      "        [0.3151, 0.1250, 0.2270,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        [0.2740, 0.5000, 0.1217,  ..., 0.0000, 0.3776, 0.9512],\n",
      "        [0.3562, 0.0000, 0.0709,  ..., 0.0000, 0.4490, 0.9512]])\n",
      "Batch labels:  tensor([1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0.,\n",
      "        0., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
      "        0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 1., 0., 0., 0., 1., 0., 1.])\n",
      "Batch sensitive features:  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1.,\n",
      "        1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1.,\n",
      "        0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1.,\n",
      "        0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0.,\n",
      "        1., 1., 0., 1., 1., 0., 0., 1., 0., 1.])\n",
      "Batch inputs:  tensor([[0.3151, 0.5000, 0.0695,  ..., 0.0000, 0.2347, 0.9512],\n",
      "        [0.2877, 0.5000, 0.0889,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        [0.1233, 0.5000, 0.0369,  ..., 0.0000, 0.5000, 0.9512],\n",
      "        ...,\n",
      "        [0.2192, 0.8750, 0.0939,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        [0.4110, 0.5000, 0.2539,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        [0.1096, 0.5000, 0.1633,  ..., 0.0000, 0.3980, 0.9512]])\n",
      "Batch labels:  tensor([1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0.,\n",
      "        0., 0., 1., 0., 0., 0., 1., 0., 1., 0.])\n",
      "Batch sensitive features:  tensor([0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1.,\n",
      "        1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0.,\n",
      "        1., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
      "        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 1., 1., 1., 1., 0.])\n",
      "Batch inputs:  tensor([[0.4110, 0.5000, 0.0398,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        [0.3699, 0.7500, 0.0426,  ..., 0.0000, 0.6020, 0.9756],\n",
      "        [0.3562, 0.5000, 0.1772,  ..., 0.0000, 0.5000, 0.9512],\n",
      "        ...,\n",
      "        [0.3699, 0.5000, 0.1000,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        [0.5890, 0.8750, 0.1212,  ..., 0.0000, 0.3673, 0.9512],\n",
      "        [0.2192, 0.5000, 0.1216,  ..., 0.4366, 0.5000, 0.9512]])\n",
      "Batch labels:  tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0.,\n",
      "        1., 0., 1., 0., 1., 0., 0., 0., 0., 1.])\n",
      "Batch sensitive features:  tensor([1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1.,\n",
      "        1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1.,\n",
      "        1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1.,\n",
      "        0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1.,\n",
      "        0., 1., 1., 1., 0., 1., 1., 0., 0., 1.])\n",
      "Batch inputs:  tensor([[0.0548, 0.5000, 0.0275,  ..., 0.3453, 0.3980, 0.9512],\n",
      "        [0.0548, 0.8750, 0.0243,  ..., 0.3678, 0.0918, 0.9512],\n",
      "        [0.0411, 0.5000, 0.1016,  ..., 0.0000, 0.4286, 0.9512],\n",
      "        ...,\n",
      "        [0.3836, 0.5000, 0.1090,  ..., 0.0000, 0.5204, 0.9512],\n",
      "        [0.0685, 0.5000, 0.1079,  ..., 0.0000, 0.4796, 0.0000],\n",
      "        [0.3014, 0.5000, 0.1353,  ..., 0.0000, 0.5000, 0.9512]])\n",
      "Batch labels:  tensor([0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 1., 1.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
      "        1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 0., 1., 0., 1., 0., 1.])\n",
      "Batch sensitive features:  tensor([1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0.,\n",
      "        0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0.,\n",
      "        1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1.,\n",
      "        1., 1., 0., 1., 0., 1., 0., 1., 0., 1.])\n",
      "Batch inputs:  tensor([[0.2192, 0.5000, 0.3847,  ..., 0.0000, 0.3980, 0.0000],\n",
      "        [0.1644, 0.5000, 0.0925,  ..., 0.0000, 0.4490, 0.9512],\n",
      "        [0.0411, 0.5000, 0.1611,  ..., 0.0000, 0.1531, 0.9512],\n",
      "        ...,\n",
      "        [0.3836, 0.5000, 0.0974,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        [0.6849, 0.0000, 0.0772,  ..., 0.0000, 0.0714, 0.9512],\n",
      "        [0.4658, 0.5000, 0.0772,  ..., 0.0000, 0.3980, 0.9512]])\n",
      "Batch labels:  tensor([0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "        0., 1., 0., 1., 0., 0., 0., 1., 0., 0.])\n",
      "Batch sensitive features:  tensor([1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
      "        0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1.,\n",
      "        0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1.,\n",
      "        0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 1., 1., 1.])\n",
      "Batch inputs:  tensor([[0.4384, 0.5000, 0.0078,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        [0.1918, 0.5000, 0.3376,  ..., 0.0000, 0.4490, 0.6341],\n",
      "        [0.1644, 0.5000, 0.0921,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        ...,\n",
      "        [0.3151, 0.5000, 0.0728,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        [0.2877, 0.7500, 0.0699,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        [0.4658, 0.5000, 0.0841,  ..., 0.0000, 0.3776, 0.9512]])\n",
      "Batch labels:  tensor([0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1.,\n",
      "        0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1.,\n",
      "        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Batch sensitive features:  tensor([1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0.,\n",
      "        1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 0., 1., 0., 0., 1., 0.])\n",
      "Batch inputs:  tensor([[0.5342, 0.5000, 0.1921,  ..., 0.0000, 0.4490, 0.9512],\n",
      "        [0.1644, 0.5000, 0.1761,  ..., 0.0000, 0.3980, 0.6341],\n",
      "        [0.1644, 0.7500, 0.2564,  ..., 0.0000, 0.5000, 0.9512],\n",
      "        ...,\n",
      "        [0.0548, 0.5000, 0.0925,  ..., 0.0000, 0.2449, 0.9512],\n",
      "        [0.0822, 0.5000, 0.1196,  ..., 0.0000, 0.2449, 0.9512],\n",
      "        [0.0274, 0.5000, 0.0939,  ..., 0.0000, 0.1735, 0.7317]])\n",
      "Batch labels:  tensor([1., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0.,\n",
      "        1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0.,\n",
      "        1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0.])\n",
      "Batch sensitive features:  tensor([1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,\n",
      "        1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 1., 0., 1., 1., 1., 1., 0., 1., 0.])\n",
      "Batch inputs:  tensor([[0.0822, 0.5000, 0.2010,  ..., 0.0000, 0.1939, 0.9512],\n",
      "        [0.1781, 0.5000, 0.2807,  ..., 0.0000, 0.3980, 0.6341],\n",
      "        [0.0959, 0.5000, 0.1652,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        ...,\n",
      "        [0.0274, 0.5000, 0.1266,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        [0.3014, 0.6250, 0.1054,  ..., 0.0000, 0.5000, 0.9512],\n",
      "        [0.0137, 0.5000, 0.2117,  ..., 0.0000, 0.1939, 0.9512]])\n",
      "Batch labels:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "        0., 1., 0., 0., 0., 1., 1., 0., 1., 0.])\n",
      "Batch sensitive features:  tensor([1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1.,\n",
      "        0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1.,\n",
      "        1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Batch inputs:  tensor([[0.3836, 0.2500, 0.1085,  ..., 0.0000, 0.6020, 0.9512],\n",
      "        [0.3288, 0.5000, 0.1762,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        [0.4384, 0.5000, 0.1169,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        ...,\n",
      "        [0.3973, 0.5000, 0.1017,  ..., 0.0000, 0.4286, 0.9512],\n",
      "        [0.2603, 0.5000, 0.1704,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        [0.1918, 0.5000, 0.0678,  ..., 0.0000, 0.3980, 0.9512]])\n",
      "Batch labels:  tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0.])\n",
      "Batch sensitive features:  tensor([0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
      "        0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1.,\n",
      "        0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 1.,\n",
      "        1., 1., 1., 0., 1., 1., 0., 0., 0., 1.])\n",
      "Batch inputs:  tensor([[0.3014, 0.5000, 0.0944,  ..., 0.0000, 0.3469, 0.9512],\n",
      "        [0.3562, 0.1250, 0.1353,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        [0.2466, 0.5000, 0.1653,  ..., 0.0000, 0.2653, 0.9512],\n",
      "        ...,\n",
      "        [0.3425, 0.5000, 0.0149,  ..., 0.0000, 0.5000, 0.9512],\n",
      "        [0.2466, 0.8750, 0.1088,  ..., 0.0000, 0.4490, 0.9512],\n",
      "        [0.5205, 0.5000, 0.1205,  ..., 0.0000, 0.3980, 0.9512]])\n",
      "Batch labels:  tensor([0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 1., 0., 0., 1., 0., 1.])\n",
      "Batch sensitive features:  tensor([0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1.,\n",
      "        1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1.,\n",
      "        1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1.,\n",
      "        1., 0., 0., 1., 1., 0., 1., 1., 0., 1.])\n",
      "Batch inputs:  tensor([[0.1370, 0.5000, 0.1594,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        [0.3288, 0.5000, 0.1189,  ..., 0.0000, 0.4796, 0.9512],\n",
      "        [0.3973, 0.5000, 0.0669,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        ...,\n",
      "        [0.3562, 0.5000, 0.2296,  ..., 0.0000, 0.3980, 0.6341],\n",
      "        [0.2466, 0.5000, 0.0981,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        [0.1507, 0.2500, 0.0492,  ..., 0.0000, 0.3980, 0.9512]])\n",
      "Batch labels:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0.,\n",
      "        1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "        0., 1., 0., 1., 0., 0., 0., 0., 0., 0.])\n",
      "Batch sensitive features:  tensor([1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.,\n",
      "        0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0.,\n",
      "        1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0.,\n",
      "        1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1.,\n",
      "        1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0.,\n",
      "        0., 1., 1., 1., 1., 1., 0., 0., 1., 0.])\n",
      "Batch inputs:  tensor([[0.0959, 0.5000, 0.0293,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        [0.1370, 0.5000, 0.0921,  ..., 0.0000, 0.0000, 0.9512],\n",
      "        [0.4110, 0.1250, 0.1442,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        ...,\n",
      "        [0.0137, 0.5000, 0.0587,  ..., 0.0000, 0.1531, 0.9512],\n",
      "        [0.4110, 0.5000, 0.0917,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        [0.2740, 0.5000, 0.1442,  ..., 0.0000, 0.3980, 0.9512]])\n",
      "Batch labels:  tensor([0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1.,\n",
      "        0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 0.])\n",
      "Batch sensitive features:  tensor([1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 0.,\n",
      "        1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.,\n",
      "        1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 1., 0., 0., 0., 1., 1.])\n",
      "Batch inputs:  tensor([[0.3425, 0.2500, 0.1125,  ..., 0.0000, 0.5000, 0.0000],\n",
      "        [0.6712, 0.2500, 0.1690,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        [0.6164, 0.7500, 0.2092,  ..., 0.0000, 0.4796, 0.9512],\n",
      "        ...,\n",
      "        [0.0959, 0.0000, 0.2473,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        [0.4932, 0.5000, 0.0575,  ..., 0.0000, 0.4592, 0.9512],\n",
      "        [0.4110, 0.7500, 0.0645,  ..., 0.0000, 0.3469, 0.9512]])\n",
      "Batch labels:  tensor([0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
      "        1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        1., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
      "        1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 1.])\n",
      "Batch sensitive features:  tensor([1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1.,\n",
      "        0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0.,\n",
      "        1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 1., 1., 0., 1., 1., 1.])\n",
      "Batch inputs:  tensor([[0.2055, 0.5000, 0.1511,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        [0.6027, 0.5000, 0.0095,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        [0.1370, 0.5000, 0.4019,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        ...,\n",
      "        [0.2192, 0.5000, 0.1307,  ..., 0.0000, 0.4388, 0.9512],\n",
      "        [0.3973, 0.5000, 0.0739,  ..., 0.0000, 0.5000, 0.9512],\n",
      "        [0.4384, 0.6250, 0.0662,  ..., 0.0000, 0.3163, 0.9512]])\n",
      "Batch labels:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0.,\n",
      "        0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 0., 1., 0.])\n",
      "Batch sensitive features:  tensor([1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0.,\n",
      "        1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1.,\n",
      "        0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1.,\n",
      "        1., 1., 1., 1., 1., 0., 1., 1., 1., 0.])\n",
      "Batch inputs:  tensor([[0.2877, 0.7500, 0.2348,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        [0.4658, 0.1250, 0.1395,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        [0.2603, 0.5000, 0.2590,  ..., 0.0000, 0.5000, 0.9512],\n",
      "        ...,\n",
      "        [0.3562, 0.5000, 0.1100,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        [0.0548, 0.0000, 0.1505,  ..., 0.0000, 0.2347, 0.9512],\n",
      "        [0.6164, 0.5000, 0.0391,  ..., 0.0000, 0.5000, 0.9512]])\n",
      "Batch labels:  tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0.,\n",
      "        0., 1., 0., 0., 0., 0., 1., 0., 0., 1.])\n",
      "Batch sensitive features:  tensor([1., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0.,\n",
      "        1., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,\n",
      "        0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,\n",
      "        1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 0., 0., 1.])\n",
      "Batch inputs:  tensor([[0.3425, 0.5000, 0.1416,  ..., 0.0000, 0.3980, 0.7561],\n",
      "        [0.2740, 0.5000, 0.1902,  ..., 0.0000, 0.5000, 0.0000],\n",
      "        [0.6164, 0.2500, 0.0945,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        ...,\n",
      "        [0.5205, 0.5000, 0.1269,  ..., 0.0000, 0.4184, 0.9512],\n",
      "        [0.5342, 0.5000, 0.1103,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        [0.1781, 0.5000, 0.0976,  ..., 0.0000, 0.3980, 0.9512]])\n",
      "Batch labels:  tensor([0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 1., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "        1., 0., 0., 1., 0., 0., 0., 1., 0., 0.])\n",
      "Batch sensitive features:  tensor([1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0.,\n",
      "        1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1.,\n",
      "        0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1.,\n",
      "        1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0.,\n",
      "        1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 1., 1., 0.])\n",
      "Batch inputs:  tensor([[0.6301, 0.5000, 0.0596,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        [0.1644, 0.5000, 0.0654,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        [0.4521, 0.2500, 0.1415,  ..., 0.0000, 0.5000, 0.9512],\n",
      "        ...,\n",
      "        [0.5753, 0.5000, 0.1420,  ..., 0.0000, 0.3980, 0.7317],\n",
      "        [0.2877, 0.7500, 0.1540,  ..., 0.0000, 0.5000, 0.9512],\n",
      "        [0.1096, 0.5000, 0.1219,  ..., 0.0000, 0.3980, 0.9512]])\n",
      "Batch labels:  tensor([0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1.,\n",
      "        0., 0., 1., 0., 0., 1., 0., 0., 1., 0.])\n",
      "Batch sensitive features:  tensor([1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0.,\n",
      "        0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,\n",
      "        1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1.,\n",
      "        0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0.,\n",
      "        0., 1., 1., 1., 1., 1., 0., 0., 1., 0.])\n",
      "Batch inputs:  tensor([[0.0685, 0.5000, 0.1518,  ..., 0.0000, 0.4490, 0.9512],\n",
      "        [0.2740, 0.5000, 0.2117,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        [0.2192, 0.6250, 0.0861,  ..., 0.0000, 0.8469, 0.8780],\n",
      "        ...,\n",
      "        [0.3562, 0.5000, 0.1535,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        [0.3562, 0.5000, 0.1349,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        [0.0137, 0.5000, 0.1725,  ..., 0.0000, 0.3469, 0.9512]])\n",
      "Batch labels:  tensor([0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 1., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 0., 1., 0., 0., 1., 0.])\n",
      "Batch sensitive features:  tensor([0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1.,\n",
      "        0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1.,\n",
      "        0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1.,\n",
      "        1., 1., 1., 1., 1., 0., 1., 1., 0., 0.])\n",
      "Batch inputs:  tensor([[0.2877, 0.5000, 0.2093,  ..., 0.0000, 0.3980, 0.0000],\n",
      "        [0.0548, 0.8750, 0.1948,  ..., 0.0000, 0.1429, 0.9512],\n",
      "        [0.0959, 0.5000, 0.2292,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        ...,\n",
      "        [0.0685, 0.5000, 0.2108,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        [0.0822, 0.7500, 0.1836,  ..., 0.0000, 0.6020, 0.9512],\n",
      "        [0.4795, 0.5000, 0.0788,  ..., 0.0000, 0.1327, 0.9512]])\n",
      "Batch labels:  tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0.,\n",
      "        0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
      "        0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
      "        1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 0.])\n",
      "Batch sensitive features:  tensor([1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1.,\n",
      "        0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1.,\n",
      "        0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 0., 1., 1., 1., 0., 1., 1., 1., 1.])\n",
      "Batch inputs:  tensor([[0.1370, 0.1250, 0.1796,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        [0.3014, 0.5000, 0.0712,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        [0.1096, 0.5000, 0.1776,  ..., 0.0000, 0.3673, 0.9512],\n",
      "        ...,\n",
      "        [0.3562, 0.1250, 0.1866,  ..., 0.0000, 0.3469, 0.9512],\n",
      "        [0.3151, 0.5000, 0.0291,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        [0.5753, 0.5000, 0.1061,  ..., 0.0000, 0.5000, 0.9512]])\n",
      "Batch labels:  tensor([1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0.,\n",
      "        1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0.,\n",
      "        0., 0., 1., 0., 0., 0., 1., 1., 0., 0.])\n",
      "Batch sensitive features:  tensor([1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 0.,\n",
      "        1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1.,\n",
      "        0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 0., 1.])\n",
      "Batch inputs:  tensor([[0.0274, 0.8750, 0.1039,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        [0.1918, 0.7500, 0.0141,  ..., 0.0000, 0.4490, 0.2195],\n",
      "        [0.6712, 0.5000, 0.1392,  ..., 0.0000, 0.0918, 0.9512],\n",
      "        ...,\n",
      "        [0.1233, 0.5000, 0.2347,  ..., 0.0000, 0.1429, 0.9512],\n",
      "        [0.5068, 0.7500, 0.0981,  ..., 0.0000, 0.5000, 0.9512],\n",
      "        [0.0411, 0.5000, 0.0540,  ..., 0.0000, 0.0714, 0.9512]])\n",
      "Batch labels:  tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1.,\n",
      "        1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.,\n",
      "        0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
      "        1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 1., 1., 0., 1., 0., 1., 0., 0., 0.])\n",
      "Batch sensitive features:  tensor([0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1.,\n",
      "        1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1.,\n",
      "        1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,\n",
      "        0., 0., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 0., 1., 0.])\n",
      "Batch inputs:  tensor([[0.2877, 0.8750, 0.0652,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        [0.3288, 0.7500, 0.1298,  ..., 0.0000, 0.1429, 0.9512],\n",
      "        [0.2192, 0.5000, 0.0998,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        ...,\n",
      "        [0.0411, 0.5000, 0.1787,  ..., 0.0000, 0.2449, 0.9512],\n",
      "        [0.0274, 0.2500, 0.1345,  ..., 0.3951, 0.2959, 0.9512],\n",
      "        [0.2603, 0.5000, 0.0731,  ..., 0.0000, 0.3469, 0.9512]])\n",
      "Batch labels:  tensor([0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
      "        0., 1., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Batch sensitive features:  tensor([0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0.,\n",
      "        0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1.,\n",
      "        0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,\n",
      "        1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1.,\n",
      "        1., 1., 0., 1., 1., 1., 1., 0., 0., 0.])\n",
      "Batch inputs:  tensor([[0.5068, 0.5000, 0.1852,  ..., 0.0000, 0.4286, 0.5366],\n",
      "        [0.1096, 0.5000, 0.0743,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        [0.4795, 0.5000, 0.0372,  ..., 0.0000, 0.4388, 0.9512],\n",
      "        ...,\n",
      "        [0.3836, 0.8750, 0.0801,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        [0.0959, 0.5000, 0.0390,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        [0.0959, 0.5000, 0.0617,  ..., 0.0000, 0.3980, 0.9512]])\n",
      "Batch labels:  tensor([0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 1., 0.,\n",
      "        0., 0., 0., 1., 1., 0., 0., 0., 0., 0.])\n",
      "Batch sensitive features:  tensor([0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1.,\n",
      "        0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
      "        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
      "        0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 0., 0., 1., 0.])\n",
      "Batch inputs:  tensor([[0.2466, 0.6250, 0.1186,  ..., 0.0000, 0.5000, 0.9512],\n",
      "        [0.0137, 0.5000, 0.1206,  ..., 0.0000, 0.2347, 0.9512],\n",
      "        [0.0548, 0.5000, 0.0776,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        ...,\n",
      "        [0.2329, 0.5000, 0.1763,  ..., 0.3997, 0.4490, 0.9512],\n",
      "        [0.2877, 0.0000, 0.0559,  ..., 0.0000, 0.5000, 0.0000],\n",
      "        [0.2192, 0.2500, 0.1907,  ..., 0.0000, 0.3980, 0.0000]])\n",
      "Batch labels:  tensor([1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0.,\n",
      "        1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0.,\n",
      "        0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 1., 0.])\n",
      "Batch sensitive features:  tensor([1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 1.,\n",
      "        0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1.,\n",
      "        1., 1., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0.,\n",
      "        1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1.,\n",
      "        0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
      "        1., 1., 0., 0., 0., 1., 1., 0., 0., 1.])\n",
      "Batch inputs:  tensor([[0.0411, 0.5000, 0.1616,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        [0.4658, 0.5000, 0.2039,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        [0.3699, 0.6250, 0.0957,  ..., 0.0000, 0.5204, 0.9512],\n",
      "        ...,\n",
      "        [0.2877, 0.5000, 0.1434,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        [0.3014, 0.5000, 0.0878,  ..., 0.5611, 0.4490, 0.9512],\n",
      "        [0.3288, 0.5000, 0.2799,  ..., 0.0000, 0.4490, 0.9512]])\n",
      "Batch labels:  tensor([0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 0.,\n",
      "        1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 1.])\n",
      "Batch sensitive features:  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1.,\n",
      "        1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0.,\n",
      "        0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0.,\n",
      "        0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0.,\n",
      "        1., 1., 1., 1., 1., 0., 1., 1., 1., 1.])\n",
      "Batch inputs:  tensor([[0.3151, 0.5000, 0.1403,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        [0.6027, 0.5000, 0.0997,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        [0.0959, 0.5000, 0.0747,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        ...,\n",
      "        [0.3014, 0.7500, 0.1623,  ..., 0.0000, 0.3980, 0.1220],\n",
      "        [0.1918, 0.5000, 0.1525,  ..., 0.0000, 0.6020, 0.9512],\n",
      "        [0.1233, 0.5000, 0.0822,  ..., 0.0000, 0.4184, 0.9512]])\n",
      "Batch labels:  tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
      "        0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0.])\n",
      "Batch sensitive features:  tensor([0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0.,\n",
      "        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0.,\n",
      "        1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1.,\n",
      "        1., 1., 1., 0., 1., 1., 0., 1., 1., 1.])\n",
      "Batch inputs:  tensor([[0.4247, 0.2500, 0.0610,  ..., 0.0000, 0.3469, 0.9512],\n",
      "        [0.2877, 0.5000, 0.0998,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        [0.3014, 0.8750, 0.1543,  ..., 0.0000, 0.5000, 0.9512],\n",
      "        ...,\n",
      "        [0.4247, 0.5000, 0.0096,  ..., 0.0000, 0.1939, 0.9512],\n",
      "        [0.3425, 0.7500, 0.0457,  ..., 0.0000, 0.5510, 0.9512],\n",
      "        [0.1370, 0.0000, 0.1823,  ..., 0.0000, 0.3980, 0.9512]])\n",
      "Batch labels:  tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1.,\n",
      "        0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
      "        1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 0., 1., 0.])\n",
      "Batch sensitive features:  tensor([0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.,\n",
      "        1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0.,\n",
      "        1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
      "        0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1.,\n",
      "        0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0.,\n",
      "        1., 1., 0., 1., 1., 0., 0., 0., 1., 0.])\n",
      "Batch inputs:  tensor([[0.0685, 0.5000, 0.1200,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        [0.3699, 0.5000, 0.1288,  ..., 0.0000, 0.3469, 0.9512],\n",
      "        [0.0822, 0.5000, 0.1006,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        ...,\n",
      "        [0.2877, 0.5000, 0.1512,  ..., 0.0000, 0.2959, 0.6341],\n",
      "        [0.2055, 0.8750, 0.2634,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        [0.2329, 0.5000, 0.1263,  ..., 0.0000, 0.3980, 0.9512]])\n",
      "Batch labels:  tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1.,\n",
      "        0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0.,\n",
      "        0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
      "        0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 0.])\n",
      "Batch sensitive features:  tensor([1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1.,\n",
      "        1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1.,\n",
      "        1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0.,\n",
      "        0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1.,\n",
      "        0., 0., 0., 1., 1., 1., 1., 1., 1., 0.])\n",
      "Batch inputs:  tensor([[0.1644, 0.6250, 0.0765,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        [0.0548, 0.5000, 0.1040,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        [0.2740, 0.5000, 0.1584,  ..., 0.0000, 0.3980, 0.0000],\n",
      "        ...,\n",
      "        [0.2740, 0.5000, 0.1086,  ..., 0.0000, 0.2959, 0.9512],\n",
      "        [0.3014, 0.5000, 0.0252,  ..., 0.3168, 0.3980, 0.9512],\n",
      "        [0.3699, 0.2500, 0.0141,  ..., 0.0000, 0.5510, 0.9512]])\n",
      "Batch labels:  tensor([0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.,\n",
      "        0., 1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Batch sensitive features:  tensor([0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 1.,\n",
      "        1., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0.,\n",
      "        1., 0., 1., 0., 1., 1., 0., 0., 0., 1.])\n",
      "Batch inputs:  tensor([[0.0959, 0.5000, 0.0740,  ..., 0.0000, 0.5000, 0.9512],\n",
      "        [0.0685, 0.5000, 0.1993,  ..., 0.0000, 0.4490, 0.0488],\n",
      "        [0.3562, 0.5000, 0.0959,  ..., 0.0000, 0.5000, 0.9512],\n",
      "        ...,\n",
      "        [0.5068, 0.7500, 0.0317,  ..., 0.3625, 0.4796, 0.9512],\n",
      "        [0.1096, 0.5000, 0.1089,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        [0.2055, 0.5000, 0.1575,  ..., 0.0000, 0.0918, 0.9512]])\n",
      "Batch labels:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1.,\n",
      "        0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0.,\n",
      "        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
      "        0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Batch sensitive features:  tensor([1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1.,\n",
      "        0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,\n",
      "        1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0.,\n",
      "        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0.,\n",
      "        0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0.,\n",
      "        1., 1., 1., 0., 1., 0., 0., 1., 0., 1.])\n",
      "Batch inputs:  tensor([[0.5753, 0.2500, 0.0612,  ..., 0.0000, 0.4490, 0.9512],\n",
      "        [0.1096, 0.5000, 0.1199,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        [0.3699, 0.5000, 0.0917,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        ...,\n",
      "        [0.6027, 0.0000, 0.0607,  ..., 0.0000, 0.2449, 0.9512],\n",
      "        [0.3014, 0.5000, 0.1937,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        [0.0411, 0.5000, 0.2487,  ..., 0.0000, 0.2449, 0.9512]])\n",
      "Batch labels:  tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1.,\n",
      "        0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 0., 0., 1., 1., 1., 0.])\n",
      "Batch sensitive features:  tensor([0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0.,\n",
      "        1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1.,\n",
      "        1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0.,\n",
      "        1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1.,\n",
      "        0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0.,\n",
      "        1., 1., 1., 1., 0., 1., 1., 1., 1., 1.])\n",
      "Batch inputs:  tensor([[0.4247, 0.5000, 0.1102,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        [0.3288, 0.5000, 0.1069,  ..., 0.0000, 0.3980, 0.0000],\n",
      "        [0.2740, 0.5000, 0.1199,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        ...,\n",
      "        [0.2877, 0.5000, 0.1768,  ..., 0.0000, 0.5000, 0.9512],\n",
      "        [0.3288, 0.2500, 0.3236,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        [0.2192, 0.5000, 0.0957,  ..., 0.0000, 0.3980, 0.9512]])\n",
      "Batch labels:  tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
      "        1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0.])\n",
      "Batch sensitive features:  tensor([1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1.,\n",
      "        1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1.,\n",
      "        1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1.,\n",
      "        1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1.,\n",
      "        1., 0., 1., 0., 0., 1., 1., 1., 1., 1.])\n",
      "Batch inputs:  tensor([[0.3288, 0.5000, 0.1221,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        [0.3836, 0.2500, 0.1523,  ..., 0.0000, 0.5510, 0.9512],\n",
      "        [0.2877, 0.7500, 0.0281,  ..., 0.0000, 0.3469, 0.9512],\n",
      "        ...,\n",
      "        [0.5479, 0.5000, 0.0836,  ..., 0.0000, 0.3980, 0.7317],\n",
      "        [0.2466, 0.5000, 0.0127,  ..., 0.0000, 0.4490, 0.9512],\n",
      "        [0.4795, 0.2500, 0.1192,  ..., 0.0000, 0.3571, 0.9512]])\n",
      "Batch labels:  tensor([0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 0., 1.])\n",
      "Batch sensitive features:  tensor([1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,\n",
      "        0., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
      "        1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0.,\n",
      "        0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1.,\n",
      "        1., 1., 0., 1., 1., 1., 1., 1., 1., 1.])\n",
      "Batch inputs:  tensor([[0.0137, 0.5000, 0.0735,  ..., 0.0000, 0.1429, 0.9512],\n",
      "        [0.3014, 0.2500, 0.0686,  ..., 0.0000, 0.5000, 0.9512],\n",
      "        [0.7808, 0.7500, 0.1269,  ..., 0.0000, 0.0714, 0.2683],\n",
      "        ...,\n",
      "        [0.3973, 0.0000, 0.1818,  ..., 0.0000, 0.3980, 0.6341],\n",
      "        [0.2603, 0.5000, 0.0522,  ..., 0.0000, 0.5000, 0.9512],\n",
      "        [0.0959, 0.5000, 0.1348,  ..., 0.0000, 0.3980, 0.2439]])\n",
      "Batch labels:  tensor([0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1.,\n",
      "        0., 0., 1., 0., 0., 0., 1., 0., 0., 0.])\n",
      "Batch sensitive features:  tensor([1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1.,\n",
      "        0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1.,\n",
      "        1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,\n",
      "        1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 0., 1., 1., 1., 0.])\n",
      "Batch inputs:  tensor([[0.4110, 0.0000, 0.2169,  ..., 0.0000, 0.0714, 0.9512],\n",
      "        [0.0548, 0.0000, 0.2332,  ..., 0.0000, 0.0918, 0.9512],\n",
      "        [0.1370, 0.5000, 0.2161,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        ...,\n",
      "        [0.4384, 0.5000, 0.0557,  ..., 0.0000, 0.6020, 0.9512],\n",
      "        [0.1918, 0.5000, 0.3092,  ..., 0.4332, 0.3980, 0.9512],\n",
      "        [0.5342, 0.7500, 0.2196,  ..., 0.4332, 0.5000, 0.0488]])\n",
      "Batch labels:  tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1.,\n",
      "        0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1.,\n",
      "        1., 0., 0., 0., 0., 0., 0., 0., 1., 1.])\n",
      "Batch sensitive features:  tensor([0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1.,\n",
      "        1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.,\n",
      "        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0.,\n",
      "        0., 1., 0., 0., 0., 1., 1., 1., 1., 1.])\n",
      "Batch inputs:  tensor([[0.3151, 0.5000, 0.1064,  ..., 0.0000, 0.3163, 0.9512],\n",
      "        [0.0411, 0.0000, 0.1492,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        [0.3151, 0.5000, 0.0442,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        ...,\n",
      "        [0.3014, 0.5000, 0.0394,  ..., 0.0000, 0.3980, 0.7317],\n",
      "        [0.1096, 0.5000, 0.2916,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        [0.2603, 0.5000, 0.3204,  ..., 0.0000, 0.3980, 0.9512]])\n",
      "Batch labels:  tensor([0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Batch sensitive features:  tensor([0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
      "        1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0.,\n",
      "        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 0., 0., 1., 1., 1., 1., 0., 1., 1.])\n",
      "Batch inputs:  tensor([[0.0411, 0.5000, 0.0968,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        [0.2329, 0.6250, 0.0462,  ..., 0.0000, 0.7245, 0.9512],\n",
      "        [0.0274, 0.5000, 0.1436,  ..., 0.0000, 0.2959, 0.9512],\n",
      "        ...,\n",
      "        [0.4110, 0.7500, 0.0612,  ..., 0.0000, 0.2959, 0.9512],\n",
      "        [0.3836, 0.6250, 0.0136,  ..., 0.0000, 0.5102, 0.9512],\n",
      "        [0.6438, 0.5000, 0.1420,  ..., 0.0000, 0.1122, 0.9512]])\n",
      "Batch labels:  tensor([0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0.,\n",
      "        1., 0., 1., 1., 0., 0., 0., 0., 0., 0.])\n",
      "Batch sensitive features:  tensor([0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0.,\n",
      "        1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1.,\n",
      "        0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0.,\n",
      "        1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0.,\n",
      "        1., 0., 1., 0., 0., 1., 1., 1., 1., 0.])\n",
      "Batch inputs:  tensor([[0.2192, 0.5000, 0.3648,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        [0.2055, 0.5000, 0.0760,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        [0.2603, 0.5000, 0.0526,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        ...,\n",
      "        [0.5068, 0.6250, 0.0917,  ..., 0.0000, 0.6020, 0.9512],\n",
      "        [0.1507, 0.5000, 0.1263,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        [0.2877, 0.5000, 0.2610,  ..., 0.0000, 0.3980, 0.9512]])\n",
      "Batch labels:  tensor([1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "        1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
      "        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 0., 1., 0., 1.])\n",
      "Batch sensitive features:  tensor([1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1.,\n",
      "        1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 0., 0., 1.,\n",
      "        1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1.,\n",
      "        1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1.,\n",
      "        1., 1., 0., 1., 1., 1., 1., 1., 1., 1.])\n",
      "Batch inputs:  tensor([[0.0685, 0.5000, 0.0485,  ..., 0.0000, 0.2959, 0.9512],\n",
      "        [0.1918, 0.5000, 0.3229,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        [0.6712, 0.2500, 0.0289,  ..., 0.0000, 0.1939, 0.9512],\n",
      "        ...,\n",
      "        [0.6164, 0.5000, 0.0950,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        [0.2329, 0.7500, 0.2101,  ..., 0.0000, 0.2449, 0.9512],\n",
      "        [0.1233, 0.7500, 0.0505,  ..., 0.0000, 0.4490, 0.9512]])\n",
      "Batch labels:  tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
      "        1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 0., 1., 0., 0., 0., 0., 0.])\n",
      "Batch sensitive features:  tensor([1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1.,\n",
      "        1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0.,\n",
      "        0., 1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0.,\n",
      "        0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1.,\n",
      "        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 0., 1.])\n",
      "Batch inputs:  tensor([[0.5616, 0.5000, 0.1165,  ..., 0.0000, 0.2347, 0.9512],\n",
      "        [0.6027, 0.5000, 0.4456,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        [0.2740, 0.5000, 0.2548,  ..., 0.0000, 0.3673, 0.9512],\n",
      "        ...,\n",
      "        [0.4932, 0.6250, 0.0788,  ..., 0.0000, 0.7041, 0.9512],\n",
      "        [0.0685, 0.5000, 0.1379,  ..., 0.0000, 0.3673, 0.9512],\n",
      "        [0.1233, 0.7500, 0.1025,  ..., 0.0000, 0.3980, 0.9512]])\n",
      "Batch labels:  tensor([0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 0., 0., 0., 1., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 0., 1., 0., 1., 0., 0., 1., 0., 0.])\n",
      "Batch sensitive features:  tensor([1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,\n",
      "        0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0.,\n",
      "        1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1.,\n",
      "        0., 1., 0., 1., 0., 0., 1., 1., 1., 1.])\n",
      "Batch inputs:  tensor([[0.3151, 0.5000, 0.1035,  ..., 0.0000, 0.3163, 0.9512],\n",
      "        [0.2329, 0.5000, 0.0703,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        [0.0822, 0.5000, 0.1547,  ..., 0.0000, 0.2449, 0.9512],\n",
      "        ...,\n",
      "        [0.7945, 0.5000, 0.0629,  ..., 0.0000, 0.1939, 0.9512],\n",
      "        [0.1781, 0.5000, 0.1573,  ..., 0.0000, 0.3980, 0.8537],\n",
      "        [0.5753, 0.7500, 0.1555,  ..., 0.0000, 0.3980, 0.9512]])\n",
      "Batch labels:  tensor([0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0.,\n",
      "        0., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1.,\n",
      "        0., 0., 1., 1., 0., 1., 1., 0., 0., 0.])\n",
      "Batch sensitive features:  tensor([0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1.,\n",
      "        1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0.,\n",
      "        0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,\n",
      "        0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 0., 0.])\n",
      "Batch inputs:  tensor([[0.4384, 0.5000, 0.0478,  ..., 0.0000, 0.4490, 0.9512],\n",
      "        [0.2055, 0.5000, 0.0877,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        [0.2740, 0.5000, 0.0911,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        ...,\n",
      "        [0.6849, 0.5000, 0.2200,  ..., 0.0000, 0.2347, 0.9512],\n",
      "        [0.2466, 0.8750, 0.1087,  ..., 0.0000, 0.4184, 0.9512],\n",
      "        [0.2192, 0.5000, 0.2086,  ..., 0.0000, 0.6020, 0.7073]])\n",
      "Batch labels:  tensor([0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1.,\n",
      "        0., 1., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1.,\n",
      "        0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0.])\n",
      "Batch sensitive features:  tensor([1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1.,\n",
      "        0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.,\n",
      "        0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1.,\n",
      "        1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,\n",
      "        1., 1., 0., 1., 1., 1., 0., 1., 1., 1.])\n",
      "Batch inputs:  tensor([[0.3425, 0.5000, 0.1520,  ..., 0.0000, 0.3980, 0.8049],\n",
      "        [0.4110, 0.5000, 0.1020,  ..., 0.0000, 0.4490, 0.9512],\n",
      "        [0.3151, 0.8750, 0.0942,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        ...,\n",
      "        [0.0822, 0.5000, 0.1483,  ..., 0.0000, 0.2143, 0.9512],\n",
      "        [0.2055, 0.6250, 0.2263,  ..., 0.0000, 0.5510, 0.9512],\n",
      "        [0.1644, 0.5000, 0.0727,  ..., 0.0000, 0.0918, 0.0732]])\n",
      "Batch labels:  tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0.,\n",
      "        1., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 0., 1., 1.])\n",
      "Batch sensitive features:  tensor([1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0.,\n",
      "        1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 0.])\n",
      "Batch inputs:  tensor([[0.6849, 0.5000, 0.1524,  ..., 0.0000, 0.0102, 0.9512],\n",
      "        [0.4110, 0.5000, 0.0577,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        [0.0822, 0.5000, 0.1274,  ..., 0.0000, 0.3469, 0.9512],\n",
      "        ...,\n",
      "        [0.4658, 0.5000, 0.1279,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        [0.0822, 0.5000, 0.1518,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        [0.3288, 0.5000, 0.0374,  ..., 0.0000, 0.3980, 0.9512]])\n",
      "Batch labels:  tensor([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1.,\n",
      "        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1.,\n",
      "        0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1.,\n",
      "        0., 0., 1., 0., 0., 0., 0., 0., 0., 1.])\n",
      "Batch sensitive features:  tensor([1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0.,\n",
      "        1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1.,\n",
      "        1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 0., 1., 0., 0., 0., 1., 1., 1., 1.])\n",
      "Batch inputs:  tensor([[0.4932, 0.8750, 0.1247,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        [0.1918, 0.5000, 0.2453,  ..., 0.0000, 0.4286, 0.9512],\n",
      "        [0.2055, 0.5000, 0.1553,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        ...,\n",
      "        [0.3014, 0.5000, 0.1187,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        [0.1918, 0.2500, 0.1199,  ..., 0.0000, 0.5000, 0.9512],\n",
      "        [0.0685, 0.5000, 0.2023,  ..., 0.0000, 0.3980, 0.9512]])\n",
      "Batch labels:  tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0.,\n",
      "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0.])\n",
      "Batch sensitive features:  tensor([0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1.,\n",
      "        1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1.,\n",
      "        1., 0., 0., 1., 0., 1., 0., 0., 0., 1.])\n",
      "Batch inputs:  tensor([[0.4658, 0.7500, 0.0815,  ..., 0.0000, 0.4490, 0.9512],\n",
      "        [0.2192, 0.5000, 0.1624,  ..., 0.0000, 0.5000, 0.9512],\n",
      "        [0.3562, 0.7500, 0.0800,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        ...,\n",
      "        [0.0411, 0.5000, 0.1516,  ..., 0.0000, 0.3469, 0.9512],\n",
      "        [0.1370, 0.5000, 0.1737,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        [0.5342, 0.5000, 0.0586,  ..., 0.0000, 0.3980, 0.9512]])\n",
      "Batch labels:  tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0.,\n",
      "        1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 0., 0., 0., 0.])\n",
      "Batch sensitive features:  tensor([1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1.,\n",
      "        0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1.,\n",
      "        1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0.,\n",
      "        1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0.,\n",
      "        1., 1., 0., 0., 1., 1., 0., 1., 1., 1.])\n",
      "Batch inputs:  tensor([[0.6438, 0.2500, 0.0259,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        [0.4384, 0.8750, 0.2324,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        [0.2329, 0.5000, 0.0258,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        ...,\n",
      "        [0.1370, 0.5000, 0.0258,  ..., 0.0000, 0.4796, 0.9512],\n",
      "        [0.3562, 0.5000, 0.0324,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        [0.1507, 0.5000, 0.0935,  ..., 0.0000, 0.3980, 0.0000]])\n",
      "Batch labels:  tensor([0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
      "        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0.,\n",
      "        0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0.,\n",
      "        0., 0., 1., 0., 0., 0., 0., 0., 1., 0.])\n",
      "Batch sensitive features:  tensor([1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0.,\n",
      "        1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0.,\n",
      "        0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,\n",
      "        0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 1., 1., 1.])\n",
      "Batch inputs:  tensor([[0.5753, 0.5000, 0.2009,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        [0.3425, 0.5000, 0.0580,  ..., 0.0000, 0.4694, 0.9512],\n",
      "        [0.6849, 0.5000, 0.2080,  ..., 0.0000, 0.3469, 0.9512],\n",
      "        ...,\n",
      "        [0.0411, 0.1250, 0.0292,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        [0.1644, 0.5000, 0.1127,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        [0.5342, 0.2500, 0.1735,  ..., 0.0000, 0.3980, 0.9512]])\n",
      "Batch labels:  tensor([1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
      "        1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Batch sensitive features:  tensor([0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1.,\n",
      "        1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1.,\n",
      "        1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,\n",
      "        0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0.,\n",
      "        0., 0., 1., 1., 1., 1., 0., 0., 1., 1.])\n",
      "Batch inputs:  tensor([[0.2329, 0.8750, 0.1206,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        [0.3836, 0.5000, 0.0707,  ..., 0.0000, 0.3469, 0.9512],\n",
      "        [0.0685, 0.5000, 0.1202,  ..., 0.0000, 0.5000, 0.9512],\n",
      "        ...,\n",
      "        [0.2329, 0.8750, 0.0303,  ..., 0.0000, 0.5000, 0.9512],\n",
      "        [0.0822, 0.5000, 0.1106,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        [0.1233, 0.5000, 0.1819,  ..., 0.0000, 0.3980, 0.9512]])\n",
      "Batch labels:  tensor([0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1.,\n",
      "        0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
      "        0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0.])\n",
      "Batch sensitive features:  tensor([1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1.,\n",
      "        1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1.,\n",
      "        1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0., 0.,\n",
      "        1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0.,\n",
      "        0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1.,\n",
      "        0., 0., 0., 1., 1., 0., 0., 0., 0., 1.])\n",
      "Batch inputs:  tensor([[0.2466, 0.5000, 0.2147,  ..., 0.0000, 0.3980, 0.6341],\n",
      "        [0.1644, 0.8750, 0.1737,  ..., 0.0000, 0.5000, 0.9512],\n",
      "        [0.6301, 0.5000, 0.0369,  ..., 0.0000, 0.1531, 0.9512],\n",
      "        ...,\n",
      "        [0.1370, 0.5000, 0.1387,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        [0.1233, 0.5000, 0.0630,  ..., 0.0000, 0.1939, 0.9512],\n",
      "        [0.0274, 0.5000, 0.2705,  ..., 0.0000, 0.3980, 0.9512]])\n",
      "Batch labels:  tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "        1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Batch sensitive features:  tensor([1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1.,\n",
      "        0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1.,\n",
      "        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0.,\n",
      "        0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 0., 1., 0.])\n",
      "Batch inputs:  tensor([[0.4795, 0.7500, 0.1209,  ..., 0.0000, 0.2449, 0.9512],\n",
      "        [0.0548, 0.5000, 0.2169,  ..., 0.0000, 0.5000, 0.9512],\n",
      "        [0.3973, 0.5000, 0.1138,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        ...,\n",
      "        [0.0959, 0.0000, 0.0901,  ..., 0.0000, 0.3980, 0.9512],\n",
      "        [0.0000, 0.5000, 0.1375,  ..., 0.0000, 0.2449, 0.9512],\n",
      "        [0.0959, 0.5000, 0.2758,  ..., 0.0000, 0.3980, 0.9512]])\n",
      "Batch labels:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1.,\n",
      "        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 1., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Batch sensitive features:  tensor([1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1.,\n",
      "        0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.,\n",
      "        0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0.,\n",
      "        1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0.,\n",
      "        0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 0., 1.])\n",
      "Batch inputs:  tensor([[0.2192, 0.5000, 0.1643, 0.7333, 0.5333, 0.6667, 0.0714, 0.2000, 1.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.3980, 0.9512],\n",
      "        [0.3973, 0.2500, 0.1327, 0.6000, 0.8000, 0.3333, 0.7857, 0.0000, 1.0000,\n",
      "         1.0000, 0.0000, 0.0000, 0.3980, 0.9512],\n",
      "        [0.1781, 0.5000, 0.1164, 0.7333, 0.5333, 0.3333, 0.8571, 0.0000, 1.0000,\n",
      "         1.0000, 0.0000, 0.0000, 0.4490, 0.9512],\n",
      "        [0.4384, 0.5000, 0.0756, 0.0667, 0.4000, 0.3333, 1.0000, 0.0000, 1.0000,\n",
      "         1.0000, 0.0000, 0.0000, 0.7551, 0.9512],\n",
      "        [0.1781, 0.2500, 0.2436, 0.8000, 0.8667, 0.6667, 0.7143, 0.2000, 1.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.3980, 0.9512],\n",
      "        [0.3836, 0.7500, 0.0110, 0.6000, 0.8000, 0.3333, 0.3571, 0.0000, 1.0000,\n",
      "         1.0000, 0.0000, 0.3409, 0.7041, 0.9512],\n",
      "        [0.4247, 0.8750, 0.1072, 0.8000, 0.8667, 0.0000, 0.7143, 0.2000, 1.0000,\n",
      "         1.0000, 0.0000, 0.0000, 0.3980, 0.9512],\n",
      "        [0.2740, 0.5000, 0.1809, 0.7333, 0.5333, 0.3333, 0.5000, 0.0000, 1.0000,\n",
      "         1.0000, 0.0000, 0.0000, 0.6020, 0.9512],\n",
      "        [0.0959, 0.5000, 0.1155, 0.7333, 0.5333, 0.3333, 0.5714, 1.0000, 1.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.2449, 0.9512],\n",
      "        [0.5616, 0.2500, 0.1532, 0.6000, 0.8000, 0.3333, 0.7143, 0.0000, 1.0000,\n",
      "         1.0000, 0.0000, 0.0000, 0.5816, 0.9512],\n",
      "        [0.2055, 0.5000, 0.1083, 0.7333, 0.5333, 0.6667, 0.5000, 0.2000, 1.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.3980, 0.9512],\n",
      "        [0.1370, 0.5000, 0.1257, 0.4667, 0.7333, 0.6667, 0.7143, 0.2000, 1.0000,\n",
      "         1.0000, 0.0000, 0.0000, 0.3980, 0.9512]])\n",
      "Batch labels:  tensor([0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0.])\n",
      "Batch sensitive features:  tensor([0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1.])\n"
     ]
    }
   ],
   "source": [
    "for batch_data in dataloader['test']:\n",
    "\n",
    "    inputs, labels, sensitive = batch_data\n",
    "    print(\"Batch inputs: \", inputs)\n",
    "    print(\"Batch labels: \", labels)\n",
    "    print(\"Batch sensitive features: \", sensitive)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1            [-1, 22792, 32]             480\n",
      "         LayerNorm-2            [-1, 22792, 32]              64\n",
      "              ReLU-3            [-1, 22792, 32]               0\n",
      "            Conv1d-4            [-1, 64, 22795]             320\n",
      "              SiLU-5            [-1, 64, 22792]               0\n",
      "            Linear-6                   [-1, 66]           4,224\n",
      "            Linear-7            [-1, 22792, 32]           2,048\n",
      "             Mamba-8            [-1, 22792, 32]               0\n",
      "            Linear-9             [-1, 22792, 1]              33\n",
      "================================================================\n",
      "Total params: 7,169\n",
      "Trainable params: 7,169\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 1.22\n",
      "Forward/backward pass size (MB): 50.26\n",
      "Params size (MB): 0.03\n",
      "Estimated Total Size (MB): 51.50\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model, x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1000 [00:01<19:55,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/config['EPOCH'], loss of epoch: 17.769164711236954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/1000 [00:02<19:17,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/config['EPOCH'], loss of epoch: 15.35576856136322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/1000 [00:03<18:59,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/config['EPOCH'], loss of epoch: 14.282690972089767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/1000 [00:04<18:39,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/config['EPOCH'], loss of epoch: 13.630553483963013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/1000 [00:05<18:42,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/config['EPOCH'], loss of epoch: 13.332520961761475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 6/1000 [00:06<18:39,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/config['EPOCH'], loss of epoch: 12.920447587966919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 7/1000 [00:07<18:43,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/config['EPOCH'], loss of epoch: 12.691672950983047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 8/1000 [00:09<18:36,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/config['EPOCH'], loss of epoch: 12.493073672056198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 9/1000 [00:10<18:32,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/config['EPOCH'], loss of epoch: 12.345839977264404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1000 [00:11<18:36,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/config['EPOCH'], loss of epoch: 12.190184563398361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 11/1000 [00:12<18:36,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/config['EPOCH'], loss of epoch: 12.235721856355667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 12/1000 [00:13<18:42,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/config['EPOCH'], loss of epoch: 12.102530807256699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 13/1000 [00:14<18:54,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/config['EPOCH'], loss of epoch: 11.892494916915894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 14/1000 [00:15<18:54,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/config['EPOCH'], loss of epoch: 11.896155446767807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 15/1000 [00:17<18:44,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/config['EPOCH'], loss of epoch: 11.786630615592003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 16/1000 [00:18<18:40,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/config['EPOCH'], loss of epoch: 11.756490260362625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 17/1000 [00:19<18:36,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/config['EPOCH'], loss of epoch: 11.64432530105114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 18/1000 [00:20<18:26,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/config['EPOCH'], loss of epoch: 11.643199846148491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 19/1000 [00:21<18:24,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/config['EPOCH'], loss of epoch: 11.542551413178444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 20/1000 [00:22<18:29,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/config['EPOCH'], loss of epoch: 11.492808148264885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 21/1000 [00:23<18:26,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/config['EPOCH'], loss of epoch: 11.448875144124031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 22/1000 [00:24<18:11,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/config['EPOCH'], loss of epoch: 11.466156601905823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 23/1000 [00:26<18:11,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/config['EPOCH'], loss of epoch: 11.40346945822239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 24/1000 [00:27<18:06,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/config['EPOCH'], loss of epoch: 11.413935884833336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▎         | 25/1000 [00:28<18:03,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/config['EPOCH'], loss of epoch: 11.404731273651123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 26/1000 [00:29<18:04,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/config['EPOCH'], loss of epoch: 11.34216271340847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 27/1000 [00:30<18:01,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/config['EPOCH'], loss of epoch: 11.350034102797508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 28/1000 [00:31<17:57,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/config['EPOCH'], loss of epoch: 11.279611125588417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 29/1000 [00:32<17:58,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/config['EPOCH'], loss of epoch: 11.318166300654411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 30/1000 [00:33<17:48,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/config['EPOCH'], loss of epoch: 11.256501272320747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 31/1000 [00:34<17:59,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/config['EPOCH'], loss of epoch: 11.234853848814964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 32/1000 [00:36<18:05,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/config['EPOCH'], loss of epoch: 11.209640473127365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 33/1000 [00:37<18:10,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/config['EPOCH'], loss of epoch: 11.188303589820862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 34/1000 [00:38<18:00,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/config['EPOCH'], loss of epoch: 11.224361717700958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 35/1000 [00:39<17:56,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/config['EPOCH'], loss of epoch: 11.257421866059303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 36/1000 [00:40<18:02,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/config['EPOCH'], loss of epoch: 11.144161328673363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 37/1000 [00:41<17:55,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/config['EPOCH'], loss of epoch: 11.213214978575706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 38/1000 [00:42<17:47,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/config['EPOCH'], loss of epoch: 11.113940000534058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 39/1000 [00:43<17:46,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/config['EPOCH'], loss of epoch: 11.191370666027069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 40/1000 [00:44<17:53,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/config['EPOCH'], loss of epoch: 11.135790959000587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 41/1000 [00:46<17:53,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/config['EPOCH'], loss of epoch: 11.122004956007004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 42/1000 [00:47<17:48,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42/config['EPOCH'], loss of epoch: 11.073901668190956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 43/1000 [00:48<17:40,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43/config['EPOCH'], loss of epoch: 11.18762369453907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 44/1000 [00:49<17:40,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44/config['EPOCH'], loss of epoch: 11.216801807284355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 45/1000 [00:50<17:39,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45/config['EPOCH'], loss of epoch: 11.046562999486923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 46/1000 [00:51<17:41,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [46/config['EPOCH'], loss of epoch: 11.191536903381348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 47/1000 [00:52<17:41,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47/config['EPOCH'], loss of epoch: 11.057764664292336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 48/1000 [00:53<17:33,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [48/config['EPOCH'], loss of epoch: 11.058096393942833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 49/1000 [00:54<17:36,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49/config['EPOCH'], loss of epoch: 11.037525907158852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 50/1000 [00:56<17:28,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/config['EPOCH'], loss of epoch: 11.007569193840027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 51/1000 [00:57<17:40,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [51/config['EPOCH'], loss of epoch: 11.017319217324257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 52/1000 [00:58<17:51,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [52/config['EPOCH'], loss of epoch: 11.039473488926888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 53/1000 [00:59<18:05,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [53/config['EPOCH'], loss of epoch: 10.984064921736717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 54/1000 [01:00<18:02,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [54/config['EPOCH'], loss of epoch: 10.99089914560318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 55/1000 [01:01<18:01,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [55/config['EPOCH'], loss of epoch: 10.987623170018196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 56/1000 [01:03<18:11,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [56/config['EPOCH'], loss of epoch: 11.147830426692963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 57/1000 [01:04<18:08,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [57/config['EPOCH'], loss of epoch: 10.993157342076302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 58/1000 [01:05<18:07,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [58/config['EPOCH'], loss of epoch: 10.977584674954414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 59/1000 [01:06<18:07,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [59/config['EPOCH'], loss of epoch: 10.981714591383934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 60/1000 [01:07<18:13,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [60/config['EPOCH'], loss of epoch: 10.95949113368988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 61/1000 [01:08<18:09,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [61/config['EPOCH'], loss of epoch: 11.026782363653183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 62/1000 [01:09<18:10,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [62/config['EPOCH'], loss of epoch: 10.935862004756927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 63/1000 [01:11<18:04,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [63/config['EPOCH'], loss of epoch: 10.987715765833855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 64/1000 [01:12<18:08,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [64/config['EPOCH'], loss of epoch: 10.989186331629753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 65/1000 [01:13<18:09,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [65/config['EPOCH'], loss of epoch: 10.900382995605469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 66/1000 [01:14<18:09,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [66/config['EPOCH'], loss of epoch: 10.92583404481411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 67/1000 [01:15<18:13,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [67/config['EPOCH'], loss of epoch: 10.951724514365196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 68/1000 [01:16<18:10,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [68/config['EPOCH'], loss of epoch: 10.93062537908554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 69/1000 [01:18<18:00,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [69/config['EPOCH'], loss of epoch: 10.92515940964222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 70/1000 [01:19<17:32,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [70/config['EPOCH'], loss of epoch: 10.950438067317009\n",
      "training completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Train-validate the model\n",
    "model=train_model(model, config, dataloader)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test completed\n"
     ]
    }
   ],
   "source": [
    "# Test model\n",
    "all_labels, all_probs, all_sensitives = test_result(model, dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_fairness_metrics(y_true, y_pred, sensitive_attributes):\n",
    "    \n",
    "    metrics = {}\n",
    "    \n",
    "    # Demographic Parity: P(Y_pred=1 | A=0) = P(Y_pred=1 | A=1)\n",
    "    dp_0 = np.mean(y_pred[sensitive_attributes == 0])\n",
    "    dp_1 = np.mean(y_pred[sensitive_attributes == 1])\n",
    "    \n",
    "    metrics['Demographic Parity'] = abs(dp_0 - dp_1)\n",
    "    \n",
    "    # Equal Opportunity: P(Y_pred=1 | Y_true=1, A=0) = P(Y_pred=1 | Y_true=1, A=1)\n",
    "    eo_0 = np.mean(y_pred[(y_true == 1) & (sensitive_attributes == 0)])\n",
    "    eo_1 = np.mean(y_pred[(y_true == 1) & (sensitive_attributes == 1)])\n",
    "    \n",
    "    metrics['Equal Opportunity'] = abs(eo_0 - eo_1)\n",
    "    \n",
    "    # Equality of Odds: Same true positive and false positive rates for both groups\n",
    "    tp_0 = np.mean(y_pred[(y_true == 1) & (sensitive_attributes == 0)])\n",
    "    fp_0 = np.mean(y_pred[(y_true == 0) & (sensitive_attributes == 0)])\n",
    "    tp_1 = np.mean(y_pred[(y_true == 1) & (sensitive_attributes == 1)])\n",
    "    fp_1 = np.mean(y_pred[(y_true == 0) & (sensitive_attributes == 1)])\n",
    "    \n",
    "    metrics['Equality of Odds'] = abs(tp_0 - tp_1) + abs(fp_0 - fp_1)\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AUROC score:  0.9022063695016843\n",
      "\n",
      "공정성 지표\n",
      "\n",
      "Demographic Parity: 0.19244429469108582\n",
      "Equal Opportunity: 0.049435317516326904\n",
      "Equality of Odds: 0.16788774728775024\n"
     ]
    }
   ],
   "source": [
    " # AUROC 계산        \n",
    "auroc_score = roc_auc_score(all_labels, all_probs)\n",
    "print(\"\\nAUROC score: \", auroc_score)\n",
    "  \n",
    "# 공성정 지표 계산\n",
    "fairness_scores = calculate_fairness_metrics(np.array(all_labels), np.array(all_probs), np.array(all_sensitives))\n",
    "\n",
    "print(\"\\n공정성 지표\\n\")\n",
    "for metric, score in fairness_scores.items():\n",
    "    print(f\"{metric}: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ROC Curve visualization\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(all_labels, all_probs)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label=f'ROC curve (AUROC = {auroc_score:.2f})')\n",
    "plt.plot([0, 1], [0, 1], 'r--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mambatab_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
