{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bi6hi16ntj9_"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import roc_auc_score, roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8DIOYcb9twoe"
      },
      "outputs": [],
      "source": [
        "# 데이터 로딩 및 전처리를 수행하는 함수 정의\n",
        "def load_and_preprocess_data():\n",
        "    # scikit-learn의 OpenML에서 성인 인구조사 소득 데이터셋 불러오기\n",
        "    from sklearn.datasets import fetch_openml\n",
        "    data = fetch_openml(name='adult', version=1, as_frame=True)\n",
        "    df = data.frame\n",
        "\n",
        "    # 특성(features)과 목표(target) 변수 분리\n",
        "    # 'class' 열을 제외한 모든 열을 특성으로, 'class' 열을 목표 변수로 설정\n",
        "    X = df.drop('class', axis=1)\n",
        "    y = df['class']\n",
        "\n",
        "    # 열의 데이터 유형 식별\n",
        "    # 범주형(문자열) 열과 수치형(정수, 실수) 열 구분\n",
        "    categorical_columns = X.select_dtypes(include=['object']).columns\n",
        "    numerical_columns = X.select_dtypes(include=['int64', 'float64']).columns\n",
        "\n",
        "    # 데이터 전처리 단계 생성\n",
        "    # ColumnTransformer를 사용하여 수치형과 범주형 열에 대해 다른 전처리 적용\n",
        "    preprocessor = ColumnTransformer(\n",
        "        transformers=[\n",
        "            # 수치형 열 처리\n",
        "            ('num', Pipeline([\n",
        "                # 결측값을 중앙값으로 대체\n",
        "                ('imputer', SimpleImputer(strategy='median')),\n",
        "                # 표준 스케일링 (평균 0, 분산 1로 정규화)\n",
        "                ('scaler', StandardScaler())\n",
        "            ]), numerical_columns),\n",
        "\n",
        "            # 범주형 열 처리\n",
        "            ('cat', Pipeline([\n",
        "                # 결측값을 'missing' 문자열로 대체\n",
        "                ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
        "                # 원핫 인코딩 (범주형 변수를 이진 벡터로 변환)\n",
        "                ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "            ]), categorical_columns)\n",
        "        ])\n",
        "\n",
        "    # 특성 데이터 전처리 수행\n",
        "    # 앞서 정의한 전처리기를 사용하여 데이터 변환\n",
        "    X_processed = preprocessor.fit_transform(X)\n",
        "\n",
        "    # 목표 변수 인코딩\n",
        "    # LabelEncoder를 사용하여 문자열 레이블을 숫자로 변환\n",
        "    le = LabelEncoder()\n",
        "    y_processed = le.fit_transform(y)\n",
        "\n",
        "    # 전처리된 특성, 목표 변수, 그리고 전처리기 반환\n",
        "    return X_processed, y_processed, preprocessor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nf0QRVGgt1di"
      },
      "outputs": [],
      "source": [
        "# Column-wise Interaction Module\n",
        "# 컬럼 간 상호작용을 학습하는 신경망 모듈 클래스 정의\n",
        "# 이 클래스는 입력 특성들 사이의 상호작용을 학습하고 새로운 특성을 생성함\n",
        "class ColumnWiseInteraction(nn.Module):\n",
        "    # 모듈 초기화 메서드\n",
        "    def __init__(self, input_dim):                                                      # input_dim: 입력 데이터의 특성(컬럼) 차원 수\n",
        "        super().__init__()                                                              # 부모 클래스(nn.Module)의 초기화 메서드 호출\n",
        "\n",
        "        self.interaction_weights = nn.Parameter(torch.randn(input_dim, input_dim))      # 상호작용 가중치 행렬 생성\n",
        "                                                                                        # 무작위로 초기화된 input_dim x input_dim 크기의 학습 가능한 파라미터 생성\n",
        "                                                                                        # 이 가중치는 각 특성 간의 상호작용을 모델링하는 데 사용됨\n",
        "\n",
        "    # 순전파(forward) 메서드 정의\n",
        "    def forward(self, x):                                                               # 입력 텐서 x에 대해 컬럼 간 상호작용을 계산하고 새로운 특성을 추가\n",
        "        # Compute column-wise interactions\n",
        "        interactions = torch.matmul(x, self.interaction_weights)                        # 입력 텐서와 상호작용 가중치 행렬의 행렬 곱 계산\n",
        "                                                                                        # 각 특성이 다른 특성들과 어떻게 상호작용하는지를 학습\n",
        "                                                                                        # 예: x의 각 컬럼이 다른 모든 컬럼에 대해 가중치 기반 상호작용 계산\n",
        "\n",
        "        return torch.cat([x, interactions], dim=1)                                      # 원본 입력 텐서와 상호작용 텐서를 특성(컬럼) 차원에서 결합\n",
        "                                                                                        # 결과: 원본 특성 + 상호작용으로 인해 생성된 새로운 특성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s21_0Tkat39W"
      },
      "outputs": [],
      "source": [
        "# Transformer 기반 분류 모델 클래스 정의\n",
        "# 입력 데이터를 고급 변환과 분류를 수행하는 신경망 모델\n",
        "class TransformerClassifier(nn.Module):\n",
        "    # 모델 초기화 메서드\n",
        "    # input_dim: 입력 특성 차원\n",
        "    # hidden_dim: 은닉층 차원\n",
        "    # num_heads: 멀티헤드 어텐션의 헤드 수\n",
        "    # num_classes: 분류할 클래스 수\n",
        "    def __init__(self, input_dim, hidden_dim, num_heads, num_classes):\n",
        "        # 부모 클래스(nn.Module) 초기화\n",
        "        super().__init__()\n",
        "\n",
        "        # 컬럼 간 상호작용 모듈 생성\n",
        "        # 입력 특성들 사이의 복잡한 상호작용 학습\n",
        "        self.column_interaction = ColumnWiseInteraction(input_dim)\n",
        "\n",
        "        # 위치 인코딩 생성\n",
        "        # 모델에 입력 데이터의 순서/위치 정보 제공\n",
        "        self.positional_encoding = nn.Parameter(torch.randn(1, input_dim * 2))\n",
        "\n",
        "        # Transformer 인코더 레이어 생성\n",
        "        # 특성 간 복잡한 관계와 의존성 모델링\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=input_dim * 2,  # 특성 차원 (상호작용 후 2배)\n",
        "            nhead=num_heads,         # 멀티헤드 어텐션 헤드 수\n",
        "            dim_feedforward=hidden_dim  # 피드포워드 레이어 차원\n",
        "        )\n",
        "        # 2개의 인코더 레이어로 구성된 Transformer 인코더 생성\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=2)\n",
        "\n",
        "        # 분류기 헤드 생성\n",
        "        # 고차원 특성을 클래스 확률로 변환\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(input_dim * 2, hidden_dim),  # 첫 번째 선형 레이어\n",
        "            nn.ReLU(),                             # 비선형성 추가\n",
        "            nn.Dropout(0.3),                       # 과적합 방지를 위한 드롭아웃\n",
        "            nn.Linear(hidden_dim, num_classes)     # 최종 분류 레이어\n",
        "        )\n",
        "\n",
        "    # 순전파(forward) 메서드 정의\n",
        "    def forward(self, x):\n",
        "        # 컬럼 간 상호작용 적용\n",
        "        # 입력 특성들 간의 상호작용 계산 및 새로운 특성 생성\n",
        "        x = self.column_interaction(x)\n",
        "\n",
        "        # 위치 인코딩 추가\n",
        "        # 입력에 위치/순서 정보 주입\n",
        "        x = x + self.positional_encoding\n",
        "\n",
        "        # Transformer 인코딩을 위해 시퀀스 차원 추가\n",
        "        # 모델의 입력 형태에 맞게 텐서 차원 조정\n",
        "        x = x.unsqueeze(0)  # 형태: [1, 배치 크기, 특성 차원]\n",
        "\n",
        "        # Transformer 인코더를 통한 특성 변환\n",
        "        # 고급 특성 표현 학습\n",
        "        x = self.transformer_encoder(x)\n",
        "        x = x.squeeze(0)\n",
        "\n",
        "        # 분류기를 통한 최종 클래스 예측\n",
        "        return self.classifier(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j4Q3GUvit7P8"
      },
      "outputs": [],
      "source": [
        "# 모델 학습을 위한 훈련 함수 정의\n",
        "def train_model(model, train_loader, criterion, optimizer, device):\n",
        "    # 모델을 훈련 모드로 설정\n",
        "    # 훈련 중에는 드롭아웃, 배치 정규화 등의 레이어가 훈련 모드로 동작\n",
        "    model.train()\n",
        "\n",
        "    # 총 손실값 초기화\n",
        "    # 배치별 손실을 누적하여 평균 손실 계산을 준비\n",
        "    total_loss = 0\n",
        "\n",
        "    # 데이터 로더에서 배치 단위로 반복\n",
        "    # batch_x: 입력 특성, batch_y: 정답 레이블\n",
        "    for batch_x, batch_y in train_loader:\n",
        "        # 입력 데이터와 레이블을 지정된 장치(CPU/GPU)로 이동\n",
        "        batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
        "\n",
        "        # 옵티마이저의 그래디언트 초기화\n",
        "        # 이전 반복의 그래디언트 제거\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 모델에 입력 데이터 전달하여 예측값 생성\n",
        "        outputs = model(batch_x)\n",
        "\n",
        "        # 손실 함수를 사용해 예측값과 실제값 사이의 손실 계산\n",
        "        loss = criterion(outputs, batch_y)\n",
        "\n",
        "        # 역전파를 통해 손실에 대한 그래디언트 계산\n",
        "        # 각 가중치의 손실에 대한 기여도 계산\n",
        "        loss.backward()\n",
        "\n",
        "        # 옵티마이저를 사용해 가중치 업데이트\n",
        "        # 계산된 그래디언트를 바탕으로 모델 파라미터 조정\n",
        "        optimizer.step()\n",
        "\n",
        "        # 배치별 손실을 총 손실에 누적\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    # 전체 배치의 평균 손실 반환\n",
        "    # 한 에폭(epoch) 동안의 평균 손실 계산\n",
        "    return total_loss / len(train_loader)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7qhLGYm7t93Z"
      },
      "outputs": [],
      "source": [
        "# 모델 평가를 위한 함수 정의\n",
        "def evaluate_model(model, test_loader, device):\n",
        "    # 모델을 평가 모드로 전환\n",
        "    # 드롭아웃, 배치 정규화 등의 레이어가 추론 모드로 동작\n",
        "    model.eval()\n",
        "\n",
        "    # 정확히 예측한 샘플 수와 전체 샘플 수 초기화\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    # 그래디언트 계산 비활성화\n",
        "    # 메모리 절약 및 계산 속도 향상\n",
        "    with torch.no_grad():\n",
        "        # 테스트 데이터 로더에서 배치 단위로 반복\n",
        "        for batch_x, batch_y in test_loader:\n",
        "            # 입력 데이터와 레이블을 지정된 장치(CPU/GPU)로 이동\n",
        "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
        "\n",
        "            # 모델에 입력 데이터 전달하여 예측값 생성\n",
        "            outputs = model(batch_x)\n",
        "\n",
        "            # 출력 텐서에서 가장 높은 확률을 가진 클래스 선택\n",
        "            # outputs.data: 최대 확률 값, predicted: 해당 클래스 인덱스\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "            # 전체 샘플 수 누적\n",
        "            total += batch_y.size(0)\n",
        "\n",
        "            # 정확히 예측한 샘플 수 계산\n",
        "            # predicted와 실제 레이블(batch_y)을 비교\n",
        "            correct += (predicted == batch_y).sum().item()\n",
        "\n",
        "    # 전체 정확도를 백분율로 반환\n",
        "    # (정확히 예측한 샘플 수 / 전체 샘플 수) * 100\n",
        "    return 100 * correct / total\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bMEN08CQvlC0"
      },
      "outputs": [],
      "source": [
        "# AUROC 계산 및 시각화 함수 추가\n",
        "def calculate_and_plot_auroc(model, test_loader, device):\n",
        "    model.eval()\n",
        "    all_probs = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_x, batch_y in test_loader:\n",
        "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
        "\n",
        "            # 모델 출력을 확률로 변환 (softmax)\n",
        "            outputs = torch.softmax(model(batch_x), dim=1)\n",
        "\n",
        "            # 양성 클래스(일반적으로 인덱스 1)의 확률 추출\n",
        "            probs = outputs[:, 1].cpu().numpy()\n",
        "            labels = batch_y.cpu().numpy()\n",
        "\n",
        "            all_probs.extend(probs)\n",
        "            all_labels.extend(labels)\n",
        "\n",
        "    # AUROC 계산\n",
        "    auroc = roc_auc_score(all_labels, all_probs)\n",
        "\n",
        "    # ROC 곡선 계산\n",
        "    fpr, tpr, thresholds = roc_curve(all_labels, all_probs)\n",
        "\n",
        "    # ROC 곡선 시각화\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(fpr, tpr, color='blue', label=f'ROC curve (AUROC = {auroc:.2f})')\n",
        "    plt.plot([0, 1], [0, 1], color='red', linestyle='--', label='Random Classifier')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('roc_curve.png')\n",
        "    plt.close()\n",
        "\n",
        "    return auroc\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u5DHQhqFwEYr"
      },
      "outputs": [],
      "source": [
        "# 메인 실행 함수 수정\n",
        "def main():\n",
        "    # 이전 코드와 동일한 설정\n",
        "    torch.manual_seed(42)\n",
        "    np.random.seed(42)\n",
        "\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    # 데이터 로드 및 전처리\n",
        "    X, y, preprocessor = load_and_preprocess_data()\n",
        "\n",
        "    # 데이터 분할\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # PyTorch 텐서로 변환\n",
        "    X_train = torch.FloatTensor(X_train)\n",
        "    X_test = torch.FloatTensor(X_test)\n",
        "    y_train = torch.LongTensor(y_train)\n",
        "    y_test = torch.LongTensor(y_test)\n",
        "\n",
        "    # DataLoaders 생성\n",
        "    train_dataset = TensorDataset(X_train, y_train)\n",
        "    test_dataset = TensorDataset(X_test, y_test)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=64)\n",
        "\n",
        "    # 모델 하이퍼파라미터\n",
        "    input_dim = X_train.shape[1]\n",
        "    hidden_dim = 128\n",
        "    num_heads = 4\n",
        "    num_classes = len(np.unique(y))\n",
        "\n",
        "    # 모델 초기화\n",
        "    model = TransformerClassifier(input_dim, hidden_dim, num_heads, num_classes).to(device)\n",
        "\n",
        "    # 손실 함수 및 최적화기\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    # 학습 루프\n",
        "    num_epochs = 10\n",
        "    for epoch in tqdm(range(num_epochs)):\n",
        "        train_loss = train_model(model, train_loader, criterion, optimizer, device)\n",
        "        test_acc = evaluate_model(model, test_loader, device)\n",
        "\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {train_loss:.4f}, Test Accuracy: {test_acc:.2f}%')\n",
        "\n",
        "# def auroc():\n",
        "#     # AUROC 계산 및 시각화\n",
        "    auroc = calculate_and_plot_auroc(model, test_loader, device)\n",
        "    print(f'AUROC: {auroc:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lejsEzGawIMf"
      },
      "outputs": [],
      "source": [
        "# 추가 유틸리티 함수: AUROC 결과 상세 분석\n",
        "def interpret_auroc(auroc):\n",
        "    \"\"\"AUROC 값에 대한 해석\"\"\"\n",
        "    if auroc >= 0.9:\n",
        "        return \"Excellent discrimination\"\n",
        "    elif auroc >= 0.8:\n",
        "        return \"Good discrimination\"\n",
        "    elif auroc >= 0.7:\n",
        "        return \"Fair discrimination\"\n",
        "    elif auroc >= 0.6:\n",
        "        return \"Poor discrimination\"\n",
        "    else:\n",
        "        return \"Failed discrimination\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P3cDgqkFxKKb",
        "outputId": "afbe80ba-589b-49c8-ed5d-615b411f6dca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(\n",
            " 10%|█         | 1/10 [00:08<01:17,  8.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.5137, Test Accuracy: 77.19%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 2/10 [00:13<00:50,  6.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/10], Loss: 0.4964, Test Accuracy: 77.72%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 3/10 [00:19<00:42,  6.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3/10], Loss: 0.4945, Test Accuracy: 77.53%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 4/10 [00:23<00:33,  5.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4/10], Loss: 0.4936, Test Accuracy: 77.60%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 5/10 [00:28<00:26,  5.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/10], Loss: 0.4926, Test Accuracy: 77.76%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 6/10 [00:34<00:21,  5.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [6/10], Loss: 0.4924, Test Accuracy: 77.73%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 7/10 [00:38<00:15,  5.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [7/10], Loss: 0.4910, Test Accuracy: 77.74%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 8/10 [00:44<00:10,  5.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [8/10], Loss: 0.4908, Test Accuracy: 77.72%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 9/10 [00:49<00:05,  5.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [9/10], Loss: 0.4902, Test Accuracy: 77.76%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:54<00:00,  5.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/10], Loss: 0.4901, Test Accuracy: 77.80%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUROC: 0.7208\n"
          ]
        }
      ],
      "source": [
        "main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4i8_83McESPD"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}