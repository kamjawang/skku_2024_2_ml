{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# 주요 라이브러리 및 모듈 가져오기\n",
        "import torch  # 딥러닝 프레임워크 PyTorch\n",
        "import torch.nn as nn  # 신경망 모듈\n",
        "import torch.optim as optim  # 최적화 알고리즘\n",
        "from torch.utils.data import DataLoader, TensorDataset  # 데이터 처리와 로딩 유틸리티\n",
        "from sklearn.model_selection import train_test_split  # 데이터셋 분할 도구\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder  # 데이터 전처리 도구\n",
        "import numpy as np  # 수학 연산\n",
        "import pandas as pd  # 데이터 프레임 처리\n",
        "from tqdm import tqdm  # 학습 진행 상태 표시\n",
        "from sklearn.metrics import roc_auc_score, roc_curve  # 모델 성능 평가 지표\n",
        "import matplotlib.pyplot as plt  # 데이터 시각화\n",
        "from sklearn.datasets import fetch_openml  # 데이터셋 로드"
      ],
      "metadata": {
        "id": "sxBzWpUUfz14"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 전처리 함수\n",
        "def preprocess_dataframe(df):\n",
        "    df_processed = df.copy()\n",
        "\n",
        "    for column in df_processed.columns:\n",
        "        if df_processed[column].dtype == 'category' or df_processed[column].dtype == 'object':\n",
        "            if pd.api.types.is_categorical_dtype(df_processed[column]):\n",
        "                df_processed[column] = df_processed[column].cat.add_categories(['Unknown'])\n",
        "            df_processed[column] = df_processed[column].fillna('Unknown')\n",
        "            le = LabelEncoder()\n",
        "            df_processed[column] = le.fit_transform(df_processed[column].astype(str))\n",
        "\n",
        "        elif df_processed[column].dtype in ['int64', 'float64']:\n",
        "            df_processed[column] = df_processed[column].fillna(df_processed[column].median())\n",
        "\n",
        "    return df_processed"
      ],
      "metadata": {
        "id": "w7Azde6wgPT5"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 메인 함수 뜯기\n",
        "\n",
        "# 데이터 로드 및 전처리\n",
        "data = pd.read_csv(\"/content/sample_data/adult.csv\",na_values=[' ?']).drop(['fnlwgt'], axis=1).dropna()\n",
        "df_processed = preprocess_dataframe(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cgQh59BzK9Aq",
        "outputId": "fa349952-bcb3-4b0b-cffe-ba730df2a7d7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-150465cc5892>:7: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
            "  if pd.api.types.is_categorical_dtype(df_processed[column]):\n",
            "<ipython-input-5-150465cc5892>:7: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
            "  if pd.api.types.is_categorical_dtype(df_processed[column]):\n",
            "<ipython-input-5-150465cc5892>:7: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
            "  if pd.api.types.is_categorical_dtype(df_processed[column]):\n",
            "<ipython-input-5-150465cc5892>:7: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
            "  if pd.api.types.is_categorical_dtype(df_processed[column]):\n",
            "<ipython-input-5-150465cc5892>:7: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
            "  if pd.api.types.is_categorical_dtype(df_processed[column]):\n",
            "<ipython-input-5-150465cc5892>:7: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
            "  if pd.api.types.is_categorical_dtype(df_processed[column]):\n",
            "<ipython-input-5-150465cc5892>:7: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
            "  if pd.api.types.is_categorical_dtype(df_processed[column]):\n",
            "<ipython-input-5-150465cc5892>:7: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
            "  if pd.api.types.is_categorical_dtype(df_processed[column]):\n",
            "<ipython-input-5-150465cc5892>:7: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
            "  if pd.api.types.is_categorical_dtype(df_processed[column]):\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 특성과 타겟, 민감한 특성 분리\n",
        "sensitive_column = 'gender'  # 예시로 성별 선택\n",
        "target_column = 'income'   # 예시로 타겟 컬럼 설정\n",
        "X_data = df_processed.drop([target_column, sensitive_column], axis=1)\n",
        "y_data = df_processed[target_column]\n",
        "sensitive_feature = df_processed[sensitive_column]"
      ],
      "metadata": {
        "id": "ctQbeR6EMEia"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 분할\n",
        "X_train, X_test, y_train, y_test, sensitive_train, sensitive_test = train_test_split(\n",
        "    X_data, y_data, sensitive_feature, test_size=0.2, random_state=42, stratify=y_data\n",
        ")"
      ],
      "metadata": {
        "id": "WeOHJnJBN_cA"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 표준화\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "Py1nsgp7OkDs"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PyTorch 텐서로 변환\n",
        "X_train = torch.FloatTensor(X_train)\n",
        "X_test = torch.FloatTensor(X_test)\n",
        "y_train = torch.LongTensor(y_train.values)\n",
        "y_test = torch.LongTensor(y_test.values)\n",
        "sensitive_train = torch.LongTensor(sensitive_train.values)\n",
        "sensitive_test = torch.LongTensor(sensitive_test.values)"
      ],
      "metadata": {
        "id": "SSIHMAxaOlLT"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DataLoader 생성\n",
        "train_dataset = TensorDataset(X_train, y_train, sensitive_train)\n",
        "test_dataset = TensorDataset(X_test, y_test, sensitive_test)\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64)"
      ],
      "metadata": {
        "id": "D1b3G72ORhYg"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 통합된 ColumnWiseInteraction 클래스\n",
        "class ColumnWiseInteraction(nn.Module):\n",
        "    def __init__(self, input_dim, interaction_dim):\n",
        "        super().__init__()\n",
        "        # 명시적인 행렬 곱을 위한 가중치 파라미터\n",
        "        self.interaction_weights = nn.Parameter(torch.randn(input_dim, interaction_dim))\n",
        "\n",
        "        # 학습 가능한 비선형 상호작용을 위한 모듈 정의\n",
        "        self.linear1 = nn.Linear(input_dim, interaction_dim)  # 첫 번째 선형 변환\n",
        "        self.activation = nn.ReLU()  # 비선형 활성화 함수\n",
        "        self.linear2 = nn.Linear(interaction_dim, input_dim)  # 두 번째 선형 변환\n",
        "\n",
        "    def forward(self, x):\n",
        "        # 명시적인 컬럼 간 상호작용 (matmul 기반)\n",
        "        matmul_interactions = torch.matmul(x, self.interaction_weights)\n",
        "\n",
        "        # 학습 가능한 비선형 상호작용\n",
        "        nonlinear_interactions = self.linear1(x)\n",
        "        nonlinear_interactions = self.activation(nonlinear_interactions)\n",
        "        nonlinear_interactions = self.linear2(nonlinear_interactions)\n",
        "\n",
        "        # 원본 입력, matmul 상호작용, 비선형 상호작용 결합\n",
        "        return torch.cat([x, matmul_interactions, nonlinear_interactions], dim=1)"
      ],
      "metadata": {
        "id": "Ea4kT9RyRj4d"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 공정성 지표 계산을 위한 클래스 정의\n",
        "class FairnessMetrics:\n",
        "    @staticmethod\n",
        "    def equal_opportunity_difference(predictions, true_labels, sensitive_features, target_label=1, epsilon=1e-6):\n",
        "        \"\"\"\n",
        "        True Positive Rate(TPR)의 민감한 그룹 간 차이를 계산.\n",
        "        \"\"\"\n",
        "        mask_positive = (true_labels == target_label)  # 실제 레이블이 positive인 경우 필터\n",
        "        mask_sensitive_0 = (sensitive_features == 0) & mask_positive  # 그룹 0의 positive 필터\n",
        "        mask_sensitive_1 = (sensitive_features == 1) & mask_positive  # 그룹 1의 positive 필터\n",
        "\n",
        "        # 각 그룹의 TPR 계산\n",
        "        tpr_0 = torch.mean(predictions[mask_sensitive_0]) if mask_sensitive_0.sum() > 0 else torch.tensor(0.0).to(predictions.device)\n",
        "        tpr_1 = torch.mean(predictions[mask_sensitive_1]) if mask_sensitive_1.sum() > 0 else torch.tensor(0.0).to(predictions.device)\n",
        "        return torch.abs(tpr_0 - tpr_1)  # TPR 차이 반환\n",
        "\n",
        "    @staticmethod\n",
        "    def false_positive_rate_difference(predictions, true_labels, sensitive_features, target_label=0, epsilon=1e-6):\n",
        "        \"\"\"\n",
        "        False Positive Rate(FPR)의 민감한 그룹 간 차이를 계산.\n",
        "        \"\"\"\n",
        "        mask_negative = (true_labels == target_label)  # 실제 레이블이 negative인 경우 필터\n",
        "        mask_sensitive_0 = (sensitive_features == 0) & mask_negative\n",
        "        mask_sensitive_1 = (sensitive_features == 1) & mask_negative\n",
        "\n",
        "        # 각 그룹의 FPR 계산\n",
        "        fpr_0 = torch.mean(predictions[mask_sensitive_0]) if mask_sensitive_0.sum() > 0 else torch.tensor(0.0).to(predictions.device)\n",
        "        fpr_1 = torch.mean(predictions[mask_sensitive_1]) if mask_sensitive_1.sum() > 0 else torch.tensor(0.0).to(predictions.device)\n",
        "        return torch.abs(fpr_0 - fpr_1)\n",
        "\n",
        "    @staticmethod\n",
        "    def equalized_odds_difference(predictions, true_labels, sensitive_features, target_label=1, epsilon=1e-6):\n",
        "        \"\"\"\n",
        "        Equalized Odds 차이를 계산: EOP와 FPR 차이 중 최대값.\n",
        "        \"\"\"\n",
        "        eop = FairnessMetrics.equal_opportunity_difference(predictions, true_labels, sensitive_features, target_label, epsilon) # True Positive Rate(TPR)의 민감한 그룹 간 차이\n",
        "        fpr_diff = FairnessMetrics.false_positive_rate_difference(predictions, true_labels, sensitive_features, target_label=0, epsilon=epsilon) # False Positive Rate(FPR)의 민감한 그룹 간 차이\n",
        "        return torch.max(eop, fpr_diff)  # 두 지표 중 큰 값을 반환\n",
        "\n",
        "    @staticmethod\n",
        "    def demographic_parity_difference(predictions, sensitive_features, epsilon=1e-6):\n",
        "        \"\"\"\n",
        "        Positive 예측률의 민감한 그룹 간 차이를 계산.\n",
        "        \"\"\"\n",
        "        mask_sensitive_0 = (sensitive_features == 0)\n",
        "        mask_sensitive_1 = (sensitive_features == 1)\n",
        "\n",
        "        rate_0 = torch.mean(predictions[mask_sensitive_0]) if mask_sensitive_0.sum() > 0 else torch.tensor(0.0).to(predictions.device)\n",
        "        rate_1 = torch.mean(predictions[mask_sensitive_1]) if mask_sensitive_1.sum() > 0 else torch.tensor(0.0).to(predictions.device)\n",
        "        return torch.abs(rate_0 - rate_1)  # 차이 반환"
      ],
      "metadata": {
        "id": "KZdDzH9VV5Cl"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 공정성을 고려한 Transformer 분류기 정의\n",
        "class FairnessAwareTransformerClassifier(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, num_heads, num_classes, interaction_dim=32):\n",
        "        super().__init__()\n",
        "        self.column_interaction = ColumnWiseInteraction(input_dim, interaction_dim)\n",
        "        self.input_projection = nn.Linear(1, hidden_dim)  # 각 특성을 임베딩\n",
        "        self.hidden_dim = hidden_dim  # Hidden dimension 저장\n",
        "        self.num_heads = num_heads  # Transformer 헤드 수\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=hidden_dim, nhead=num_heads, dim_feedforward=hidden_dim * 4, batch_first=True\n",
        "        )\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=2)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(hidden_dim, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Column-wise interaction 적용\n",
        "        x = self.column_interaction(x)\n",
        "        seq_len = x.size(1)  # 입력의 sequence 길이 (특성 수)\n",
        "\n",
        "        # Input projection 및 차원 확장\n",
        "        x = x.unsqueeze(-1)  # (batch_size, seq_len, 1)\n",
        "        x = self.input_projection(x)  # (batch_size, seq_len, hidden_dim)\n",
        "\n",
        "        # 동적으로 위치 인코딩 생성\n",
        "        positional_encoding = torch.randn(1, seq_len, self.hidden_dim, device=x.device)\n",
        "        x = x + positional_encoding\n",
        "\n",
        "        # Transformer Encoder 적용\n",
        "        x = self.transformer_encoder(x)\n",
        "\n",
        "        # Sequence의 평균을 사용하여 분류 입력 생성\n",
        "        x = x.mean(dim=1)\n",
        "        return self.classifier(x)"
      ],
      "metadata": {
        "id": "lu9-fmHkV8OX"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 함수\n",
        "def train_model(model, train_loader, criterion, optimizer, device, lambda_fairness=0.01):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    total_fairness_loss = 0\n",
        "    total_eop = 0\n",
        "    total_eo = 0\n",
        "    total_dp = 0\n",
        "    total_batches = 0\n",
        "\n",
        "    for batch_x, batch_y, batch_sensitive in train_loader:\n",
        "        batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
        "        batch_sensitive = batch_sensitive.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 예측 및 분류 손실\n",
        "        outputs = model(batch_x)\n",
        "        classification_loss = criterion(outputs, batch_y)\n",
        "\n",
        "        # 공정성 손실 계산\n",
        "        probabilities = torch.softmax(outputs, dim=1)[:, 1]  # Probability of class 1\n",
        "\n",
        "        # To avoid NaNs, ensure that probabilities are between 0 and 1\n",
        "        probabilities = torch.clamp(probabilities, min=0.0, max=1.0)\n",
        "\n",
        "        # 공정성 지표 계산\n",
        "        eop = FairnessMetrics.equal_opportunity_difference(probabilities, batch_y, batch_sensitive, target_label=1)\n",
        "        eo = FairnessMetrics.equalized_odds_difference(probabilities, batch_y, batch_sensitive, target_label=1, epsilon=1e-6)\n",
        "        dp = FairnessMetrics.demographic_parity_difference(probabilities, batch_sensitive)\n",
        "\n",
        "        # 공정성 손실 합산 (가중치를 조정할 수 있습니다)\n",
        "        fairness_loss = eop + eo + dp\n",
        "\n",
        "        # 전체 손실 결합\n",
        "        total_loss_batch = classification_loss + lambda_fairness * fairness_loss\n",
        "        total_loss_batch.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # 손실 및 공정성 지표 기록\n",
        "        total_loss += classification_loss.item()\n",
        "        total_fairness_loss += fairness_loss.item()\n",
        "        total_eop += eop.item()\n",
        "        total_eo += eo.item()\n",
        "        total_dp += dp.item()\n",
        "        total_batches += 1\n",
        "\n",
        "    avg_loss = total_loss / total_batches\n",
        "    avg_fairness_loss = total_fairness_loss / total_batches\n",
        "    avg_eop = total_eop / total_batches\n",
        "    avg_eo = total_eo / total_batches\n",
        "    avg_dp = total_dp / total_batches\n",
        "\n",
        "    return avg_loss, avg_fairness_loss, avg_eop, avg_eo, avg_dp"
      ],
      "metadata": {
        "id": "IMrElRSZWD3S"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 평가 함수\n",
        "def evaluate_model(model, test_loader, device):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_predictions = []\n",
        "    all_labels = []\n",
        "    all_sensitive = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_x, batch_y, batch_sensitive in test_loader:\n",
        "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
        "            outputs = model(batch_x)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += batch_y.size(0)\n",
        "            correct += (predicted == batch_y).sum().item()\n",
        "\n",
        "            # 공정성 지표 계산을 위한 데이터 수집\n",
        "            probabilities = torch.softmax(outputs, dim=1)[:, 1]\n",
        "            all_predictions.append(probabilities.cpu())\n",
        "            all_labels.append(batch_y.cpu())\n",
        "            all_sensitive.append(batch_sensitive.cpu())\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "\n",
        "    # 모든 배치를 하나로 합침\n",
        "    all_predictions = torch.cat(all_predictions)\n",
        "    all_labels = torch.cat(all_labels)\n",
        "    all_sensitive = torch.cat(all_sensitive)\n",
        "\n",
        "    # 공정성 지표 계산\n",
        "    eop = FairnessMetrics.equal_opportunity_difference(all_predictions, all_labels, all_sensitive, target_label=1).item()\n",
        "    eo = FairnessMetrics.equalized_odds_difference(all_predictions, all_labels, all_sensitive, target_label=1, epsilon=1e-6).item()\n",
        "    dp = FairnessMetrics.demographic_parity_difference(all_predictions, all_sensitive).item()\n",
        "\n",
        "    # AUROC 계산\n",
        "    auroc = roc_auc_score(all_labels.numpy(), all_predictions.numpy())\n",
        "\n",
        "    return accuracy, eop, eo, dp, auroc"
      ],
      "metadata": {
        "id": "TwhwqP_CWDVT"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# 모델 초기화\n",
        "input_dim = X_train.shape[1]\n",
        "hidden_dim = 128\n",
        "num_heads = 4\n",
        "num_classes = 2\n",
        "\n",
        "model = FairnessAwareTransformerClassifier(input_dim, hidden_dim, num_heads, num_classes).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "num_epochs = 10  # 충분한 학습을 위해 epoch 수 증가\n",
        "\n",
        "# 기록을 위한 리스트 초기화\n",
        "train_fairness_history = {\n",
        "    'loss': [],\n",
        "    'fairness_loss': [],\n",
        "    'EOP': [],\n",
        "    'EO': [],\n",
        "    'DP': []\n",
        "}\n",
        "test_fairness_history = {\n",
        "    'accuracy': [],\n",
        "    'EOP': [],\n",
        "    'EO': [],\n",
        "    'DP': []\n",
        "}\n",
        "\n",
        "for epoch in tqdm(range(num_epochs), desc=\"Training\"):\n",
        "    train_loss, train_fairness_loss, train_eop, train_eo, train_dp = train_model(\n",
        "        model, train_loader, criterion, optimizer,\n",
        "        device, lambda_fairness=0.1\n",
        "    )\n",
        "    test_acc, test_eop, test_eo, test_dp, test_auroc = evaluate_model(model, test_loader, device)\n",
        "\n",
        "    # 기록 저장\n",
        "    train_fairness_history['loss'].append(train_loss)\n",
        "    train_fairness_history['fairness_loss'].append(train_fairness_loss)\n",
        "    train_fairness_history['EOP'].append(train_eop)\n",
        "    train_fairness_history['EO'].append(train_eo)\n",
        "    train_fairness_history['DP'].append(train_dp)\n",
        "\n",
        "    test_fairness_history['accuracy'].append(test_acc)\n",
        "    test_fairness_history['EOP'].append(test_eop)\n",
        "    test_fairness_history['EO'].append(test_eo)\n",
        "    test_fairness_history['DP'].append(test_dp)\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], '\n",
        "          f'Loss: {train_loss:.4f}, '\n",
        "          f'Fairness Loss: {train_fairness_loss:.4f}, '\n",
        "          f'EOP: {train_eop:.4f}, '\n",
        "          f'EO: {train_eo:.4f}, '\n",
        "          f'DP: {train_dp:.4f}, '\n",
        "          f'Test Accuracy: {test_acc:.2f}%, '\n",
        "          f'Test EOP: {test_eop:.4f}, '\n",
        "          f'Test EO: {test_eo:.4f}, '\n",
        "          f'Test DP: {test_dp:.4f}',\n",
        "          f'Test AUROC: {test_auroc:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QWVIr5zvImfU",
        "outputId": "9f370bd4-80f7-4ac9-cffe-c343e05c4887"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  10%|█         | 1/10 [00:09<01:27,  9.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.4326, Fairness Loss: 0.3253, EOP: 0.1210, EO: 0.1305, DP: 0.0738, Test Accuracy: 82.15%, Test EOP: 0.0367, Test EO: 0.0367, Test DP: 0.0777 Test AUROC: 0.8584\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  20%|██        | 2/10 [00:16<01:04,  8.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/10], Loss: 0.3795, Fairness Loss: 0.4184, EOP: 0.1494, EO: 0.1622, DP: 0.1068, Test Accuracy: 83.65%, Test EOP: 0.0275, Test EO: 0.0596, Test DP: 0.1149 Test AUROC: 0.8835\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  30%|███       | 3/10 [00:23<00:53,  7.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3/10], Loss: 0.3587, Fairness Loss: 0.4591, EOP: 0.1604, EO: 0.1760, DP: 0.1227, Test Accuracy: 84.38%, Test EOP: 0.0129, Test EO: 0.0621, Test DP: 0.1250 Test AUROC: 0.8904\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  40%|████      | 4/10 [00:31<00:45,  7.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4/10], Loss: 0.3518, Fairness Loss: 0.4930, EOP: 0.1746, EO: 0.1892, DP: 0.1292, Test Accuracy: 83.85%, Test EOP: 0.0320, Test EO: 0.0787, Test DP: 0.1468 Test AUROC: 0.8909\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  50%|█████     | 5/10 [00:38<00:36,  7.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/10], Loss: 0.3494, Fairness Loss: 0.4702, EOP: 0.1615, EO: 0.1787, DP: 0.1300, Test Accuracy: 84.45%, Test EOP: 0.0452, Test EO: 0.0786, Test DP: 0.1432 Test AUROC: 0.8930\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  60%|██████    | 6/10 [00:45<00:29,  7.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [6/10], Loss: 0.3467, Fairness Loss: 0.4905, EOP: 0.1687, EO: 0.1846, DP: 0.1371, Test Accuracy: 84.49%, Test EOP: 0.0357, Test EO: 0.0771, Test DP: 0.1385 Test AUROC: 0.8939\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  70%|███████   | 7/10 [00:53<00:22,  7.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [7/10], Loss: 0.3508, Fairness Loss: 0.4887, EOP: 0.1659, EO: 0.1850, DP: 0.1378, Test Accuracy: 83.68%, Test EOP: 0.0470, Test EO: 0.0944, Test DP: 0.1623 Test AUROC: 0.8930\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  80%|████████  | 8/10 [01:00<00:14,  7.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [8/10], Loss: 0.3487, Fairness Loss: 0.4795, EOP: 0.1635, EO: 0.1812, DP: 0.1347, Test Accuracy: 84.02%, Test EOP: 0.0271, Test EO: 0.0777, Test DP: 0.1400 Test AUROC: 0.8936\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  90%|█████████ | 9/10 [01:07<00:07,  7.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [9/10], Loss: 0.3462, Fairness Loss: 0.4726, EOP: 0.1628, EO: 0.1796, DP: 0.1301, Test Accuracy: 84.14%, Test EOP: 0.0313, Test EO: 0.0720, Test DP: 0.1332 Test AUROC: 0.8926\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 10/10 [01:14<00:00,  7.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/10], Loss: 0.3464, Fairness Loss: 0.4911, EOP: 0.1705, EO: 0.1875, DP: 0.1330, Test Accuracy: 84.52%, Test EOP: 0.0224, Test EO: 0.0670, Test DP: 0.1315 Test AUROC: 0.8917\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1) EOP: 0.1 / EO: 0.45 / DP: 0.45"
      ],
      "metadata": {
        "id": "d6ZIX9NuS5aq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 함수\n",
        "def train_model(model, train_loader, criterion, optimizer, device, lambda_fairness=0.01):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    total_fairness_loss = 0\n",
        "    total_eop = 0\n",
        "    total_eo = 0\n",
        "    total_dp = 0\n",
        "    total_batches = 0\n",
        "\n",
        "    for batch_x, batch_y, batch_sensitive in train_loader:\n",
        "        batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
        "        batch_sensitive = batch_sensitive.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 예측 및 분류 손실\n",
        "        outputs = model(batch_x)\n",
        "        classification_loss = criterion(outputs, batch_y)\n",
        "\n",
        "        # 공정성 손실 계산\n",
        "        probabilities = torch.softmax(outputs, dim=1)[:, 1]  # Probability of class 1\n",
        "\n",
        "        # To avoid NaNs, ensure that probabilities are between 0 and 1\n",
        "        probabilities = torch.clamp(probabilities, min=0.0, max=1.0)\n",
        "\n",
        "        # 공정성 지표 계산\n",
        "        eop = FairnessMetrics.equal_opportunity_difference(probabilities, batch_y, batch_sensitive, target_label=1)\n",
        "        eo = FairnessMetrics.equalized_odds_difference(probabilities, batch_y, batch_sensitive, target_label=1, epsilon=1e-6)\n",
        "        dp = FairnessMetrics.demographic_parity_difference(probabilities, batch_sensitive)\n",
        "\n",
        "        # 공정성 가중치 조정\n",
        "        a = 0.1\n",
        "        b = 0.45\n",
        "        c = 0.45\n",
        "\n",
        "\n",
        "        # 공정성 손실 합산\n",
        "        fairness_loss = (a * eop) + (b * eo) +  (c * dp)\n",
        "\n",
        "        # 전체 손실 결합\n",
        "        total_loss_batch = classification_loss + lambda_fairness * fairness_loss\n",
        "        total_loss_batch.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # 손실 및 공정성 지표 기록\n",
        "        total_loss += classification_loss.item()\n",
        "        total_fairness_loss += fairness_loss.item()\n",
        "        total_eop += eop.item()\n",
        "        total_eo += eo.item()\n",
        "        total_dp += dp.item()\n",
        "        total_batches += 1\n",
        "\n",
        "    avg_loss = total_loss / total_batches\n",
        "    avg_fairness_loss = total_fairness_loss / total_batches\n",
        "    avg_eop = total_eop / total_batches\n",
        "    avg_eo = total_eo / total_batches\n",
        "    avg_dp = total_dp / total_batches\n",
        "\n",
        "    return avg_loss, avg_fairness_loss, avg_eop, avg_eo, avg_dp\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# 모델 초기화\n",
        "input_dim = X_train.shape[1]\n",
        "hidden_dim = 128\n",
        "num_heads = 4\n",
        "num_classes = 2\n",
        "\n",
        "model = FairnessAwareTransformerClassifier(input_dim, hidden_dim, num_heads, num_classes).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "num_epochs = 10  # 충분한 학습을 위해 epoch 수 증가\n",
        "\n",
        "# 기록을 위한 리스트 초기화\n",
        "train_fairness_history = {\n",
        "    'loss': [],\n",
        "    'fairness_loss': [],\n",
        "    'EOP': [],\n",
        "    'EO': [],\n",
        "    'DP': []\n",
        "}\n",
        "test_fairness_history = {\n",
        "    'accuracy': [],\n",
        "    'EOP': [],\n",
        "    'EO': [],\n",
        "    'DP': []\n",
        "}\n",
        "\n",
        "for epoch in tqdm(range(num_epochs), desc=\"Training\"):\n",
        "    train_loss, train_fairness_loss, train_eop, train_eo, train_dp = train_model(\n",
        "        model, train_loader, criterion, optimizer,\n",
        "        device, lambda_fairness=0.1\n",
        "    )\n",
        "    test_acc, test_eop, test_eo, test_dp, test_auroc = evaluate_model(model, test_loader, device)\n",
        "\n",
        "    # 기록 저장\n",
        "    train_fairness_history['loss'].append(train_loss)\n",
        "    train_fairness_history['fairness_loss'].append(train_fairness_loss)\n",
        "    train_fairness_history['EOP'].append(train_eop)\n",
        "    train_fairness_history['EO'].append(train_eo)\n",
        "    train_fairness_history['DP'].append(train_dp)\n",
        "\n",
        "    test_fairness_history['accuracy'].append(test_acc)\n",
        "    test_fairness_history['EOP'].append(test_eop)\n",
        "    test_fairness_history['EO'].append(test_eo)\n",
        "    test_fairness_history['DP'].append(test_dp)\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], '\n",
        "          f'Loss: {train_loss:.4f}, '\n",
        "          f'Fairness Loss: {train_fairness_loss:.4f}, '\n",
        "          f'EOP: {train_eop:.4f}, '\n",
        "          f'EO: {train_eo:.4f}, '\n",
        "          f'DP: {train_dp:.4f}, '\n",
        "          f'Test Accuracy: {test_acc:.2f}%, '\n",
        "          f'Test EOP: {test_eop:.4f}, '\n",
        "          f'Test EO: {test_eo:.4f}, '\n",
        "          f'Test DP: {test_dp:.4f}',\n",
        "          f'Test AUROC: {test_auroc:.4f}')\n",
        ""
      ],
      "metadata": {
        "id": "2e8yvfdMImc-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2be748f2-7787-4599-9efe-37c16a700cbc"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  10%|█         | 1/10 [00:07<01:08,  7.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.4194, Fairness Loss: 0.1604, EOP: 0.1946, EO: 0.2021, DP: 0.1111, Test Accuracy: 82.38%, Test EOP: 0.0941, Test EO: 0.0941, Test DP: 0.1147 Test AUROC: 0.8657\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  20%|██        | 2/10 [00:14<00:58,  7.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/10], Loss: 0.3673, Fairness Loss: 0.1885, EOP: 0.2132, EO: 0.2261, DP: 0.1454, Test Accuracy: 84.38%, Test EOP: 0.1050, Test EO: 0.1050, Test DP: 0.1636 Test AUROC: 0.8895\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  30%|███       | 3/10 [00:22<00:52,  7.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3/10], Loss: 0.3505, Fairness Loss: 0.1922, EOP: 0.2088, EO: 0.2233, DP: 0.1573, Test Accuracy: 84.11%, Test EOP: 0.0760, Test EO: 0.1057, Test DP: 0.1783 Test AUROC: 0.8920\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  40%|████      | 4/10 [00:29<00:43,  7.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4/10], Loss: 0.3432, Fairness Loss: 0.1911, EOP: 0.2038, EO: 0.2200, DP: 0.1594, Test Accuracy: 84.41%, Test EOP: 0.0648, Test EO: 0.0941, Test DP: 0.1685 Test AUROC: 0.8927\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  50%|█████     | 5/10 [00:36<00:36,  7.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/10], Loss: 0.3415, Fairness Loss: 0.1907, EOP: 0.2056, EO: 0.2212, DP: 0.1569, Test Accuracy: 83.34%, Test EOP: 0.0666, Test EO: 0.0736, Test DP: 0.1381 Test AUROC: 0.8933\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  60%|██████    | 6/10 [00:44<00:29,  7.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [6/10], Loss: 0.3392, Fairness Loss: 0.2004, EOP: 0.2218, EO: 0.2363, DP: 0.1597, Test Accuracy: 84.62%, Test EOP: 0.0602, Test EO: 0.0862, Test DP: 0.1538 Test AUROC: 0.8955\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  70%|███████   | 7/10 [00:51<00:21,  7.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [7/10], Loss: 0.3388, Fairness Loss: 0.1935, EOP: 0.2102, EO: 0.2263, DP: 0.1571, Test Accuracy: 84.99%, Test EOP: 0.0954, Test EO: 0.0977, Test DP: 0.1770 Test AUROC: 0.8976\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  80%|████████  | 8/10 [00:58<00:14,  7.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [8/10], Loss: 0.3353, Fairness Loss: 0.1926, EOP: 0.2048, EO: 0.2209, DP: 0.1616, Test Accuracy: 84.88%, Test EOP: 0.0760, Test EO: 0.0872, Test DP: 0.1585 Test AUROC: 0.8965\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  90%|█████████ | 9/10 [01:05<00:07,  7.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [9/10], Loss: 0.3387, Fairness Loss: 0.1901, EOP: 0.2065, EO: 0.2218, DP: 0.1547, Test Accuracy: 84.88%, Test EOP: 0.0586, Test EO: 0.0837, Test DP: 0.1552 Test AUROC: 0.8952\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 10/10 [01:13<00:00,  7.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/10], Loss: 0.3396, Fairness Loss: 0.1909, EOP: 0.2058, EO: 0.2235, DP: 0.1551, Test Accuracy: 84.68%, Test EOP: 0.0462, Test EO: 0.0785, Test DP: 0.1486 Test AUROC: 0.8959\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2) EOP: 0.5 / EO: 0.25 / DP: 0.25"
      ],
      "metadata": {
        "id": "BvEUzyUUTDZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 함수\n",
        "def train_model(model, train_loader, criterion, optimizer, device, lambda_fairness=0.01):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    total_fairness_loss = 0\n",
        "    total_eop = 0\n",
        "    total_eo = 0\n",
        "    total_dp = 0\n",
        "    total_batches = 0\n",
        "\n",
        "    for batch_x, batch_y, batch_sensitive in train_loader:\n",
        "        batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
        "        batch_sensitive = batch_sensitive.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 예측 및 분류 손실\n",
        "        outputs = model(batch_x)\n",
        "        classification_loss = criterion(outputs, batch_y)\n",
        "\n",
        "        # 공정성 손실 계산\n",
        "        probabilities = torch.softmax(outputs, dim=1)[:, 1]  # Probability of class 1\n",
        "\n",
        "        # To avoid NaNs, ensure that probabilities are between 0 and 1\n",
        "        probabilities = torch.clamp(probabilities, min=0.0, max=1.0)\n",
        "\n",
        "        # 공정성 지표 계산\n",
        "        eop = FairnessMetrics.equal_opportunity_difference(probabilities, batch_y, batch_sensitive, target_label=1)\n",
        "        eo = FairnessMetrics.equalized_odds_difference(probabilities, batch_y, batch_sensitive, target_label=1, epsilon=1e-6)\n",
        "        dp = FairnessMetrics.demographic_parity_difference(probabilities, batch_sensitive)\n",
        "\n",
        "        # 공정성 가중치 조정\n",
        "        a = 0.5\n",
        "        b = 0.25\n",
        "        c = 0.25\n",
        "\n",
        "\n",
        "        # 공정성 손실 합산\n",
        "        fairness_loss = (a * eop) + (b * eo) +  (c * dp)\n",
        "\n",
        "        # 전체 손실 결합\n",
        "        total_loss_batch = classification_loss + lambda_fairness * fairness_loss\n",
        "        total_loss_batch.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # 손실 및 공정성 지표 기록\n",
        "        total_loss += classification_loss.item()\n",
        "        total_fairness_loss += fairness_loss.item()\n",
        "        total_eop += eop.item()\n",
        "        total_eo += eo.item()\n",
        "        total_dp += dp.item()\n",
        "        total_batches += 1\n",
        "\n",
        "    avg_loss = total_loss / total_batches\n",
        "    avg_fairness_loss = total_fairness_loss / total_batches\n",
        "    avg_eop = total_eop / total_batches\n",
        "    avg_eo = total_eo / total_batches\n",
        "    avg_dp = total_dp / total_batches\n",
        "\n",
        "    return avg_loss, avg_fairness_loss, avg_eop, avg_eo, avg_dp\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# 모델 초기화\n",
        "input_dim = X_train.shape[1]\n",
        "hidden_dim = 128\n",
        "num_heads = 4\n",
        "num_classes = 2\n",
        "\n",
        "model = FairnessAwareTransformerClassifier(input_dim, hidden_dim, num_heads, num_classes).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "num_epochs = 10  # 충분한 학습을 위해 epoch 수 증가\n",
        "\n",
        "# 기록을 위한 리스트 초기화\n",
        "train_fairness_history = {\n",
        "    'loss': [],\n",
        "    'fairness_loss': [],\n",
        "    'EOP': [],\n",
        "    'EO': [],\n",
        "    'DP': []\n",
        "}\n",
        "test_fairness_history = {\n",
        "    'accuracy': [],\n",
        "    'EOP': [],\n",
        "    'EO': [],\n",
        "    'DP': []\n",
        "}\n",
        "\n",
        "for epoch in tqdm(range(num_epochs), desc=\"Training\"):\n",
        "    train_loss, train_fairness_loss, train_eop, train_eo, train_dp = train_model(\n",
        "        model, train_loader, criterion, optimizer,\n",
        "        device, lambda_fairness=0.1\n",
        "    )\n",
        "    test_acc, test_eop, test_eo, test_dp, test_auroc = evaluate_model(model, test_loader, device)\n",
        "\n",
        "    # 기록 저장\n",
        "    train_fairness_history['loss'].append(train_loss)\n",
        "    train_fairness_history['fairness_loss'].append(train_fairness_loss)\n",
        "    train_fairness_history['EOP'].append(train_eop)\n",
        "    train_fairness_history['EO'].append(train_eo)\n",
        "    train_fairness_history['DP'].append(train_dp)\n",
        "\n",
        "    test_fairness_history['accuracy'].append(test_acc)\n",
        "    test_fairness_history['EOP'].append(test_eop)\n",
        "    test_fairness_history['EO'].append(test_eo)\n",
        "    test_fairness_history['DP'].append(test_dp)\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], '\n",
        "          f'Loss: {train_loss:.4f}, '\n",
        "          f'Fairness Loss: {train_fairness_loss:.4f}, '\n",
        "          f'EOP: {train_eop:.4f}, '\n",
        "          f'EO: {train_eo:.4f}, '\n",
        "          f'DP: {train_dp:.4f}, '\n",
        "          f'Test Accuracy: {test_acc:.2f}%, '\n",
        "          f'Test EOP: {test_eop:.4f}, '\n",
        "          f'Test EO: {test_eo:.4f}, '\n",
        "          f'Test DP: {test_dp:.4f}',\n",
        "          f'Test AUROC: {test_auroc:.4f}')"
      ],
      "metadata": {
        "id": "xsb_oMNMImbf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9de66d5e-adad-40ad-a8eb-11929fdd7bab"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  10%|█         | 1/10 [00:07<01:03,  7.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.4562, Fairness Loss: 0.1344, EOP: 0.1498, EO: 0.1566, DP: 0.0815, Test Accuracy: 79.73%, Test EOP: 0.0976, Test EO: 0.0976, Test DP: 0.1070 Test AUROC: 0.8447\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  20%|██        | 2/10 [00:14<00:57,  7.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/10], Loss: 0.4016, Fairness Loss: 0.1844, EOP: 0.2001, EO: 0.2094, DP: 0.1282, Test Accuracy: 83.13%, Test EOP: 0.1036, Test EO: 0.1036, Test DP: 0.1474 Test AUROC: 0.8666\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  30%|███       | 3/10 [00:21<00:51,  7.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3/10], Loss: 0.3736, Fairness Loss: 0.2035, EOP: 0.2168, EO: 0.2310, DP: 0.1496, Test Accuracy: 83.42%, Test EOP: 0.0970, Test EO: 0.0970, Test DP: 0.1385 Test AUROC: 0.8775\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  40%|████      | 4/10 [00:28<00:42,  7.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4/10], Loss: 0.3681, Fairness Loss: 0.1894, EOP: 0.1984, EO: 0.2140, DP: 0.1466, Test Accuracy: 83.91%, Test EOP: 0.1105, Test EO: 0.1105, Test DP: 0.1870 Test AUROC: 0.8837\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  50%|█████     | 5/10 [00:36<00:36,  7.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/10], Loss: 0.3618, Fairness Loss: 0.1968, EOP: 0.2045, EO: 0.2210, DP: 0.1575, Test Accuracy: 84.30%, Test EOP: 0.0809, Test EO: 0.1125, Test DP: 0.1858 Test AUROC: 0.8885\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  60%|██████    | 6/10 [00:43<00:28,  7.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [6/10], Loss: 0.3569, Fairness Loss: 0.1894, EOP: 0.1968, EO: 0.2140, DP: 0.1501, Test Accuracy: 83.60%, Test EOP: 0.0199, Test EO: 0.0704, Test DP: 0.1229 Test AUROC: 0.8879\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  70%|███████   | 7/10 [00:50<00:21,  7.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [7/10], Loss: 0.3555, Fairness Loss: 0.1840, EOP: 0.1891, EO: 0.2064, DP: 0.1514, Test Accuracy: 84.37%, Test EOP: 0.0244, Test EO: 0.0917, Test DP: 0.1499 Test AUROC: 0.8889\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  80%|████████  | 8/10 [00:57<00:14,  7.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [8/10], Loss: 0.3516, Fairness Loss: 0.1930, EOP: 0.2007, EO: 0.2177, DP: 0.1528, Test Accuracy: 84.38%, Test EOP: 0.0562, Test EO: 0.0938, Test DP: 0.1623 Test AUROC: 0.8917\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  90%|█████████ | 9/10 [01:05<00:07,  7.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [9/10], Loss: 0.3506, Fairness Loss: 0.1977, EOP: 0.2035, EO: 0.2232, DP: 0.1606, Test Accuracy: 84.14%, Test EOP: 0.0378, Test EO: 0.0753, Test DP: 0.1399 Test AUROC: 0.8895\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 10/10 [01:12<00:00,  7.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/10], Loss: 0.3492, Fairness Loss: 0.1991, EOP: 0.2074, EO: 0.2234, DP: 0.1583, Test Accuracy: 84.07%, Test EOP: 0.0347, Test EO: 0.1092, Test DP: 0.1762 Test AUROC: 0.8898\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3) EOP: 0.9 / EO: 0.05 / DP: 0.05"
      ],
      "metadata": {
        "id": "oZGMGaiRTFrK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 함수\n",
        "def train_model(model, train_loader, criterion, optimizer, device, lambda_fairness=0.01):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    total_fairness_loss = 0\n",
        "    total_eop = 0\n",
        "    total_eo = 0\n",
        "    total_dp = 0\n",
        "    total_batches = 0\n",
        "\n",
        "    for batch_x, batch_y, batch_sensitive in train_loader:\n",
        "        batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
        "        batch_sensitive = batch_sensitive.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 예측 및 분류 손실\n",
        "        outputs = model(batch_x)\n",
        "        classification_loss = criterion(outputs, batch_y)\n",
        "\n",
        "        # 공정성 손실 계산\n",
        "        probabilities = torch.softmax(outputs, dim=1)[:, 1]  # Probability of class 1\n",
        "\n",
        "        # To avoid NaNs, ensure that probabilities are between 0 and 1\n",
        "        probabilities = torch.clamp(probabilities, min=0.0, max=1.0)\n",
        "\n",
        "        # 공정성 지표 계산\n",
        "        eop = FairnessMetrics.equal_opportunity_difference(probabilities, batch_y, batch_sensitive, target_label=1)\n",
        "        eo = FairnessMetrics.equalized_odds_difference(probabilities, batch_y, batch_sensitive, target_label=1, epsilon=1e-6)\n",
        "        dp = FairnessMetrics.demographic_parity_difference(probabilities, batch_sensitive)\n",
        "\n",
        "        # 공정성 가중치 조정\n",
        "        a = 0.9\n",
        "        b = 0.05\n",
        "        c = 0.05\n",
        "\n",
        "\n",
        "        # 공정성 손실 합산\n",
        "        fairness_loss = (a * eop) + (b * eo) +  (c * dp)\n",
        "\n",
        "        # 전체 손실 결합\n",
        "        total_loss_batch = classification_loss + lambda_fairness * fairness_loss\n",
        "        total_loss_batch.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # 손실 및 공정성 지표 기록\n",
        "        total_loss += classification_loss.item()\n",
        "        total_fairness_loss += fairness_loss.item()\n",
        "        total_eop += eop.item()\n",
        "        total_eo += eo.item()\n",
        "        total_dp += dp.item()\n",
        "        total_batches += 1\n",
        "\n",
        "    avg_loss = total_loss / total_batches\n",
        "    avg_fairness_loss = total_fairness_loss / total_batches\n",
        "    avg_eop = total_eop / total_batches\n",
        "    avg_eo = total_eo / total_batches\n",
        "    avg_dp = total_dp / total_batches\n",
        "\n",
        "    return avg_loss, avg_fairness_loss, avg_eop, avg_eo, avg_dp\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# 모델 초기화\n",
        "input_dim = X_train.shape[1]\n",
        "hidden_dim = 128\n",
        "num_heads = 4\n",
        "num_classes = 2\n",
        "\n",
        "model = FairnessAwareTransformerClassifier(input_dim, hidden_dim, num_heads, num_classes).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "num_epochs = 10  # 충분한 학습을 위해 epoch 수 증가\n",
        "\n",
        "# 기록을 위한 리스트 초기화\n",
        "train_fairness_history = {\n",
        "    'loss': [],\n",
        "    'fairness_loss': [],\n",
        "    'EOP': [],\n",
        "    'EO': [],\n",
        "    'DP': []\n",
        "}\n",
        "test_fairness_history = {\n",
        "    'accuracy': [],\n",
        "    'EOP': [],\n",
        "    'EO': [],\n",
        "    'DP': []\n",
        "}\n",
        "\n",
        "for epoch in tqdm(range(num_epochs), desc=\"Training\"):\n",
        "    train_loss, train_fairness_loss, train_eop, train_eo, train_dp = train_model(\n",
        "        model, train_loader, criterion, optimizer,\n",
        "        device, lambda_fairness=0.1\n",
        "    )\n",
        "    test_acc, test_eop, test_eo, test_dp, test_auroc = evaluate_model(model, test_loader, device)\n",
        "\n",
        "    # 기록 저장\n",
        "    train_fairness_history['loss'].append(train_loss)\n",
        "    train_fairness_history['fairness_loss'].append(train_fairness_loss)\n",
        "    train_fairness_history['EOP'].append(train_eop)\n",
        "    train_fairness_history['EO'].append(train_eo)\n",
        "    train_fairness_history['DP'].append(train_dp)\n",
        "\n",
        "    test_fairness_history['accuracy'].append(test_acc)\n",
        "    test_fairness_history['EOP'].append(test_eop)\n",
        "    test_fairness_history['EO'].append(test_eo)\n",
        "    test_fairness_history['DP'].append(test_dp)\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], '\n",
        "          f'Loss: {train_loss:.4f}, '\n",
        "          f'Fairness Loss: {train_fairness_loss:.4f}, '\n",
        "          f'EOP: {train_eop:.4f}, '\n",
        "          f'EO: {train_eo:.4f}, '\n",
        "          f'DP: {train_dp:.4f}, '\n",
        "          f'Test Accuracy: {test_acc:.2f}%, '\n",
        "          f'Test EOP: {test_eop:.4f}, '\n",
        "          f'Test EO: {test_eo:.4f}, '\n",
        "          f'Test DP: {test_dp:.4f}',\n",
        "          f'Test AUROC: {test_auroc:.4f}')"
      ],
      "metadata": {
        "id": "cDmRKxQyImZA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1843e3a8-4371-40d3-f732-2a427b178e08"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  10%|█         | 1/10 [00:06<01:02,  6.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.4279, Fairness Loss: 0.1901, EOP: 0.1938, EO: 0.2018, DP: 0.1117, Test Accuracy: 82.09%, Test EOP: 0.0888, Test EO: 0.0888, Test DP: 0.1127 Test AUROC: 0.8485\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  20%|██        | 2/10 [00:14<00:58,  7.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/10], Loss: 0.3925, Fairness Loss: 0.1945, EOP: 0.1973, EO: 0.2079, DP: 0.1315, Test Accuracy: 81.99%, Test EOP: 0.1048, Test EO: 0.1048, Test DP: 0.1219 Test AUROC: 0.8617\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  30%|███       | 3/10 [00:21<00:50,  7.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3/10], Loss: 0.3843, Fairness Loss: 0.1973, EOP: 0.1996, EO: 0.2137, DP: 0.1398, Test Accuracy: 82.62%, Test EOP: 0.1392, Test EO: 0.1392, Test DP: 0.1748 Test AUROC: 0.8606\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  40%|████      | 4/10 [00:29<00:44,  7.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4/10], Loss: 0.3771, Fairness Loss: 0.2309, EOP: 0.2340, EO: 0.2454, DP: 0.1590, Test Accuracy: 82.94%, Test EOP: 0.1386, Test EO: 0.1386, Test DP: 0.1697 Test AUROC: 0.8688\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  50%|█████     | 5/10 [00:37<00:37,  7.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/10], Loss: 0.3986, Fairness Loss: 0.2019, EOP: 0.2040, EO: 0.2190, DP: 0.1464, Test Accuracy: 81.35%, Test EOP: 0.1161, Test EO: 0.1161, Test DP: 0.1671 Test AUROC: 0.8598\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  60%|██████    | 6/10 [00:44<00:30,  7.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [6/10], Loss: 0.4105, Fairness Loss: 0.1967, EOP: 0.1990, EO: 0.2118, DP: 0.1396, Test Accuracy: 78.68%, Test EOP: 0.0887, Test EO: 0.0887, Test DP: 0.0897 Test AUROC: 0.8452\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  70%|███████   | 7/10 [00:52<00:23,  7.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [7/10], Loss: 0.4835, Fairness Loss: 0.1357, EOP: 0.1389, EO: 0.1434, DP: 0.0692, Test Accuracy: 76.07%, Test EOP: 0.0001, Test EO: 0.0001, Test DP: 0.0000 Test AUROC: 0.3272\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  80%|████████  | 8/10 [00:59<00:15,  7.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [8/10], Loss: 0.5090, Fairness Loss: 0.0941, EOP: 0.0964, EO: 0.1014, DP: 0.0449, Test Accuracy: 76.13%, Test EOP: 0.0191, Test EO: 0.0191, Test DP: 0.0110 Test AUROC: 0.4761\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  90%|█████████ | 9/10 [01:07<00:07,  7.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [9/10], Loss: 0.5029, Fairness Loss: 0.0974, EOP: 0.0998, EO: 0.1047, DP: 0.0475, Test Accuracy: 80.63%, Test EOP: 0.0816, Test EO: 0.0816, Test DP: 0.0827 Test AUROC: 0.7934\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 10/10 [01:15<00:00,  7.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/10], Loss: 0.4213, Fairness Loss: 0.2116, EOP: 0.2164, EO: 0.2220, DP: 0.1160, Test Accuracy: 76.14%, Test EOP: 0.0292, Test EO: 0.0404, Test DP: 0.0588 Test AUROC: 0.8682\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4) EOP:0.4 / OP:0.2 / DP:0.4"
      ],
      "metadata": {
        "id": "57V39gPWTGKy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 함수\n",
        "def train_model(model, train_loader, criterion, optimizer, device, lambda_fairness=0.01):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    total_fairness_loss = 0\n",
        "    total_eop = 0\n",
        "    total_eo = 0\n",
        "    total_dp = 0\n",
        "    total_batches = 0\n",
        "\n",
        "    for batch_x, batch_y, batch_sensitive in train_loader:\n",
        "        batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
        "        batch_sensitive = batch_sensitive.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 예측 및 분류 손실\n",
        "        outputs = model(batch_x)\n",
        "        classification_loss = criterion(outputs, batch_y)\n",
        "\n",
        "        # 공정성 손실 계산\n",
        "        probabilities = torch.softmax(outputs, dim=1)[:, 1]  # Probability of class 1\n",
        "\n",
        "        # To avoid NaNs, ensure that probabilities are between 0 and 1\n",
        "        probabilities = torch.clamp(probabilities, min=0.0, max=1.0)\n",
        "\n",
        "        # 공정성 지표 계산\n",
        "        eop = FairnessMetrics.equal_opportunity_difference(probabilities, batch_y, batch_sensitive, target_label=1)\n",
        "        eo = FairnessMetrics.equalized_odds_difference(probabilities, batch_y, batch_sensitive, target_label=1, epsilon=1e-6)\n",
        "        dp = FairnessMetrics.demographic_parity_difference(probabilities, batch_sensitive)\n",
        "\n",
        "        # 공정성 가중치 조정\n",
        "        a = 0.4\n",
        "        b = 0.2\n",
        "        c = 0.4\n",
        "\n",
        "\n",
        "        # 공정성 손실 합산\n",
        "        fairness_loss = (a * eop) + (b * eo) +  (c * dp)\n",
        "\n",
        "        # 전체 손실 결합\n",
        "        total_loss_batch = classification_loss + lambda_fairness * fairness_loss\n",
        "        total_loss_batch.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # 손실 및 공정성 지표 기록\n",
        "        total_loss += classification_loss.item()\n",
        "        total_fairness_loss += fairness_loss.item()\n",
        "        total_eop += eop.item()\n",
        "        total_eo += eo.item()\n",
        "        total_dp += dp.item()\n",
        "        total_batches += 1\n",
        "\n",
        "    avg_loss = total_loss / total_batches\n",
        "    avg_fairness_loss = total_fairness_loss / total_batches\n",
        "    avg_eop = total_eop / total_batches\n",
        "    avg_eo = total_eo / total_batches\n",
        "    avg_dp = total_dp / total_batches\n",
        "\n",
        "    return avg_loss, avg_fairness_loss, avg_eop, avg_eo, avg_dp\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# 모델 초기화\n",
        "input_dim = X_train.shape[1]\n",
        "hidden_dim = 128\n",
        "num_heads = 4\n",
        "num_classes = 2\n",
        "\n",
        "model = FairnessAwareTransformerClassifier(input_dim, hidden_dim, num_heads, num_classes).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "num_epochs = 10  # 충분한 학습을 위해 epoch 수 증가\n",
        "\n",
        "# 기록을 위한 리스트 초기화\n",
        "train_fairness_history = {\n",
        "    'loss': [],\n",
        "    'fairness_loss': [],\n",
        "    'EOP': [],\n",
        "    'EO': [],\n",
        "    'DP': []\n",
        "}\n",
        "test_fairness_history = {\n",
        "    'accuracy': [],\n",
        "    'EOP': [],\n",
        "    'EO': [],\n",
        "    'DP': []\n",
        "}\n",
        "\n",
        "for epoch in tqdm(range(num_epochs), desc=\"Training\"):\n",
        "    train_loss, train_fairness_loss, train_eop, train_eo, train_dp = train_model(\n",
        "        model, train_loader, criterion, optimizer,\n",
        "        device, lambda_fairness=0.1\n",
        "    )\n",
        "    test_acc, test_eop, test_eo, test_dp, test_auroc = evaluate_model(model, test_loader, device)\n",
        "\n",
        "    # 기록 저장\n",
        "    train_fairness_history['loss'].append(train_loss)\n",
        "    train_fairness_history['fairness_loss'].append(train_fairness_loss)\n",
        "    train_fairness_history['EOP'].append(train_eop)\n",
        "    train_fairness_history['EO'].append(train_eo)\n",
        "    train_fairness_history['DP'].append(train_dp)\n",
        "\n",
        "    test_fairness_history['accuracy'].append(test_acc)\n",
        "    test_fairness_history['EOP'].append(test_eop)\n",
        "    test_fairness_history['EO'].append(test_eo)\n",
        "    test_fairness_history['DP'].append(test_dp)\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], '\n",
        "          f'Loss: {train_loss:.4f}, '\n",
        "          f'Fairness Loss: {train_fairness_loss:.4f}, '\n",
        "          f'EOP: {train_eop:.4f}, '\n",
        "          f'EO: {train_eo:.4f}, '\n",
        "          f'DP: {train_dp:.4f}, '\n",
        "          f'Test Accuracy: {test_acc:.2f}%, '\n",
        "          f'Test EOP: {test_eop:.4f}, '\n",
        "          f'Test EO: {test_eo:.4f}, '\n",
        "          f'Test DP: {test_dp:.4f}',\n",
        "          f'Test AUROC: {test_auroc:.4f}')"
      ],
      "metadata": {
        "id": "ikCgH_-VImXB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54d7ada6-d809-4413-c86e-093300eb33f1"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  10%|█         | 1/10 [00:07<01:04,  7.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.4303, Fairness Loss: 0.1521, EOP: 0.1681, EO: 0.1807, DP: 0.1219, Test Accuracy: 82.41%, Test EOP: 0.0831, Test EO: 0.0956, Test DP: 0.1622 Test AUROC: 0.8735\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  20%|██        | 2/10 [00:14<00:59,  7.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/10], Loss: 0.3650, Fairness Loss: 0.1800, EOP: 0.1915, EO: 0.2107, DP: 0.1531, Test Accuracy: 83.90%, Test EOP: 0.0408, Test EO: 0.0905, Test DP: 0.1572 Test AUROC: 0.8872\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  30%|███       | 3/10 [00:21<00:50,  7.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3/10], Loss: 0.3512, Fairness Loss: 0.1887, EOP: 0.2009, EO: 0.2239, DP: 0.1589, Test Accuracy: 83.88%, Test EOP: 0.0565, Test EO: 0.0932, Test DP: 0.1637 Test AUROC: 0.8894\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  40%|████      | 4/10 [00:29<00:44,  7.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4/10], Loss: 0.3482, Fairness Loss: 0.1879, EOP: 0.2013, EO: 0.2205, DP: 0.1582, Test Accuracy: 84.35%, Test EOP: 0.0500, Test EO: 0.0966, Test DP: 0.1588 Test AUROC: 0.8921\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  50%|█████     | 5/10 [00:36<00:36,  7.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/10], Loss: 0.3445, Fairness Loss: 0.1885, EOP: 0.2002, EO: 0.2194, DP: 0.1614, Test Accuracy: 83.71%, Test EOP: 0.0319, Test EO: 0.0873, Test DP: 0.1514 Test AUROC: 0.8917\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  60%|██████    | 6/10 [00:43<00:29,  7.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [6/10], Loss: 0.3442, Fairness Loss: 0.1908, EOP: 0.2041, EO: 0.2217, DP: 0.1620, Test Accuracy: 84.38%, Test EOP: 0.0372, Test EO: 0.1028, Test DP: 0.1681 Test AUROC: 0.8938\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  70%|███████   | 7/10 [00:51<00:22,  7.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [7/10], Loss: 0.3406, Fairness Loss: 0.1833, EOP: 0.1914, EO: 0.2134, DP: 0.1602, Test Accuracy: 84.27%, Test EOP: 0.0345, Test EO: 0.0974, Test DP: 0.1647 Test AUROC: 0.8938\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  80%|████████  | 8/10 [00:58<00:14,  7.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [8/10], Loss: 0.3392, Fairness Loss: 0.1950, EOP: 0.2109, EO: 0.2293, DP: 0.1619, Test Accuracy: 84.35%, Test EOP: 0.0146, Test EO: 0.0956, Test DP: 0.1651 Test AUROC: 0.8928\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  90%|█████████ | 9/10 [01:05<00:07,  7.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [9/10], Loss: 0.3393, Fairness Loss: 0.1884, EOP: 0.1998, EO: 0.2183, DP: 0.1621, Test Accuracy: 84.36%, Test EOP: 0.0267, Test EO: 0.0828, Test DP: 0.1489 Test AUROC: 0.8929\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 10/10 [01:12<00:00,  7.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/10], Loss: 0.3392, Fairness Loss: 0.1970, EOP: 0.2091, EO: 0.2301, DP: 0.1684, Test Accuracy: 84.17%, Test EOP: 0.0460, Test EO: 0.1124, Test DP: 0.1831 Test AUROC: 0.8934\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5) EOP:0.45 / OP:0.1 / DP:0.45"
      ],
      "metadata": {
        "id": "YpVpyciYTHJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 함수\n",
        "def train_model(model, train_loader, criterion, optimizer, device, lambda_fairness=0.01):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    total_fairness_loss = 0\n",
        "    total_eop = 0\n",
        "    total_eo = 0\n",
        "    total_dp = 0\n",
        "    total_batches = 0\n",
        "\n",
        "    for batch_x, batch_y, batch_sensitive in train_loader:\n",
        "        batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
        "        batch_sensitive = batch_sensitive.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 예측 및 분류 손실\n",
        "        outputs = model(batch_x)\n",
        "        classification_loss = criterion(outputs, batch_y)\n",
        "\n",
        "        # 공정성 손실 계산\n",
        "        probabilities = torch.softmax(outputs, dim=1)[:, 1]  # Probability of class 1\n",
        "\n",
        "        # To avoid NaNs, ensure that probabilities are between 0 and 1\n",
        "        probabilities = torch.clamp(probabilities, min=0.0, max=1.0)\n",
        "\n",
        "        # 공정성 지표 계산\n",
        "        eop = FairnessMetrics.equal_opportunity_difference(probabilities, batch_y, batch_sensitive, target_label=1)\n",
        "        eo = FairnessMetrics.equalized_odds_difference(probabilities, batch_y, batch_sensitive, target_label=1, epsilon=1e-6)\n",
        "        dp = FairnessMetrics.demographic_parity_difference(probabilities, batch_sensitive)\n",
        "\n",
        "        # 공정성 가중치 조정\n",
        "        a = 0.45\n",
        "        b = 0.1\n",
        "        c = 0.45\n",
        "\n",
        "\n",
        "        # 공정성 손실 합산\n",
        "        fairness_loss = (a * eop) + (b * eo) +  (c * dp)\n",
        "\n",
        "        # 전체 손실 결합\n",
        "        total_loss_batch = classification_loss + lambda_fairness * fairness_loss\n",
        "        total_loss_batch.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # 손실 및 공정성 지표 기록\n",
        "        total_loss += classification_loss.item()\n",
        "        total_fairness_loss += fairness_loss.item()\n",
        "        total_eop += eop.item()\n",
        "        total_eo += eo.item()\n",
        "        total_dp += dp.item()\n",
        "        total_batches += 1\n",
        "\n",
        "    avg_loss = total_loss / total_batches\n",
        "    avg_fairness_loss = total_fairness_loss / total_batches\n",
        "    avg_eop = total_eop / total_batches\n",
        "    avg_eo = total_eo / total_batches\n",
        "    avg_dp = total_dp / total_batches\n",
        "\n",
        "    return avg_loss, avg_fairness_loss, avg_eop, avg_eo, avg_dp\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# 모델 초기화\n",
        "input_dim = X_train.shape[1]\n",
        "hidden_dim = 128\n",
        "num_heads = 4\n",
        "num_classes = 2\n",
        "\n",
        "model = FairnessAwareTransformerClassifier(input_dim, hidden_dim, num_heads, num_classes).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "num_epochs = 10  # 충분한 학습을 위해 epoch 수 증가\n",
        "\n",
        "# 기록을 위한 리스트 초기화\n",
        "train_fairness_history = {\n",
        "    'loss': [],\n",
        "    'fairness_loss': [],\n",
        "    'EOP': [],\n",
        "    'EO': [],\n",
        "    'DP': []\n",
        "}\n",
        "test_fairness_history = {\n",
        "    'accuracy': [],\n",
        "    'EOP': [],\n",
        "    'EO': [],\n",
        "    'DP': []\n",
        "}\n",
        "\n",
        "for epoch in tqdm(range(num_epochs), desc=\"Training\"):\n",
        "    train_loss, train_fairness_loss, train_eop, train_eo, train_dp = train_model(\n",
        "        model, train_loader, criterion, optimizer,\n",
        "        device, lambda_fairness=0.1\n",
        "    )\n",
        "    test_acc, test_eop, test_eo, test_dp, test_auroc = evaluate_model(model, test_loader, device)\n",
        "\n",
        "    # 기록 저장\n",
        "    train_fairness_history['loss'].append(train_loss)\n",
        "    train_fairness_history['fairness_loss'].append(train_fairness_loss)\n",
        "    train_fairness_history['EOP'].append(train_eop)\n",
        "    train_fairness_history['EO'].append(train_eo)\n",
        "    train_fairness_history['DP'].append(train_dp)\n",
        "\n",
        "    test_fairness_history['accuracy'].append(test_acc)\n",
        "    test_fairness_history['EOP'].append(test_eop)\n",
        "    test_fairness_history['EO'].append(test_eo)\n",
        "    test_fairness_history['DP'].append(test_dp)\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], '\n",
        "          f'Loss: {train_loss:.4f}, '\n",
        "          f'Fairness Loss: {train_fairness_loss:.4f}, '\n",
        "          f'EOP: {train_eop:.4f}, '\n",
        "          f'EO: {train_eo:.4f}, '\n",
        "          f'DP: {train_dp:.4f}, '\n",
        "          f'Test Accuracy: {test_acc:.2f}%, '\n",
        "          f'Test EOP: {test_eop:.4f}, '\n",
        "          f'Test EO: {test_eo:.4f}, '\n",
        "          f'Test DP: {test_dp:.4f}',\n",
        "          f'Test AUROC: {test_auroc:.4f}')"
      ],
      "metadata": {
        "id": "bN6MNKr-ImU5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e97ef3e0-b011-4caf-8ce7-6487d7adb7e8"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  10%|█         | 1/10 [00:07<01:08,  7.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.4489, Fairness Loss: 0.1508, EOP: 0.1849, EO: 0.1925, DP: 0.1074, Test Accuracy: 79.56%, Test EOP: 0.1401, Test EO: 0.1401, Test DP: 0.1411 Test AUROC: 0.8331\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  20%|██        | 2/10 [00:14<00:58,  7.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/10], Loss: 0.4246, Fairness Loss: 0.1671, EOP: 0.2071, EO: 0.2139, DP: 0.1167, Test Accuracy: 76.50%, Test EOP: 0.1195, Test EO: 0.1195, Test DP: 0.1186 Test AUROC: 0.8009\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  30%|███       | 3/10 [00:22<00:51,  7.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3/10], Loss: 0.4519, Fairness Loss: 0.1425, EOP: 0.1683, EO: 0.1792, DP: 0.1084, Test Accuracy: 80.40%, Test EOP: 0.1410, Test EO: 0.1410, Test DP: 0.1269 Test AUROC: 0.8313\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  40%|████      | 4/10 [00:29<00:44,  7.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4/10], Loss: 0.4470, Fairness Loss: 0.1420, EOP: 0.1647, EO: 0.1778, DP: 0.1115, Test Accuracy: 76.07%, Test EOP: 0.0842, Test EO: 0.0842, Test DP: 0.0934 Test AUROC: 0.7797\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  50%|█████     | 5/10 [00:36<00:36,  7.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/10], Loss: 0.4542, Fairness Loss: 0.1338, EOP: 0.1525, EO: 0.1649, DP: 0.1082, Test Accuracy: 76.08%, Test EOP: 0.1047, Test EO: 0.1047, Test DP: 0.1095 Test AUROC: 0.7895\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  60%|██████    | 6/10 [00:44<00:29,  7.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [6/10], Loss: 0.4387, Fairness Loss: 0.1515, EOP: 0.1773, EO: 0.1894, DP: 0.1173, Test Accuracy: 81.05%, Test EOP: 0.1497, Test EO: 0.1497, Test DP: 0.1252 Test AUROC: 0.8377\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  70%|███████   | 7/10 [00:51<00:21,  7.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [7/10], Loss: 0.4199, Fairness Loss: 0.1770, EOP: 0.2106, EO: 0.2212, DP: 0.1337, Test Accuracy: 79.42%, Test EOP: 0.1628, Test EO: 0.1628, Test DP: 0.1434 Test AUROC: 0.8254\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  80%|████████  | 8/10 [00:59<00:14,  7.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [8/10], Loss: 0.4219, Fairness Loss: 0.1740, EOP: 0.2076, EO: 0.2156, DP: 0.1311, Test Accuracy: 80.18%, Test EOP: 0.1611, Test EO: 0.1611, Test DP: 0.1454 Test AUROC: 0.8341\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  90%|█████████ | 9/10 [01:06<00:07,  7.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [9/10], Loss: 0.4258, Fairness Loss: 0.1697, EOP: 0.2076, EO: 0.2158, DP: 0.1216, Test Accuracy: 81.16%, Test EOP: 0.1474, Test EO: 0.1474, Test DP: 0.1314 Test AUROC: 0.8296\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 10/10 [01:13<00:00,  7.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/10], Loss: 0.4253, Fairness Loss: 0.1703, EOP: 0.2123, EO: 0.2179, DP: 0.1178, Test Accuracy: 81.35%, Test EOP: 0.1432, Test EO: 0.1432, Test DP: 0.1171 Test AUROC: 0.8220\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6) EOP:0.5 / OP:0 / DP:0.5"
      ],
      "metadata": {
        "id": "pIC_WTPyTHoS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 함수\n",
        "def train_model(model, train_loader, criterion, optimizer, device, lambda_fairness=0.01):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    total_fairness_loss = 0\n",
        "    total_eop = 0\n",
        "    total_eo = 0\n",
        "    total_dp = 0\n",
        "    total_batches = 0\n",
        "\n",
        "    for batch_x, batch_y, batch_sensitive in train_loader:\n",
        "        batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
        "        batch_sensitive = batch_sensitive.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 예측 및 분류 손실\n",
        "        outputs = model(batch_x)\n",
        "        classification_loss = criterion(outputs, batch_y)\n",
        "\n",
        "        # 공정성 손실 계산\n",
        "        probabilities = torch.softmax(outputs, dim=1)[:, 1]  # Probability of class 1\n",
        "\n",
        "        # To avoid NaNs, ensure that probabilities are between 0 and 1\n",
        "        probabilities = torch.clamp(probabilities, min=0.0, max=1.0)\n",
        "\n",
        "        # 공정성 지표 계산\n",
        "        eop = FairnessMetrics.equal_opportunity_difference(probabilities, batch_y, batch_sensitive, target_label=1)\n",
        "        eo = FairnessMetrics.equalized_odds_difference(probabilities, batch_y, batch_sensitive, target_label=1, epsilon=1e-6)\n",
        "        dp = FairnessMetrics.demographic_parity_difference(probabilities, batch_sensitive)\n",
        "\n",
        "        # 공정성 가중치 조정\n",
        "        a = 0.5\n",
        "        b = 0\n",
        "        c = 0.5\n",
        "\n",
        "\n",
        "        # 공정성 손실 합산\n",
        "        fairness_loss = (a * eop) + (b * eo) +  (c * dp)\n",
        "\n",
        "        # 전체 손실 결합\n",
        "        total_loss_batch = classification_loss + lambda_fairness * fairness_loss\n",
        "        total_loss_batch.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # 손실 및 공정성 지표 기록\n",
        "        total_loss += classification_loss.item()\n",
        "        total_fairness_loss += fairness_loss.item()\n",
        "        total_eop += eop.item()\n",
        "        total_eo += eo.item()\n",
        "        total_dp += dp.item()\n",
        "        total_batches += 1\n",
        "\n",
        "    avg_loss = total_loss / total_batches\n",
        "    avg_fairness_loss = total_fairness_loss / total_batches\n",
        "    avg_eop = total_eop / total_batches\n",
        "    avg_eo = total_eo / total_batches\n",
        "    avg_dp = total_dp / total_batches\n",
        "\n",
        "    return avg_loss, avg_fairness_loss, avg_eop, avg_eo, avg_dp\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# 모델 초기화\n",
        "input_dim = X_train.shape[1]\n",
        "hidden_dim = 128\n",
        "num_heads = 4\n",
        "num_classes = 2\n",
        "\n",
        "model = FairnessAwareTransformerClassifier(input_dim, hidden_dim, num_heads, num_classes).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "num_epochs = 10  # 충분한 학습을 위해 epoch 수 증가\n",
        "\n",
        "# 기록을 위한 리스트 초기화\n",
        "train_fairness_history = {\n",
        "    'loss': [],\n",
        "    'fairness_loss': [],\n",
        "    'EOP': [],\n",
        "    'EO': [],\n",
        "    'DP': []\n",
        "}\n",
        "test_fairness_history = {\n",
        "    'accuracy': [],\n",
        "    'EOP': [],\n",
        "    'EO': [],\n",
        "    'DP': []\n",
        "}\n",
        "\n",
        "for epoch in tqdm(range(num_epochs), desc=\"Training\"):\n",
        "    train_loss, train_fairness_loss, train_eop, train_eo, train_dp = train_model(\n",
        "        model, train_loader, criterion, optimizer,\n",
        "        device, lambda_fairness=0.1\n",
        "    )\n",
        "    test_acc, test_eop, test_eo, test_dp, test_auroc = evaluate_model(model, test_loader, device)\n",
        "\n",
        "    # 기록 저장\n",
        "    train_fairness_history['loss'].append(train_loss)\n",
        "    train_fairness_history['fairness_loss'].append(train_fairness_loss)\n",
        "    train_fairness_history['EOP'].append(train_eop)\n",
        "    train_fairness_history['EO'].append(train_eo)\n",
        "    train_fairness_history['DP'].append(train_dp)\n",
        "\n",
        "    test_fairness_history['accuracy'].append(test_acc)\n",
        "    test_fairness_history['EOP'].append(test_eop)\n",
        "    test_fairness_history['EO'].append(test_eo)\n",
        "    test_fairness_history['DP'].append(test_dp)\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], '\n",
        "          f'Loss: {train_loss:.4f}, '\n",
        "          f'Fairness Loss: {train_fairness_loss:.4f}, '\n",
        "          f'EOP: {train_eop:.4f}, '\n",
        "          f'EO: {train_eo:.4f}, '\n",
        "          f'DP: {train_dp:.4f}, '\n",
        "          f'Test Accuracy: {test_acc:.2f}%, '\n",
        "          f'Test EOP: {test_eop:.4f}, '\n",
        "          f'Test EO: {test_eo:.4f}, '\n",
        "          f'Test DP: {test_dp:.4f}',\n",
        "          f'Test AUROC: {test_auroc:.4f}')"
      ],
      "metadata": {
        "id": "sNXXp-YqImSz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50bedebd-d36b-49e6-881d-c1e956a3613d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  10%|█         | 1/10 [00:07<01:08,  7.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.4263, Fairness Loss: 0.1625, EOP: 0.2059, EO: 0.2133, DP: 0.1192, Test Accuracy: 82.65%, Test EOP: 0.1474, Test EO: 0.1474, Test DP: 0.1328 Test AUROC: 0.8554\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  20%|██        | 2/10 [00:14<00:57,  7.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/10], Loss: 0.3805, Fairness Loss: 0.1847, EOP: 0.2266, EO: 0.2363, DP: 0.1429, Test Accuracy: 83.69%, Test EOP: 0.1231, Test EO: 0.1231, Test DP: 0.1497 Test AUROC: 0.8783\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  30%|███       | 3/10 [00:21<00:51,  7.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3/10], Loss: 0.3612, Fairness Loss: 0.1872, EOP: 0.2191, EO: 0.2336, DP: 0.1553, Test Accuracy: 83.91%, Test EOP: 0.0987, Test EO: 0.0987, Test DP: 0.1613 Test AUROC: 0.8860\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  40%|████      | 4/10 [00:28<00:42,  7.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4/10], Loss: 0.3497, Fairness Loss: 0.1869, EOP: 0.2156, EO: 0.2314, DP: 0.1581, Test Accuracy: 83.98%, Test EOP: 0.0714, Test EO: 0.0917, Test DP: 0.1630 Test AUROC: 0.8884\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  50%|█████     | 5/10 [00:36<00:36,  7.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/10], Loss: 0.3485, Fairness Loss: 0.1736, EOP: 0.1919, EO: 0.2084, DP: 0.1554, Test Accuracy: 83.67%, Test EOP: 0.0768, Test EO: 0.0865, Test DP: 0.1554 Test AUROC: 0.8896\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  60%|██████    | 6/10 [00:43<00:29,  7.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [6/10], Loss: 0.3593, Fairness Loss: 0.1785, EOP: 0.1966, EO: 0.2148, DP: 0.1604, Test Accuracy: 83.61%, Test EOP: 0.0949, Test EO: 0.1029, Test DP: 0.1686 Test AUROC: 0.8859\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  70%|███████   | 7/10 [00:50<00:21,  7.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [7/10], Loss: 0.3534, Fairness Loss: 0.1938, EOP: 0.2189, EO: 0.2349, DP: 0.1687, Test Accuracy: 84.34%, Test EOP: 0.1083, Test EO: 0.1083, Test DP: 0.1660 Test AUROC: 0.8915\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  80%|████████  | 8/10 [00:58<00:14,  7.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [8/10], Loss: 0.3507, Fairness Loss: 0.1924, EOP: 0.2255, EO: 0.2379, DP: 0.1593, Test Accuracy: 84.32%, Test EOP: 0.0682, Test EO: 0.0856, Test DP: 0.1574 Test AUROC: 0.8865\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  90%|█████████ | 9/10 [01:05<00:07,  7.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [9/10], Loss: 0.3509, Fairness Loss: 0.1764, EOP: 0.2038, EO: 0.2207, DP: 0.1490, Test Accuracy: 84.01%, Test EOP: 0.0650, Test EO: 0.0835, Test DP: 0.1475 Test AUROC: 0.8876\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 10/10 [01:12<00:00,  7.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/10], Loss: 0.3473, Fairness Loss: 0.1896, EOP: 0.2137, EO: 0.2298, DP: 0.1655, Test Accuracy: 83.83%, Test EOP: 0.0719, Test EO: 0.0762, Test DP: 0.1425 Test AUROC: 0.8883\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7) EOP:0.45 / OP:0.45 / DP: 0.1"
      ],
      "metadata": {
        "id": "7We6PnX3TINq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 함수\n",
        "def train_model(model, train_loader, criterion, optimizer, device, lambda_fairness=0.01):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    total_fairness_loss = 0\n",
        "    total_eop = 0\n",
        "    total_eo = 0\n",
        "    total_dp = 0\n",
        "    total_batches = 0\n",
        "\n",
        "    for batch_x, batch_y, batch_sensitive in train_loader:\n",
        "        batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
        "        batch_sensitive = batch_sensitive.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 예측 및 분류 손실\n",
        "        outputs = model(batch_x)\n",
        "        classification_loss = criterion(outputs, batch_y)\n",
        "\n",
        "        # 공정성 손실 계산\n",
        "        probabilities = torch.softmax(outputs, dim=1)[:, 1]  # Probability of class 1\n",
        "\n",
        "        # To avoid NaNs, ensure that probabilities are between 0 and 1\n",
        "        probabilities = torch.clamp(probabilities, min=0.0, max=1.0)\n",
        "\n",
        "        # 공정성 지표 계산\n",
        "        eop = FairnessMetrics.equal_opportunity_difference(probabilities, batch_y, batch_sensitive, target_label=1)\n",
        "        eo = FairnessMetrics.equalized_odds_difference(probabilities, batch_y, batch_sensitive, target_label=1, epsilon=1e-6)\n",
        "        dp = FairnessMetrics.demographic_parity_difference(probabilities, batch_sensitive)\n",
        "\n",
        "        # 공정성 가중치 조정\n",
        "        a = 0.45\n",
        "        b = 0.45\n",
        "        c = 0.1\n",
        "\n",
        "\n",
        "        # 공정성 손실 합산\n",
        "        fairness_loss = (a * eop) + (b * eo) +  (c * dp)\n",
        "\n",
        "        # 전체 손실 결합\n",
        "        total_loss_batch = classification_loss + lambda_fairness * fairness_loss\n",
        "        total_loss_batch.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # 손실 및 공정성 지표 기록\n",
        "        total_loss += classification_loss.item()\n",
        "        total_fairness_loss += fairness_loss.item()\n",
        "        total_eop += eop.item()\n",
        "        total_eo += eo.item()\n",
        "        total_dp += dp.item()\n",
        "        total_batches += 1\n",
        "\n",
        "    avg_loss = total_loss / total_batches\n",
        "    avg_fairness_loss = total_fairness_loss / total_batches\n",
        "    avg_eop = total_eop / total_batches\n",
        "    avg_eo = total_eo / total_batches\n",
        "    avg_dp = total_dp / total_batches\n",
        "\n",
        "    return avg_loss, avg_fairness_loss, avg_eop, avg_eo, avg_dp\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# 모델 초기화\n",
        "input_dim = X_train.shape[1]\n",
        "hidden_dim = 128\n",
        "num_heads = 4\n",
        "num_classes = 2\n",
        "\n",
        "model = FairnessAwareTransformerClassifier(input_dim, hidden_dim, num_heads, num_classes).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "num_epochs = 10  # 충분한 학습을 위해 epoch 수 증가\n",
        "\n",
        "# 기록을 위한 리스트 초기화\n",
        "train_fairness_history = {\n",
        "    'loss': [],\n",
        "    'fairness_loss': [],\n",
        "    'EOP': [],\n",
        "    'EO': [],\n",
        "    'DP': []\n",
        "}\n",
        "test_fairness_history = {\n",
        "    'accuracy': [],\n",
        "    'EOP': [],\n",
        "    'EO': [],\n",
        "    'DP': []\n",
        "}\n",
        "\n",
        "for epoch in tqdm(range(num_epochs), desc=\"Training\"):\n",
        "    train_loss, train_fairness_loss, train_eop, train_eo, train_dp = train_model(\n",
        "        model, train_loader, criterion, optimizer,\n",
        "        device, lambda_fairness=0.1\n",
        "    )\n",
        "    test_acc, test_eop, test_eo, test_dp, test_auroc = evaluate_model(model, test_loader, device)\n",
        "\n",
        "    # 기록 저장\n",
        "    train_fairness_history['loss'].append(train_loss)\n",
        "    train_fairness_history['fairness_loss'].append(train_fairness_loss)\n",
        "    train_fairness_history['EOP'].append(train_eop)\n",
        "    train_fairness_history['EO'].append(train_eo)\n",
        "    train_fairness_history['DP'].append(train_dp)\n",
        "\n",
        "    test_fairness_history['accuracy'].append(test_acc)\n",
        "    test_fairness_history['EOP'].append(test_eop)\n",
        "    test_fairness_history['EO'].append(test_eo)\n",
        "    test_fairness_history['DP'].append(test_dp)\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], '\n",
        "          f'Loss: {train_loss:.4f}, '\n",
        "          f'Fairness Loss: {train_fairness_loss:.4f}, '\n",
        "          f'EOP: {train_eop:.4f}, '\n",
        "          f'EO: {train_eo:.4f}, '\n",
        "          f'DP: {train_dp:.4f}, '\n",
        "          f'Test Accuracy: {test_acc:.2f}%, '\n",
        "          f'Test EOP: {test_eop:.4f}, '\n",
        "          f'Test EO: {test_eo:.4f}, '\n",
        "          f'Test DP: {test_dp:.4f}',\n",
        "          f'Test AUROC: {test_auroc:.4f}')"
      ],
      "metadata": {
        "id": "mwbztk87ImQ5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1f7ce07-3118-4c17-b575-1c98ddf9f45e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  10%|█         | 1/10 [00:07<01:03,  7.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.4451, Fairness Loss: 0.1592, EOP: 0.1638, EO: 0.1699, DP: 0.0902, Test Accuracy: 80.51%, Test EOP: 0.1087, Test EO: 0.1087, Test DP: 0.1099 Test AUROC: 0.8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  20%|██        | 2/10 [00:14<00:58,  7.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/10], Loss: 0.3978, Fairness Loss: 0.1977, EOP: 0.1997, EO: 0.2108, DP: 0.1296, Test Accuracy: 82.94%, Test EOP: 0.0765, Test EO: 0.0765, Test DP: 0.1171 Test AUROC: 0.8667\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  30%|███       | 3/10 [00:21<00:51,  7.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3/10], Loss: 0.3805, Fairness Loss: 0.1988, EOP: 0.1961, EO: 0.2128, DP: 0.1482, Test Accuracy: 82.75%, Test EOP: 0.0535, Test EO: 0.0842, Test DP: 0.1362 Test AUROC: 0.8718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  40%|████      | 4/10 [00:28<00:43,  7.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4/10], Loss: 0.3728, Fairness Loss: 0.1939, EOP: 0.1932, EO: 0.2066, DP: 0.1403, Test Accuracy: 83.70%, Test EOP: 0.0624, Test EO: 0.0754, Test DP: 0.1394 Test AUROC: 0.8815\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  50%|█████     | 5/10 [00:36<00:36,  7.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/10], Loss: 0.3701, Fairness Loss: 0.1978, EOP: 0.1953, EO: 0.2116, DP: 0.1466, Test Accuracy: 84.05%, Test EOP: 0.1061, Test EO: 0.1061, Test DP: 0.1602 Test AUROC: 0.8787\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  60%|██████    | 6/10 [00:43<00:28,  7.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [6/10], Loss: 0.3652, Fairness Loss: 0.1992, EOP: 0.1956, EO: 0.2137, DP: 0.1496, Test Accuracy: 83.18%, Test EOP: 0.0530, Test EO: 0.1013, Test DP: 0.1638 Test AUROC: 0.8828\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  70%|███████   | 7/10 [00:50<00:21,  7.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [7/10], Loss: 0.3613, Fairness Loss: 0.2134, EOP: 0.2143, EO: 0.2282, DP: 0.1430, Test Accuracy: 83.66%, Test EOP: 0.0562, Test EO: 0.0985, Test DP: 0.1735 Test AUROC: 0.8853\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  80%|████████  | 8/10 [00:57<00:14,  7.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [8/10], Loss: 0.3562, Fairness Loss: 0.2042, EOP: 0.2005, EO: 0.2188, DP: 0.1556, Test Accuracy: 84.56%, Test EOP: 0.0409, Test EO: 0.0858, Test DP: 0.1448 Test AUROC: 0.8910\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  90%|█████████ | 9/10 [01:05<00:07,  7.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [9/10], Loss: 0.3543, Fairness Loss: 0.2079, EOP: 0.2075, EO: 0.2223, DP: 0.1453, Test Accuracy: 84.61%, Test EOP: 0.0324, Test EO: 0.0732, Test DP: 0.1378 Test AUROC: 0.8798\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 10/10 [01:12<00:00,  7.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/10], Loss: 0.3610, Fairness Loss: 0.1868, EOP: 0.1845, EO: 0.2000, DP: 0.1376, Test Accuracy: 83.66%, Test EOP: 0.0543, Test EO: 0.0989, Test DP: 0.1639 Test AUROC: 0.8866\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8) EOP:0.25 / OP:0.25 / DP: 0.5"
      ],
      "metadata": {
        "id": "V3WvT7q8TIrU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 함수\n",
        "def train_model(model, train_loader, criterion, optimizer, device, lambda_fairness=0.01):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    total_fairness_loss = 0\n",
        "    total_eop = 0\n",
        "    total_eo = 0\n",
        "    total_dp = 0\n",
        "    total_batches = 0\n",
        "\n",
        "    for batch_x, batch_y, batch_sensitive in train_loader:\n",
        "        batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
        "        batch_sensitive = batch_sensitive.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 예측 및 분류 손실\n",
        "        outputs = model(batch_x)\n",
        "        classification_loss = criterion(outputs, batch_y)\n",
        "\n",
        "        # 공정성 손실 계산\n",
        "        probabilities = torch.softmax(outputs, dim=1)[:, 1]  # Probability of class 1\n",
        "\n",
        "        # To avoid NaNs, ensure that probabilities are between 0 and 1\n",
        "        probabilities = torch.clamp(probabilities, min=0.0, max=1.0)\n",
        "\n",
        "        # 공정성 지표 계산\n",
        "        eop = FairnessMetrics.equal_opportunity_difference(probabilities, batch_y, batch_sensitive, target_label=1)\n",
        "        eo = FairnessMetrics.equalized_odds_difference(probabilities, batch_y, batch_sensitive, target_label=1, epsilon=1e-6)\n",
        "        dp = FairnessMetrics.demographic_parity_difference(probabilities, batch_sensitive)\n",
        "\n",
        "        # 공정성 가중치 조정\n",
        "        a = 0.25\n",
        "        b = 0.25\n",
        "        c = 0.5\n",
        "\n",
        "\n",
        "        # 공정성 손실 합산\n",
        "        fairness_loss = (a * eop) + (b * eo) +  (c * dp)\n",
        "\n",
        "        # 전체 손실 결합\n",
        "        total_loss_batch = classification_loss + lambda_fairness * fairness_loss\n",
        "        total_loss_batch.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # 손실 및 공정성 지표 기록\n",
        "        total_loss += classification_loss.item()\n",
        "        total_fairness_loss += fairness_loss.item()\n",
        "        total_eop += eop.item()\n",
        "        total_eo += eo.item()\n",
        "        total_dp += dp.item()\n",
        "        total_batches += 1\n",
        "\n",
        "    avg_loss = total_loss / total_batches\n",
        "    avg_fairness_loss = total_fairness_loss / total_batches\n",
        "    avg_eop = total_eop / total_batches\n",
        "    avg_eo = total_eo / total_batches\n",
        "    avg_dp = total_dp / total_batches\n",
        "\n",
        "    return avg_loss, avg_fairness_loss, avg_eop, avg_eo, avg_dp\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# 모델 초기화\n",
        "input_dim = X_train.shape[1]\n",
        "hidden_dim = 128\n",
        "num_heads = 4\n",
        "num_classes = 2\n",
        "\n",
        "model = FairnessAwareTransformerClassifier(input_dim, hidden_dim, num_heads, num_classes).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "num_epochs = 10  # 충분한 학습을 위해 epoch 수 증가\n",
        "\n",
        "# 기록을 위한 리스트 초기화\n",
        "train_fairness_history = {\n",
        "    'loss': [],\n",
        "    'fairness_loss': [],\n",
        "    'EOP': [],\n",
        "    'EO': [],\n",
        "    'DP': []\n",
        "}\n",
        "test_fairness_history = {\n",
        "    'accuracy': [],\n",
        "    'EOP': [],\n",
        "    'EO': [],\n",
        "    'DP': []\n",
        "}\n",
        "\n",
        "for epoch in tqdm(range(num_epochs), desc=\"Training\"):\n",
        "    train_loss, train_fairness_loss, train_eop, train_eo, train_dp = train_model(\n",
        "        model, train_loader, criterion, optimizer,\n",
        "        device, lambda_fairness=0.1\n",
        "    )\n",
        "    test_acc, test_eop, test_eo, test_dp, test_auroc = evaluate_model(model, test_loader, device)\n",
        "\n",
        "    # 기록 저장\n",
        "    train_fairness_history['loss'].append(train_loss)\n",
        "    train_fairness_history['fairness_loss'].append(train_fairness_loss)\n",
        "    train_fairness_history['EOP'].append(train_eop)\n",
        "    train_fairness_history['EO'].append(train_eo)\n",
        "    train_fairness_history['DP'].append(train_dp)\n",
        "\n",
        "    test_fairness_history['accuracy'].append(test_acc)\n",
        "    test_fairness_history['EOP'].append(test_eop)\n",
        "    test_fairness_history['EO'].append(test_eo)\n",
        "    test_fairness_history['DP'].append(test_dp)\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], '\n",
        "          f'Loss: {train_loss:.4f}, '\n",
        "          f'Fairness Loss: {train_fairness_loss:.4f}, '\n",
        "          f'EOP: {train_eop:.4f}, '\n",
        "          f'EO: {train_eo:.4f}, '\n",
        "          f'DP: {train_dp:.4f}, '\n",
        "          f'Test Accuracy: {test_acc:.2f}%, '\n",
        "          f'Test EOP: {test_eop:.4f}, '\n",
        "          f'Test EO: {test_eo:.4f}, '\n",
        "          f'Test DP: {test_dp:.4f}',\n",
        "          f'Test AUROC: {test_auroc:.4f}')"
      ],
      "metadata": {
        "id": "Xh-mTVJVImHS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ad8192a-7460-4790-8f5a-557850c1143d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  10%|█         | 1/10 [00:06<01:02,  6.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.4402, Fairness Loss: 0.1366, EOP: 0.1758, EO: 0.1828, DP: 0.0939, Test Accuracy: 82.08%, Test EOP: 0.0951, Test EO: 0.0951, Test DP: 0.1202 Test AUROC: 0.8513\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  20%|██        | 2/10 [00:14<00:58,  7.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/10], Loss: 0.3849, Fairness Loss: 0.1670, EOP: 0.2033, EO: 0.2117, DP: 0.1266, Test Accuracy: 83.17%, Test EOP: 0.0830, Test EO: 0.0830, Test DP: 0.1240 Test AUROC: 0.8731\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  30%|███       | 3/10 [00:21<00:49,  7.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3/10], Loss: 0.3661, Fairness Loss: 0.1820, EOP: 0.2135, EO: 0.2256, DP: 0.1445, Test Accuracy: 83.22%, Test EOP: 0.1337, Test EO: 0.1337, Test DP: 0.1895 Test AUROC: 0.8782\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  40%|████      | 4/10 [00:28<00:43,  7.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4/10], Loss: 0.3589, Fairness Loss: 0.1874, EOP: 0.2153, EO: 0.2295, DP: 0.1525, Test Accuracy: 83.35%, Test EOP: 0.0938, Test EO: 0.0938, Test DP: 0.1420 Test AUROC: 0.8835\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  50%|█████     | 5/10 [00:36<00:36,  7.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/10], Loss: 0.3518, Fairness Loss: 0.1812, EOP: 0.2051, EO: 0.2197, DP: 0.1499, Test Accuracy: 84.03%, Test EOP: 0.0738, Test EO: 0.0811, Test DP: 0.1527 Test AUROC: 0.8824\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  60%|██████    | 6/10 [00:43<00:29,  7.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [6/10], Loss: 0.3497, Fairness Loss: 0.1817, EOP: 0.2087, EO: 0.2241, DP: 0.1471, Test Accuracy: 83.55%, Test EOP: 0.0409, Test EO: 0.0662, Test DP: 0.1246 Test AUROC: 0.8863\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  70%|███████   | 7/10 [00:51<00:22,  7.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [7/10], Loss: 0.3541, Fairness Loss: 0.1703, EOP: 0.2028, EO: 0.2159, DP: 0.1314, Test Accuracy: 84.01%, Test EOP: 0.0369, Test EO: 0.0791, Test DP: 0.1434 Test AUROC: 0.8853\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  80%|████████  | 8/10 [00:58<00:14,  7.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [8/10], Loss: 0.3504, Fairness Loss: 0.1806, EOP: 0.2091, EO: 0.2225, DP: 0.1454, Test Accuracy: 84.01%, Test EOP: 0.0537, Test EO: 0.0885, Test DP: 0.1524 Test AUROC: 0.8850\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  90%|█████████ | 9/10 [01:05<00:07,  7.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [9/10], Loss: 0.3506, Fairness Loss: 0.1953, EOP: 0.2230, EO: 0.2379, DP: 0.1602, Test Accuracy: 83.72%, Test EOP: 0.0641, Test EO: 0.0850, Test DP: 0.1512 Test AUROC: 0.8864\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 10/10 [01:12<00:00,  7.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/10], Loss: 0.3481, Fairness Loss: 0.1810, EOP: 0.2048, EO: 0.2204, DP: 0.1494, Test Accuracy: 84.10%, Test EOP: 0.0292, Test EO: 0.0822, Test DP: 0.1470 Test AUROC: 0.8875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9) EOP:0.05 / OP:0.05 / DP: 0.9"
      ],
      "metadata": {
        "id": "3hjmCOtYTS-D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 함수\n",
        "def train_model(model, train_loader, criterion, optimizer, device, lambda_fairness=0.01):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    total_fairness_loss = 0\n",
        "    total_eop = 0\n",
        "    total_eo = 0\n",
        "    total_dp = 0\n",
        "    total_batches = 0\n",
        "\n",
        "    for batch_x, batch_y, batch_sensitive in train_loader:\n",
        "        batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
        "        batch_sensitive = batch_sensitive.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 예측 및 분류 손실\n",
        "        outputs = model(batch_x)\n",
        "        classification_loss = criterion(outputs, batch_y)\n",
        "\n",
        "        # 공정성 손실 계산\n",
        "        probabilities = torch.softmax(outputs, dim=1)[:, 1]  # Probability of class 1\n",
        "\n",
        "        # To avoid NaNs, ensure that probabilities are between 0 and 1\n",
        "        probabilities = torch.clamp(probabilities, min=0.0, max=1.0)\n",
        "\n",
        "        # 공정성 지표 계산\n",
        "        eop = FairnessMetrics.equal_opportunity_difference(probabilities, batch_y, batch_sensitive, target_label=1)\n",
        "        eo = FairnessMetrics.equalized_odds_difference(probabilities, batch_y, batch_sensitive, target_label=1, epsilon=1e-6)\n",
        "        dp = FairnessMetrics.demographic_parity_difference(probabilities, batch_sensitive)\n",
        "\n",
        "        # 공정성 가중치 조정\n",
        "        a = 0.05\n",
        "        b = 0.05\n",
        "        c = 0.9\n",
        "\n",
        "\n",
        "        # 공정성 손실 합산\n",
        "        fairness_loss = (a * eop) + (b * eo) +  (c * dp)\n",
        "\n",
        "        # 전체 손실 결합\n",
        "        total_loss_batch = classification_loss + lambda_fairness * fairness_loss\n",
        "        total_loss_batch.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # 손실 및 공정성 지표 기록\n",
        "        total_loss += classification_loss.item()\n",
        "        total_fairness_loss += fairness_loss.item()\n",
        "        total_eop += eop.item()\n",
        "        total_eo += eo.item()\n",
        "        total_dp += dp.item()\n",
        "        total_batches += 1\n",
        "\n",
        "    avg_loss = total_loss / total_batches\n",
        "    avg_fairness_loss = total_fairness_loss / total_batches\n",
        "    avg_eop = total_eop / total_batches\n",
        "    avg_eo = total_eo / total_batches\n",
        "    avg_dp = total_dp / total_batches\n",
        "\n",
        "    return avg_loss, avg_fairness_loss, avg_eop, avg_eo, avg_dp\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# 모델 초기화\n",
        "input_dim = X_train.shape[1]\n",
        "hidden_dim = 128\n",
        "num_heads = 4\n",
        "num_classes = 2\n",
        "\n",
        "model = FairnessAwareTransformerClassifier(input_dim, hidden_dim, num_heads, num_classes).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "num_epochs = 10  # 충분한 학습을 위해 epoch 수 증가\n",
        "\n",
        "# 기록을 위한 리스트 초기화\n",
        "train_fairness_history = {\n",
        "    'loss': [],\n",
        "    'fairness_loss': [],\n",
        "    'EOP': [],\n",
        "    'EO': [],\n",
        "    'DP': []\n",
        "}\n",
        "test_fairness_history = {\n",
        "    'accuracy': [],\n",
        "    'EOP': [],\n",
        "    'EO': [],\n",
        "    'DP': []\n",
        "}\n",
        "\n",
        "for epoch in tqdm(range(num_epochs), desc=\"Training\"):\n",
        "    train_loss, train_fairness_loss, train_eop, train_eo, train_dp = train_model(\n",
        "        model, train_loader, criterion, optimizer,\n",
        "        device, lambda_fairness=0.1\n",
        "    )\n",
        "    test_acc, test_eop, test_eo, test_dp, test_auroc = evaluate_model(model, test_loader, device)\n",
        "\n",
        "    # 기록 저장\n",
        "    train_fairness_history['loss'].append(train_loss)\n",
        "    train_fairness_history['fairness_loss'].append(train_fairness_loss)\n",
        "    train_fairness_history['EOP'].append(train_eop)\n",
        "    train_fairness_history['EO'].append(train_eo)\n",
        "    train_fairness_history['DP'].append(train_dp)\n",
        "\n",
        "    test_fairness_history['accuracy'].append(test_acc)\n",
        "    test_fairness_history['EOP'].append(test_eop)\n",
        "    test_fairness_history['EO'].append(test_eo)\n",
        "    test_fairness_history['DP'].append(test_dp)\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], '\n",
        "          f'Loss: {train_loss:.4f}, '\n",
        "          f'Fairness Loss: {train_fairness_loss:.4f}, '\n",
        "          f'EOP: {train_eop:.4f}, '\n",
        "          f'EO: {train_eo:.4f}, '\n",
        "          f'DP: {train_dp:.4f}, '\n",
        "          f'Test Accuracy: {test_acc:.2f}%, '\n",
        "          f'Test EOP: {test_eop:.4f}, '\n",
        "          f'Test EO: {test_eo:.4f}, '\n",
        "          f'Test DP: {test_dp:.4f}',\n",
        "          f'Test AUROC: {test_auroc:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZTBW-RLTTTQ",
        "outputId": "b7cc0379-6c4e-4dd0-e1b5-232292244eb6"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  10%|█         | 1/10 [00:07<01:08,  7.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.4510, Fairness Loss: 0.1089, EOP: 0.1755, EO: 0.1836, DP: 0.1011, Test Accuracy: 76.25%, Test EOP: 0.1083, Test EO: 0.1083, Test DP: 0.1093 Test AUROC: 0.7830\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  20%|██        | 2/10 [00:14<00:59,  7.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/10], Loss: 0.4258, Fairness Loss: 0.1262, EOP: 0.2176, EO: 0.2241, DP: 0.1157, Test Accuracy: 80.15%, Test EOP: 0.1531, Test EO: 0.1531, Test DP: 0.1362 Test AUROC: 0.8346\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  30%|███       | 3/10 [00:22<00:50,  7.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3/10], Loss: 0.4201, Fairness Loss: 0.1344, EOP: 0.2172, EO: 0.2244, DP: 0.1248, Test Accuracy: 81.84%, Test EOP: 0.1749, Test EO: 0.1749, Test DP: 0.1377 Test AUROC: 0.8312\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  40%|████      | 4/10 [00:29<00:44,  7.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4/10], Loss: 0.4264, Fairness Loss: 0.1217, EOP: 0.2130, EO: 0.2197, DP: 0.1112, Test Accuracy: 77.22%, Test EOP: 0.0111, Test EO: 0.0111, Test DP: 0.0193 Test AUROC: 0.6331\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  50%|█████     | 5/10 [00:36<00:36,  7.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/10], Loss: 0.5528, Fairness Loss: 0.0141, EOP: 0.0501, EO: 0.0520, DP: 0.0100, Test Accuracy: 76.07%, Test EOP: 0.0000, Test EO: 0.0000, Test DP: 0.0000 Test AUROC: 0.7183\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  60%|██████    | 6/10 [00:44<00:29,  7.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [6/10], Loss: 0.5540, Fairness Loss: 0.0088, EOP: 0.0378, EO: 0.0389, DP: 0.0055, Test Accuracy: 76.07%, Test EOP: 0.0000, Test EO: 0.0000, Test DP: 0.0000 Test AUROC: 0.6283\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  70%|███████   | 7/10 [00:51<00:21,  7.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [7/10], Loss: 0.5535, Fairness Loss: 0.0079, EOP: 0.0348, EO: 0.0358, DP: 0.0049, Test Accuracy: 76.07%, Test EOP: 0.0000, Test EO: 0.0000, Test DP: 0.0001 Test AUROC: 0.6515\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  80%|████████  | 8/10 [00:58<00:14,  7.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [8/10], Loss: 0.5160, Fairness Loss: 0.0441, EOP: 0.0886, EO: 0.0918, DP: 0.0389, Test Accuracy: 81.28%, Test EOP: 0.0981, Test EO: 0.0981, Test DP: 0.0827 Test AUROC: 0.8052\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  90%|█████████ | 9/10 [01:06<00:07,  7.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [9/10], Loss: 0.4522, Fairness Loss: 0.0888, EOP: 0.1842, EO: 0.1872, DP: 0.0780, Test Accuracy: 80.94%, Test EOP: 0.0885, Test EO: 0.0885, Test DP: 0.0830 Test AUROC: 0.7834\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 10/10 [01:13<00:00,  7.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/10], Loss: 0.4580, Fairness Loss: 0.0850, EOP: 0.1849, EO: 0.1881, DP: 0.0738, Test Accuracy: 79.30%, Test EOP: 0.0508, Test EO: 0.0508, Test DP: 0.0523 Test AUROC: 0.7360\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "10) EOP:0.25 / OP:0.5 / DP: 0.25"
      ],
      "metadata": {
        "id": "91S6RD61YufD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 함수\n",
        "def train_model(model, train_loader, criterion, optimizer, device, lambda_fairness=0.01):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    total_fairness_loss = 0\n",
        "    total_eop = 0\n",
        "    total_eo = 0\n",
        "    total_dp = 0\n",
        "    total_batches = 0\n",
        "\n",
        "    for batch_x, batch_y, batch_sensitive in train_loader:\n",
        "        batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
        "        batch_sensitive = batch_sensitive.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 예측 및 분류 손실\n",
        "        outputs = model(batch_x)\n",
        "        classification_loss = criterion(outputs, batch_y)\n",
        "\n",
        "        # 공정성 손실 계산\n",
        "        probabilities = torch.softmax(outputs, dim=1)[:, 1]  # Probability of class 1\n",
        "\n",
        "        # To avoid NaNs, ensure that probabilities are between 0 and 1\n",
        "        probabilities = torch.clamp(probabilities, min=0.0, max=1.0)\n",
        "\n",
        "        # 공정성 지표 계산\n",
        "        eop = FairnessMetrics.equal_opportunity_difference(probabilities, batch_y, batch_sensitive, target_label=1)\n",
        "        eo = FairnessMetrics.equalized_odds_difference(probabilities, batch_y, batch_sensitive, target_label=1, epsilon=1e-6)\n",
        "        dp = FairnessMetrics.demographic_parity_difference(probabilities, batch_sensitive)\n",
        "\n",
        "        # 공정성 가중치 조정\n",
        "        a = 0.25\n",
        "        b = 0.5\n",
        "        c = 0.25\n",
        "\n",
        "\n",
        "        # 공정성 손실 합산\n",
        "        fairness_loss = (a * eop) + (b * eo) +  (c * dp)\n",
        "\n",
        "        # 전체 손실 결합\n",
        "        total_loss_batch = classification_loss + lambda_fairness * fairness_loss\n",
        "        total_loss_batch.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # 손실 및 공정성 지표 기록\n",
        "        total_loss += classification_loss.item()\n",
        "        total_fairness_loss += fairness_loss.item()\n",
        "        total_eop += eop.item()\n",
        "        total_eo += eo.item()\n",
        "        total_dp += dp.item()\n",
        "        total_batches += 1\n",
        "\n",
        "    avg_loss = total_loss / total_batches\n",
        "    avg_fairness_loss = total_fairness_loss / total_batches\n",
        "    avg_eop = total_eop / total_batches\n",
        "    avg_eo = total_eo / total_batches\n",
        "    avg_dp = total_dp / total_batches\n",
        "\n",
        "    return avg_loss, avg_fairness_loss, avg_eop, avg_eo, avg_dp\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# 모델 초기화\n",
        "input_dim = X_train.shape[1]\n",
        "hidden_dim = 128\n",
        "num_heads = 4\n",
        "num_classes = 2\n",
        "\n",
        "model = FairnessAwareTransformerClassifier(input_dim, hidden_dim, num_heads, num_classes).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "num_epochs = 10  # 충분한 학습을 위해 epoch 수 증가\n",
        "\n",
        "# 기록을 위한 리스트 초기화\n",
        "train_fairness_history = {\n",
        "    'loss': [],\n",
        "    'fairness_loss': [],\n",
        "    'EOP': [],\n",
        "    'EO': [],\n",
        "    'DP': []\n",
        "}\n",
        "test_fairness_history = {\n",
        "    'accuracy': [],\n",
        "    'EOP': [],\n",
        "    'EO': [],\n",
        "    'DP': []\n",
        "}\n",
        "\n",
        "for epoch in tqdm(range(num_epochs), desc=\"Training\"):\n",
        "    train_loss, train_fairness_loss, train_eop, train_eo, train_dp = train_model(\n",
        "        model, train_loader, criterion, optimizer,\n",
        "        device, lambda_fairness=0.1\n",
        "    )\n",
        "    test_acc, test_eop, test_eo, test_dp, test_auroc = evaluate_model(model, test_loader, device)\n",
        "\n",
        "    # 기록 저장\n",
        "    train_fairness_history['loss'].append(train_loss)\n",
        "    train_fairness_history['fairness_loss'].append(train_fairness_loss)\n",
        "    train_fairness_history['EOP'].append(train_eop)\n",
        "    train_fairness_history['EO'].append(train_eo)\n",
        "    train_fairness_history['DP'].append(train_dp)\n",
        "\n",
        "    test_fairness_history['accuracy'].append(test_acc)\n",
        "    test_fairness_history['EOP'].append(test_eop)\n",
        "    test_fairness_history['EO'].append(test_eo)\n",
        "    test_fairness_history['DP'].append(test_dp)\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], '\n",
        "          f'Loss: {train_loss:.4f}, '\n",
        "          f'Fairness Loss: {train_fairness_loss:.4f}, '\n",
        "          f'EOP: {train_eop:.4f}, '\n",
        "          f'EO: {train_eo:.4f}, '\n",
        "          f'DP: {train_dp:.4f}, '\n",
        "          f'Test Accuracy: {test_acc:.2f}%, '\n",
        "          f'Test EOP: {test_eop:.4f}, '\n",
        "          f'Test EO: {test_eo:.4f}, '\n",
        "          f'Test DP: {test_dp:.4f}',\n",
        "          f'Test AUROC: {test_auroc:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "obOgqsXAYu9h",
        "outputId": "959ca208-fc71-4be7-b18f-453e1e54e9e2"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  10%|█         | 1/10 [00:07<01:08,  7.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.4488, Fairness Loss: 0.1566, EOP: 0.1711, EO: 0.1787, DP: 0.0979, Test Accuracy: 81.52%, Test EOP: 0.1437, Test EO: 0.1437, Test DP: 0.1116 Test AUROC: 0.8451\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  20%|██        | 2/10 [00:14<00:57,  7.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/10], Loss: 0.4043, Fairness Loss: 0.2022, EOP: 0.2190, EO: 0.2274, DP: 0.1351, Test Accuracy: 83.21%, Test EOP: 0.1607, Test EO: 0.1607, Test DP: 0.1554 Test AUROC: 0.8638\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  30%|███       | 3/10 [00:22<00:51,  7.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3/10], Loss: 0.3805, Fairness Loss: 0.2050, EOP: 0.2169, EO: 0.2278, DP: 0.1472, Test Accuracy: 83.48%, Test EOP: 0.0926, Test EO: 0.0926, Test DP: 0.1532 Test AUROC: 0.8768\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  40%|████      | 4/10 [00:29<00:44,  7.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4/10], Loss: 0.3661, Fairness Loss: 0.1878, EOP: 0.1933, EO: 0.2078, DP: 0.1423, Test Accuracy: 82.99%, Test EOP: 0.0495, Test EO: 0.0963, Test DP: 0.1611 Test AUROC: 0.8835\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  50%|█████     | 5/10 [00:36<00:36,  7.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/10], Loss: 0.3612, Fairness Loss: 0.1887, EOP: 0.1881, EO: 0.2090, DP: 0.1488, Test Accuracy: 83.62%, Test EOP: 0.0409, Test EO: 0.0801, Test DP: 0.1389 Test AUROC: 0.8846\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  60%|██████    | 6/10 [00:44<00:29,  7.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [6/10], Loss: 0.3550, Fairness Loss: 0.1938, EOP: 0.1956, EO: 0.2129, DP: 0.1538, Test Accuracy: 84.08%, Test EOP: 0.0624, Test EO: 0.0944, Test DP: 0.1557 Test AUROC: 0.8867\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  70%|███████   | 7/10 [00:51<00:21,  7.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [7/10], Loss: 0.3523, Fairness Loss: 0.1972, EOP: 0.1992, EO: 0.2166, DP: 0.1563, Test Accuracy: 83.36%, Test EOP: 0.0533, Test EO: 0.1088, Test DP: 0.1761 Test AUROC: 0.8881\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  80%|████████  | 8/10 [00:58<00:14,  7.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [8/10], Loss: 0.3494, Fairness Loss: 0.2021, EOP: 0.2044, EO: 0.2224, DP: 0.1590, Test Accuracy: 84.23%, Test EOP: 0.0622, Test EO: 0.0972, Test DP: 0.1616 Test AUROC: 0.8881\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  90%|█████████ | 9/10 [01:05<00:07,  7.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [9/10], Loss: 0.3474, Fairness Loss: 0.2007, EOP: 0.2039, EO: 0.2214, DP: 0.1562, Test Accuracy: 84.12%, Test EOP: 0.0378, Test EO: 0.0891, Test DP: 0.1481 Test AUROC: 0.8896\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 10/10 [01:13<00:00,  7.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/10], Loss: 0.3492, Fairness Loss: 0.1988, EOP: 0.2016, EO: 0.2195, DP: 0.1545, Test Accuracy: 84.16%, Test EOP: 0.0525, Test EO: 0.1080, Test DP: 0.1754 Test AUROC: 0.8926\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}