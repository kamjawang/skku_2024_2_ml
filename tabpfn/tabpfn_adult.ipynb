{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gpytorch\n",
    "!pip install ConfigSpace\n",
    "!pip install openml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tabpfn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-learn==1.1.3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ucimlrepo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tabpfn\n",
    "from tabpfn import TabPFNClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "\n",
    "adult = fetch_ucirepo(id=2) \n",
    "\n",
    "X = adult.data.features\n",
    "y = adult.data.targets \n",
    "  \n",
    "\n",
    "df = pd.concat([X,y],axis=1)\n",
    "\n",
    "df = df.dropna()\n",
    "\n",
    "df['income'] = df['income'].str.replace(r'K\\.', 'K', regex=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 세트 1000개 이상인 경우 실행 안되므로 Sampling 쪼개기\n",
    "\n",
    "def stratified_sample(df, stratify_col, n_per_class, random_state=None, replace=False):\n",
    "    return df.groupby(stratify_col).sample(n=n_per_class, replace=replace, random_state=random_state)\n",
    "\n",
    "\n",
    "df = stratified_sample(df, stratify_col='income', n_per_class=400, random_state=123)\n",
    "\n",
    "\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['age', 'workclass', 'fnlwgt', 'education', 'education-num',\n",
    "       'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
    "       'capital-gain', 'capital-loss', 'hours-per-week', 'native-country',\n",
    "       ]]\n",
    "y = df[['income']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label을 0,1로 변환\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "y_label = le.fit_transform(y.astype(str)) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#categorical data를 숫자로 변환후 변환된 값으로 데이터세트 칼럼 구성\n",
    "for i in ['workclass','education',\n",
    "       'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
    "       'native-country']:\n",
    "    X[f'{i}_cat'] = le.fit_transform(X[f'{i}'].astype(str))\n",
    "X = X[['age', 'fnlwgt', 'capital-gain', 'capital-loss', 'hours-per-week',\n",
    "      'workclass_cat', 'education_cat', 'marital-status_cat',\n",
    "      'occupation_cat', 'relationship_cat', 'race_cat', 'sex_cat',\n",
    "      'native-country_cat']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_configurations = X_train.shape[1] * len(set(y_train))\n",
    "print(\"최대 N_ensemble_configurations:\", max_configurations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N_ensemble_configurations defines how many estimators are averaged, it is bounded by #features * #classes\n",
    "# more ensemble members are slower, but more accurate\n",
    "classifier = TabPFNClassifier(device='cuda', N_ensemble_configurations=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "classifier.fit(X_train, y_train)\n",
    "y_eval, p_eval = classifier.predict(X_test, return_winning_probability=True)\n",
    "print('Prediction time: ', time.time() - start, 'Accuracy', accuracy_score(y_test, y_eval), 'AUROC', roc_auc_score(y_test,y_eval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_cat, y_label, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_configurations = X_train.shape[1] * len(set(y_train))\n",
    "print(\"최대 N_ensemble_configurations:\", max_configurations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N_ensemble_configurations defines how many estimators are averaged, it is bounded by #features * #classes\n",
    "# more ensemble members are slower, but more accurate\n",
    "classifier = TabPFNClassifier(device='cuda', N_ensemble_configurations=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "classifier.fit(X_train, y_train)\n",
    "y_eval, p_eval = classifier.predict(X_test, return_winning_probability=True)\n",
    "print('Prediction time: ', time.time() - start, 'Accuracy', accuracy_score(y_test, y_eval))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "'''\n",
    "    - 기계학습특론 : 공정성 지표 metric example 코드\n",
    "    - 공정성 지표 :\n",
    "       1) Equal Opportunity (EOP)\n",
    "       2) Equalized Odds (EO)\n",
    "       3) Demographic Parity (DP)\n",
    "\n",
    "    - Input :\n",
    "       - prediction : 예측값\n",
    "       - true_label : 실측값\n",
    "       - sensitive_feature (= protected_attribute_train / test )\n",
    "       - target_label : label 선택한 값 ( 1 , 0 )\n",
    "\n",
    "    - Output :\n",
    "       - 3 가지 지표 : 퍼센트값 (%)\n",
    "        1) Equal Opportunity (EOP)\n",
    "        2) Equalized Odds (EO)\n",
    "        3) Demographic Parity (DP)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "    평가함수\n",
    "'''\n",
    "\n",
    "\n",
    "def equalized_odds_difference(predictions, true_labels, sensitive_features, target_label):\n",
    "\n",
    "    binary_predictions = np.where(predictions > 0.5, 1, 0)\n",
    "    positive_mask = true_labels == target_label\n",
    "    tpr_0 = np.mean(binary_predictions[(sensitive_features == 0) & positive_mask] == target_label)\n",
    "    tpr_1 = np.mean(binary_predictions[(sensitive_features == 1) & positive_mask] == target_label)\n",
    "\n",
    "    return np.abs(tpr_0 - tpr_1)\n",
    "\n",
    "def demographic_parity_difference(predictions, sensitive_features):\n",
    "\n",
    "    binary_predictions = np.where(predictions > 0.5, 1, 0)\n",
    "\n",
    "    rate_0 = np.mean(binary_predictions[sensitive_features == 0])\n",
    "    rate_1 = np.mean(binary_predictions[sensitive_features == 1])\n",
    "\n",
    "    return np.abs(rate_0 - rate_1)\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"지표 산출에 필요한 input 인자 생성 -> 'sex_cat' \"\"\"\n",
    "\n",
    "\n",
    "sensitive_attribute = 'sex_cat'\n",
    "protected_attribute_train = X_train[sensitive_attribute]\n",
    "protected_attribute_test = X_test[sensitive_attribute]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "delta_equal_opportunity = equalized_odds_difference(y_eval, y_test, protected_attribute_test,\n",
    "                                                    target_label=1)\n",
    "\n",
    "delta_equalized_odds_negative = equalized_odds_difference(y_eval, y_test,\n",
    "                                                          protected_attribute_test, target_label=0)\n",
    "\n",
    "delta_demographic_parity = demographic_parity_difference(y_eval, protected_attribute_test)\n",
    "\n",
    "delta_equalized_odds = max(delta_equal_opportunity, delta_equalized_odds_negative)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "log_message = (f'delta_equalized_odds {delta_equalized_odds:.2%}\\t delta_equal_opportunity {delta_equal_opportunity:.2%}'f'\\t delta_demographic_parity {delta_demographic_parity:.2%}\\t')\n",
    "\n",
    "\n",
    "\n",
    "print(log_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "성능 개선 방법\n",
    "- N_ensemble_configurations 바꾸기 (max : 특성개수 * labeling 종류 개수)\n",
    "- train/test 비율 변화 (train이 많을수록 좋아지긴 함)\n",
    "- class 불균형 맞추기\n",
    "- 여러번 샘플링 해서 결과를 투표로 결정\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
